{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d281b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Imports\n",
    "# ---------------------------------------------------------------------\n",
    "import os  # For folder creation\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle  # For saving/loading models\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Download historical GOLDBEES ETF price data\n",
    "# ---------------------------------------------------------------------\n",
    "def download_gold_prices(start_date: datetime, end_date: datetime) -> pd.DataFrame:\n",
    "    # Download historical GOLDBEES ETF price data\n",
    "    print(\"\\nStep 1: Downloading gold price data (GOLDBEES.BO)...\")\n",
    "    gold = yf.download('GOLDBEES.BO', start=start_date, end=end_date, progress=False)\n",
    "    print(\"Download complete.\")\n",
    "    #print(gold.head())\n",
    "\n",
    "    if isinstance(gold.columns, pd.MultiIndex):\n",
    "        gold.columns = gold.columns.get_level_values(0)\n",
    "\n",
    "    gold = gold[['Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "    gold.columns.name = None  # Remove \"Price\" label from column index\n",
    "\n",
    "    print(\"Current working directory:\", os.getcwd())  \n",
    "    # Ensure the 'Data' directory exists\n",
    "    os.makedirs(\"Data\", exist_ok=True)\n",
    "\n",
    "    # Save raw data to CSV\n",
    "    gold.to_csv(\"Data/GOLDBEES_ETF_price_data.csv\")\n",
    "    print(\"Saved raw gold price data to Data/GOLDBEES_ETF_price_data.csv\")\n",
    "    #print(gold.columns)\n",
    "    #print(gold.head())\n",
    "    return gold\n",
    "\n",
    "\n",
    "# Technical Indicator Calculation\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "#RSI Calculation\n",
    "# ---------------------------------------------------------------------\n",
    "def calculate_rsi(prices: pd.Series, period: int = 14) -> pd.Series:\n",
    "    # Relative Strength Index calculation\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "\n",
    "# Technical Indicator Calculation\n",
    "# ---------------------------------------------------------------------\n",
    "def add_technical_indicators(gold: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Technical indicators\n",
    "    print(\"Adding technical indicators...\")\n",
    "\n",
    "    gold['Returns'] = gold['Close'].pct_change()\n",
    "    gold['MA_5'] = gold['Close'].rolling(window=5).mean()\n",
    "    gold['MA_20'] = gold['Close'].rolling(window=20).mean()\n",
    "    gold['MA_50'] = gold['Close'].rolling(window=50).mean()\n",
    "    gold['Volatility'] = gold['Returns'].rolling(window=20).std()\n",
    "    gold['RSI'] = calculate_rsi(gold['Close'])\n",
    "\n",
    "    print(\"Calculating Bollinger Bands...\")\n",
    "    rolling_std = gold['Close'].rolling(window=20).std()\n",
    "    gold['BB_upper'] = gold['MA_20'] + (rolling_std * 2)\n",
    "    gold['BB_lower'] = gold['MA_20'] - (rolling_std * 2)\n",
    "    gold['BB_width'] = gold['BB_upper'] - gold['BB_lower']\n",
    "    gold['BB_position'] = (gold['Close'] - gold['BB_lower']) / gold['BB_width']\n",
    "\n",
    "    # MACD and Signal Line\n",
    "    exp1 = gold['Close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = gold['Close'].ewm(span=26, adjust=False).mean()\n",
    "    gold['MACD'] = exp1 - exp2\n",
    "    gold['MACD_Signal'] = gold['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    gold['MACD_Hist'] = gold['MACD'] - gold['MACD_Signal']\n",
    "\n",
    "    # Momentum (n-day price diff)\n",
    "    gold['Momentum_10'] = gold['Close'] - gold['Close'].shift(10)\n",
    "\n",
    "    # Rate of Change (ROC)\n",
    "    gold['ROC_10'] = gold['Close'].pct_change(periods=10)\n",
    "\n",
    "\n",
    "    # Drop NaNs and infinite values after all calculations\n",
    "    gold.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    gold.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    # Desired column order\n",
    "    columns_order = [\n",
    "        'Date', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility', 'RSI',\n",
    "        'BB_upper', 'BB_lower', 'BB_width', 'BB_position',\n",
    "        'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'Momentum_10', 'ROC_10'\n",
    "    ]\n",
    "\n",
    "    # Reorder and handle missing columns\n",
    "    existing_cols = [col for col in columns_order if col in gold.columns]\n",
    "    gold = gold[existing_cols]\n",
    "\n",
    "    print(f\"Added indicators to {len(gold)} rows.\")\n",
    "\n",
    "    # Save full DataFrame with indicators\n",
    "    gold.to_csv(\"Data/GOLDBEES_ETF_price_data_technical_indicators.csv\")\n",
    "    print(\"Saved technical indicators to Data/GOLDBEES_ETF_price_data_technical_indicators.csv\")\n",
    "\n",
    "    return gold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Add continuous sentiment Based on Price Trend with Labels\n",
    "# ---------------------------------------------------------------------\n",
    "def generate_sentiment_from_trend_with_labels(gold: pd.DataFrame, sentiment_today: float = 0.0, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate numeric sentiment scores and sentiment labels based on price returns.\n",
    "\n",
    "    Args:\n",
    "        gold (pd.DataFrame): DataFrame with 'Close' column\n",
    "        seed (int): Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with 'Sentiment' and 'Sentiment_Label' columns\n",
    "    \"\"\"\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "\n",
    "    gold = gold.copy()\n",
    "    gold['Returns'] = gold['Close'].pct_change()\n",
    "\n",
    "    sentiment_scores = []\n",
    "    sentiment_labels = []\n",
    "\n",
    "    for ret in gold['Returns']:\n",
    "        if pd.isna(ret):\n",
    "            sentiment = 0.0\n",
    "        elif ret > 0.01:\n",
    "            sentiment = round(random.uniform(0.5, 1.0), 2)\n",
    "        elif ret > 0.0:\n",
    "            sentiment = round(random.uniform(0.1, 0.5), 2)\n",
    "        elif ret > -0.01:\n",
    "            sentiment = round(random.uniform(-0.5, -0.1), 2)\n",
    "        else:\n",
    "            sentiment = round(random.uniform(-1.0, -0.5), 2)\n",
    "\n",
    "        # Assign label\n",
    "        if sentiment > 0.1:\n",
    "            label = 'positive'\n",
    "        elif sentiment < -0.1:\n",
    "            label = 'negative'\n",
    "        else:\n",
    "            label = 'neutral'\n",
    "\n",
    "        sentiment_scores.append(sentiment)\n",
    "        sentiment_labels.append(label)\n",
    "\n",
    "    gold['Sentiment'] = sentiment_scores\n",
    "    gold['Sentiment_Label'] = sentiment_labels\n",
    "\n",
    "    # Inject today's sentiment into the last row\n",
    "    #gold['Sentiment'] = 0.0  # Initialize all with neutral\n",
    "    if not gold.empty:\n",
    "        gold.iloc[-1, gold.columns.get_loc('Sentiment')] = sentiment_today\n",
    "        print(f\"Injected today's sentiment ({sentiment_today:+.2f}) into the last row.\")\n",
    "\n",
    "    # Save to CSV\n",
    "    os.makedirs(\"Data\", exist_ok=True)\n",
    "    gold.to_csv(\"Data/GOLDBEES_ETF_price_data_technical_indicators_sentiment.csv\")\n",
    "    print(\"Sentiment columns added and saved to Data/GOLDBEES_ETF_price_data_technical_indicators_sentiment.csv\")\n",
    "\n",
    "    return gold\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8713b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Downloading gold price data (GOLDBEES.BO)...\n",
      "YF.download() has changed argument auto_adjust default to True\n",
      "Download complete.\n",
      "Current working directory: d:\\Python\\04_Python_DA225o\\zDL_Project_Gold_Price_07_LangChain\n",
      "Saved raw gold price data to Data/GOLDBEES_ETF_price_data.csv\n",
      "Adding technical indicators...\n",
      "Calculating Bollinger Bands...\n",
      "Added indicators to 3743 rows.\n",
      "Saved technical indicators to Data/GOLDBEES_ETF_price_data_technical_indicators.csv\n",
      "Injected today's sentiment (+0.00) into the last row.\n",
      "Sentiment columns added and saved to Data/GOLDBEES_ETF_price_data_technical_indicators_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "start = datetime(2010, 1, 1)\n",
    "end = datetime(2026, 1, 1)\n",
    "gold = download_gold_prices(start, end)\n",
    "gold = add_technical_indicators(gold)\n",
    "gold = generate_sentiment_from_trend_with_labels(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b94a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ARIMAX with technical indicators and save the model.\n",
    "# ---------------------------------------------------------------------\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "def train_arimax(df: pd.DataFrame, model_dir=\"Model/Arimax\", arima_order=(1, 1, 1)):\n",
    "    # -------------------------------\n",
    "    # Step 1: Setup\n",
    "    # -------------------------------\n",
    "    #model_dir = \"Model/Arimax\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    model_path = os.path.join(model_dir, f\"arimax_{today_str}.pkl\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 2: Define Exogenous Features\n",
    "    # -------------------------------\n",
    "    exog_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment',\n",
    "        'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'Momentum_10', 'ROC_10'\n",
    "    ]\n",
    "\n",
    "    for col in exog_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    df = df[['Close'] + exog_cols].dropna()\n",
    "    df = df.asfreq('B')\n",
    "    df.ffill(inplace=True)\n",
    "\n",
    "    y = df['Close']\n",
    "    exog = df[exog_cols]\n",
    "\n",
    "    # -------------------------------\n",
    "    # Step 3: # Train new model\n",
    "    # -------------------------------\n",
    "    # Clean old models\n",
    "    for fname in os.listdir(model_dir):\n",
    "        if fname.startswith(\"arimax_\") and fname.endswith(\".pkl\"):\n",
    "            os.remove(os.path.join(model_dir, fname))\n",
    "\n",
    "    # Train new model\n",
    "    model = SARIMAX(endog=y, exog=exog, order=arima_order,\n",
    "                    enforce_stationarity=False, enforce_invertibility=False)\n",
    "    model_fit = model.fit(disp=False, method='powell')\n",
    "\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model_fit, f)\n",
    "    print(f\"Saved new ARIMAX model to: {model_path}\")   \n",
    "    return model_fit, model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ab60cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new ARIMAX model to: Model/Arimax\\arimax_2025-06-23.pkl\n"
     ]
    }
   ],
   "source": [
    "model, path = train_arimax(gold, model_dir=\"Model/Arimax\", arima_order=(1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3d2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains an XGBoost model using gold price and technical features, then saves the model.\n",
    "# ---------------------------------------------------------------------\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def train_xgboost_model(gold: pd.DataFrame, model_dir=\"Model/XGBoost\", test_size: float = 0.2, random_state: int = 42):\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    model_path = os.path.join(model_dir, f\"xgboost_{today_str}.pkl\")\n",
    "\n",
    "    # Clean up old models in the directory\n",
    "    for fname in os.listdir(model_dir):\n",
    "        if fname.startswith(\"xgboost_\") and fname.endswith(\".pkl\"):\n",
    "            os.remove(os.path.join(model_dir, fname))\n",
    "\n",
    "    # Feature engineering\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment',\n",
    "        'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'Momentum_10', 'ROC_10'\n",
    "    ]\n",
    "\n",
    "    gold_clean = gold[['Close'] + feature_cols].copy().dropna()\n",
    "    gold_clean['Close_pct_change_1'] = gold_clean['Close'].pct_change(1)\n",
    "    gold_clean['Close_pct_change_2'] = gold_clean['Close'].pct_change(2)\n",
    "    gold_clean['Close_pct_change_3'] = gold_clean['Close'].pct_change(3)\n",
    "    gold_clean['Close_rolling_std_5'] = gold_clean['Close'].rolling(5).std()\n",
    "    gold_clean['Close_rolling_std_10'] = gold_clean['Close'].rolling(10).std()\n",
    "    gold_clean['Close_vs_MA5'] = (gold_clean['Close'] - gold_clean['MA_5']) / gold_clean['MA_5']\n",
    "    gold_clean['Close_vs_MA20'] = (gold_clean['Close'] - gold_clean['MA_20']) / gold_clean['MA_20']\n",
    "\n",
    "    # Final features and target\n",
    "    feature_cols_extended = feature_cols + [\n",
    "        'Close_pct_change_1', 'Close_pct_change_2', 'Close_pct_change_3',\n",
    "        'Close_rolling_std_5', 'Close_rolling_std_10',\n",
    "        'Close_vs_MA5', 'Close_vs_MA20'\n",
    "    ]\n",
    "\n",
    "    gold_clean['Target_pct_change'] = gold_clean['Close'].pct_change().shift(-1)\n",
    "    gold_clean['Target_price'] = gold_clean['Close'].shift(-1)\n",
    "    gold_clean = gold_clean.dropna()\n",
    "    gold_clean = gold_clean[\n",
    "        (np.isfinite(gold_clean['Target_pct_change'])) &\n",
    "        (np.abs(gold_clean['Target_pct_change']) < 1.0)\n",
    "    ]\n",
    "\n",
    "    # Prepare data\n",
    "    X = gold_clean[feature_cols_extended]\n",
    "    y_pct = gold_clean['Target_pct_change']\n",
    "\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train, y_train = X.iloc[:split_idx], y_pct.iloc[:split_idx]\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Train XGBoost\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.008,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.95,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_alpha=0.001,\n",
    "        reg_lambda=0.01,\n",
    "        gamma=0,\n",
    "        random_state=random_state,\n",
    "        objective='reg:squarederror',\n",
    "        tree_method='hist'\n",
    "    )\n",
    "\n",
    "    print(\" Training new XGBoost model...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Save the model\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    return model, model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f195e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training new XGBoost model...\n",
      "Model saved to Model/XGBoost\\xgboost_2025-06-23.pkl\n"
     ]
    }
   ],
   "source": [
    "#from modules.model_train import train_xgboost_model\n",
    "model, path = train_xgboost_model(gold, model_dir=\"Model/XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9babdef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model on gold data with engineered features and save it to disk.\n",
    "# ---------------------------------------------------------------------------\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "def train_random_forest_model(gold: pd.DataFrame, model_dir=\"Model/RandomForest\", test_size: float = 0.2, random_state: int = 42):\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    model_path = os.path.join(model_dir, f\"random_forest_{today_str}.pkl\")\n",
    "\n",
    "    # Clean up old models\n",
    "    for fname in os.listdir(model_dir):\n",
    "        if fname.startswith(\"random_forest_\") and fname.endswith(\".pkl\"):\n",
    "            os.remove(os.path.join(model_dir, fname))\n",
    "\n",
    "    # Feature engineering\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment'\n",
    "    ]\n",
    "\n",
    "    gold_clean = gold[['Close'] + feature_cols].copy().dropna()\n",
    "    gold_clean['Close_pct_change_1'] = gold_clean['Close'].pct_change(1)\n",
    "    gold_clean['Close_pct_change_2'] = gold_clean['Close'].pct_change(2)\n",
    "    gold_clean['Close_pct_change_3'] = gold_clean['Close'].pct_change(3)\n",
    "    gold_clean['Close_rolling_std_5'] = gold_clean['Close'].rolling(5).std()\n",
    "    gold_clean['Close_rolling_std_10'] = gold_clean['Close'].rolling(10).std()\n",
    "    gold_clean['Close_vs_MA5'] = (gold_clean['Close'] - gold_clean['MA_5']) / gold_clean['MA_5']\n",
    "    gold_clean['Close_vs_MA20'] = (gold_clean['Close'] - gold_clean['MA_20']) / gold_clean['MA_20']\n",
    "    gold_clean['Price_momentum_3'] = gold_clean['Close'] / gold_clean['Close'].shift(3) - 1\n",
    "    gold_clean['Price_momentum_5'] = gold_clean['Close'] / gold_clean['Close'].shift(5) - 1\n",
    "\n",
    "    feature_cols_extended = feature_cols + [\n",
    "        'Close_pct_change_1', 'Close_pct_change_2', 'Close_pct_change_3',\n",
    "        'Close_rolling_std_5', 'Close_rolling_std_10',\n",
    "        'Close_vs_MA5', 'Close_vs_MA20',\n",
    "        'Price_momentum_3', 'Price_momentum_5'\n",
    "    ]\n",
    "\n",
    "    # Prepare target\n",
    "    gold_clean.dropna(inplace=True)\n",
    "    gold_clean['Target_pct_change'] = gold_clean['Close'].pct_change().shift(-1)\n",
    "    gold_clean['Target_price'] = gold_clean['Close'].shift(-1)\n",
    "    gold_clean.dropna(inplace=True)\n",
    "    gold_clean = gold_clean[(np.abs(gold_clean['Target_pct_change']) < 1.0)]\n",
    "\n",
    "    X = gold_clean[feature_cols_extended]\n",
    "    y = gold_clean['Target_pct_change']\n",
    "\n",
    "    # Scaling\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train model\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=200, max_depth=15,\n",
    "        min_samples_split=5, min_samples_leaf=2,\n",
    "        max_features='sqrt', bootstrap=True,\n",
    "        random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print(\" Training new Random Forest model...\")\n",
    "    model.fit(X_scaled, y)\n",
    "\n",
    "    # Save model\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(f\" Model saved to {model_path}\")\n",
    "    return model, model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6bd557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training new Random Forest model...\n",
      " Model saved to Model/RandomForest\\random_forest_2025-06-23.pkl\n"
     ]
    }
   ],
   "source": [
    "#from modules.model_train import train_random_forest_model\n",
    "model, path = train_random_forest_model(gold, model_dir=\"Model/RandomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f6c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class GoldPriceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "\n",
    "def train_lstm_model(gold: pd.DataFrame, model_dir=\"Model/LSTM\", sequence_length=10, epochs=50, batch_size=16, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train and save an LSTM model using gold price data.\n",
    "\n",
    "    Parameters:\n",
    "        gold (pd.DataFrame): Input gold DataFrame with features.\n",
    "        sequence_length (int): Number of past days used for each training sequence.\n",
    "        epochs (int): Training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        lr (float): Learning rate.\n",
    "        model_dir (str): Directory where model will be saved.\n",
    "\n",
    "    Returns:\n",
    "        model (LSTMModel): Trained model.\n",
    "        model_path (str): Path to saved model.\n",
    "    \"\"\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    model_path = os.path.join(model_dir, f\"lstm_{today_str}.pt\")\n",
    "\n",
    "    # Feature selection\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment'\n",
    "    ]\n",
    "\n",
    "    gold = gold[['Close'] + feature_cols].dropna()\n",
    "    gold = gold.asfreq('B')\n",
    "    gold.ffill(inplace=True)\n",
    "    gold['Target'] = gold['Close'].shift(-1)\n",
    "    gold.dropna(inplace=True)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(gold[feature_cols])\n",
    "    y_scaled = scaler.fit_transform(gold[['Target']])\n",
    "\n",
    "    # Sequence creation\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X_scaled) - sequence_length):\n",
    "        X_seq.append(X_scaled[i:i + sequence_length])\n",
    "        y_seq.append(y_scaled[i + sequence_length])\n",
    "\n",
    "    X_seq = np.array(X_seq)\n",
    "    y_seq = np.array(y_seq)\n",
    "\n",
    "    # Model training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTMModel(input_size=X_seq.shape[2]).to(device)\n",
    "\n",
    "    # Remove previous models\n",
    "    for f in os.listdir(model_dir):\n",
    "        if f.startswith(\"lstm_\") and f.endswith(\".pt\"):\n",
    "            os.remove(os.path.join(model_dir, f))\n",
    "\n",
    "    train_ds = GoldPriceDataset(X_seq, y_seq)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xb).squeeze()\n",
    "            loss = criterion(output, yb.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch} - Avg Loss: {total_loss / len(train_dl):.6f}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\" LSTM model saved to: {model_path}\")\n",
    "    return model, model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf50988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Avg Loss: 0.002905\n",
      "Epoch 10 - Avg Loss: 0.000179\n",
      "Epoch 20 - Avg Loss: 0.000151\n",
      "Epoch 30 - Avg Loss: 0.000149\n",
      "Epoch 40 - Avg Loss: 0.000143\n",
      "Epoch 49 - Avg Loss: 0.000134\n",
      " LSTM model saved to: Model/LSTM\\lstm_2025-06-23.pt\n"
     ]
    }
   ],
   "source": [
    "#from modules.model_train import train_lstm_model\n",
    "model, path = train_lstm_model(gold, model_dir=\"Model/LSTM\", sequence_length=10, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
