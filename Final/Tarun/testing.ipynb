{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d18d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script installs all required libraries for data analysis, plotting, LLM workflows, and notebook imports.\n",
    "# Note: The installation command is commented out to prevent accidental execution.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Required Libraries:\n",
    "# pandas: Data manipulation and analysis\n",
    "# numpy: Numerical computations\n",
    "# matplotlib: Data visualization\n",
    "# yfinance: Downloading financial data from Yahoo Finance\n",
    "# langchain: Building LLM-powered applications and chains\n",
    "# import_ipynb: Importing Jupyter notebooks as Python modules\n",
    "# scipy: Scientific computing (e.g., signal processing)\n",
    "# statsmodels: Statistical modeling and time series analysis\n",
    "# xgboost: Gradient boosting for machine learning\n",
    "# selenium: Web scraping and browser automation\n",
    "# webdriver_manager: Managing browser drivers for Selenium\n",
    "# transformers: State-of-the-art NLP models\n",
    "# peft: Parameter-efficient fine-tuning for transformers\n",
    "# accelerate: Optimizing training and inference of models\n",
    "# bitsandbytes: Efficient training of large models with 8-bit optimizers\n",
    "# tensorflow: Deep learning framework\n",
    "# torch: PyTorch deep learning framework\n",
    "# tensorboard: Visualization tool for TensorFlow and PyTorch\n",
    "# scikit-learn: Machine learning library for Python (version 1.6.1)\n",
    "\n",
    "# Install all required libraries\n",
    "#%pip install -U tensorflow pandas torch tensorboard numpy matplotlib yfinance langchain import_ipynb scipy statsmodels xgboost selenium webdriver_manager transformers peft accelerate bitsandbytes\n",
    "#%pip install scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb411c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# -------------------------------------------------------------------------\n",
    "#  LangChain Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import datetime\n",
    "#from langchain.chains import SequentialChain, LLMChain\n",
    "#from langchain.prompts import PromptTemplate\n",
    "#from langchain.llms import OpenAI  # Replace with any LLM provider\n",
    "#from langchain.output_parsers import RegexParser\n",
    "# -------------------------------------------------------------------------\n",
    "# Other Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from torch.utils.data import Dataset\n",
    "import statsmodels.api as sm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "# -------------------------------------------------------------------------\n",
    "#  Custom Imports\n",
    "from modules.modules import SetTransformer, VariableSetDataset\n",
    "from modules.functions import *\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "# Import predict_sentiment from your finbert_finetune_refactored.py\n",
    "#from finbert_finetune_refactored import predict_sentiment\n",
    "# -------------------------------------------------------------------------\n",
    "#  Web Scraping Imports\n",
    "# -------------------------------------------------------------------------\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "# -------------------------------------------------------------------------\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Load Datasets for Time Series Models\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "input_data = f\"{WORKAREA}/Tarun/data/GOLDBEES_ETF_price_data_technical_indicators_sentiment.csv\"\n",
    "df = pd.read_csv(input_data, index_col=0, parse_dates=True)\n",
    "gold_today = df.iloc[[-1]]\n",
    "print(f\"Data \\n\\n{gold_today.head()}\\n\\n\")\n",
    "current_price = gold_today['Close'].values[0]\n",
    "print(f\"Current Gold Price: {current_price}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Load News Data and Predict Sentiment\n",
    "# ---------------------------------------------------------------------------\n",
    "gold_data_plain = f\"{WORKAREA}/Tarun/data/GOLDBEES_ETF_price_data.csv\"\n",
    "news_data_path = f\"{WORKAREA}/Tarun/data/news_data_{today}.csv\"\n",
    "news_data_with_sentiment_path = f'{WORKAREA}/Tarun/data/news_data_with_sentiment_{today}.csv'\n",
    "finbert_model_path = f'{WORKAREA}/Tarun/Model/finbert_best_model_merged'\n",
    "\n",
    "batch_predict_and_update_csv(news_data_path, finbert_model_path, news_data_with_sentiment_path)\n",
    "\n",
    "df_gold = pd.read_csv(gold_data_plain)\n",
    "df_raw = pd.read_csv(news_data_with_sentiment_path)\n",
    "print(f\"Raw Data \\n\\n{df_raw.head()}\\n\\n\")\n",
    "df_processed = preprocess_dataset(df_raw)\n",
    "print(f\"Raw Data \\n\\n{df_raw.head()}\\n\\n\")\n",
    "df_processed = generate_topic_encodings(df_processed)  ## model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "print(f\"Processed Data \\n\\n{df_processed.head()}\\n\\n\")\n",
    "#final_df = add_gold_price_change(df_processed,df_gold)  ## final_df = merged_df[['Date','text','sentiment','topic_encodings','sentiment_combined_encodings','price_percentage_change']].copy()\n",
    "final_df = add_gold_price_change_with_weekend_handling(df_processed,df_gold)\n",
    "print(f\"Final Data \\n\\n{final_df.head()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Tarun] : Replace the file read with values produced by previous members in the chain.\n",
    "\n",
    "#news_llm_model_data = pd.read_pickle('data/combined_dataset_with_price_change.pkl')\n",
    "#print(\"Number of rows in df:\",news_llm_model_data.shape)\n",
    "#news_llm_model_data.head()\n",
    "\n",
    "## Group input data into sets for use in model.\n",
    "#encodings, price_changes, masks = group_into_variable_sets(news_llm_model_data)\n",
    "#print(f\"Encodings shape: {encodings.shape}, Price changes shape: {price_changes.shape}, Masks shape: {masks.shape}\")\n",
    "\n",
    "## Create the dataset\n",
    "#dataset = VariableSetDataset(encodings, price_changes, masks)\n",
    "#print(f\"Dataset {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "confidence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "logits",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "probabilities",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "final_sentiment",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a6ced5e1-55e4-40c0-bffa-b2bc808a6cb9",
       "rows": [
        [
         "0",
         "Test_text",
         "neutral",
         "0.9977",
         "[-2.3928005695343018, 4.305459976196289, -2.5729339122772217]",
         "{'positive': '0.0012', 'neutral': '0.9977', 'negative': '0.0010'}",
         "0.00019953999999999987"
        ],
        [
         "1",
         "Test_text2",
         "neutral",
         "0.9979",
         "[-2.380605697631836, 4.358696460723877, -2.6132867336273193]",
         "{'positive': '0.0012', 'neutral': '0.9979', 'negative': '0.0009'}",
         "0.0002993699999999999"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "      <th>logits</th>\n",
       "      <th>probabilities</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_text</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>[-2.3928005695343018, 4.305459976196289, -2.57...</td>\n",
       "      <td>{'positive': '0.0012', 'neutral': '0.9977', 'n...</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_text2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>[-2.380605697631836, 4.358696460723877, -2.613...</td>\n",
       "      <td>{'positive': '0.0012', 'neutral': '0.9979', 'n...</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text sentiment confidence  \\\n",
       "0   Test_text   neutral     0.9977   \n",
       "1  Test_text2   neutral     0.9979   \n",
       "\n",
       "                                              logits  \\\n",
       "0  [-2.3928005695343018, 4.305459976196289, -2.57...   \n",
       "1  [-2.380605697631836, 4.358696460723877, -2.613...   \n",
       "\n",
       "                                       probabilities  final_sentiment  \n",
       "0  {'positive': '0.0012', 'neutral': '0.9977', 'n...         0.000200  \n",
       "1  {'positive': '0.0012', 'neutral': '0.9979', 'n...         0.000299  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO [Mohan]: Integrate sentiment extraction model here [Done this, please check]\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "#Download the model from here and paste it inside Models/\n",
    "#> https://indianinstituteofscience-my.sharepoint.com/:f:/g/personal/mohanpanakam_iisc_ac_in/Etg-B99_anJCk2jGh4Cy3vABWPLR3brtxxlMZAPxf9kDgQ?e=uGe18T\n",
    "\n",
    "def predict_sentiments(model_path, inp_text):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    results = []\n",
    "    for text in inp_text:\n",
    "        prediction = predict_sentiment(text, model, tokenizer, device)\n",
    "        if prediction:\n",
    "            results.append(prediction)\n",
    "\n",
    "    return results\n",
    "\n",
    "#Quick sanity check\n",
    "inp_text = [\"Test_text\",\"Test_text2\"]\n",
    "result = predict_sentiments(\"Model/finbert_best_model_merged\",inp_text)\n",
    "df = pd.DataFrame(result)\n",
    "df['final_sentiment'] = df.probabilities.apply(lambda x: float(x['positive']) - float(x['negative'])) * df.confidence.astype(float)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Adithya] : Insert Topic extraction model here.\n",
    "def embed_sentences(sentences):\n",
    "    if(type(sentences) == str):\n",
    "        sentences = [sentences]\n",
    "    model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #This is around 1 GB in size, it took a while for me to run this.\n",
    "    embed = hub.load(model_url)\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = embed(sentences)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b2c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adith\\anaconda3\\envs\\DL_project\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adith\\anaconda3\\envs\\DL_project\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adith\\anaconda3\\envs\\DL_project\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adith\\anaconda3\\envs\\DL_project\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512]) torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "#TODO: rename this to get__inputs or somehting like that once scraper is integrated.\n",
    "\n",
    "# 1. Define a function to generate dummy input (replace with real input later)\n",
    "def generate_dummy_news_input(device):\n",
    "\n",
    "    #TODO:This should be replaced with scraping script later.\n",
    "    dummy_input_text = [\"Test input 1\", \"Test_input 2\", \"Test input 3\"]\n",
    "\n",
    "    #Get topic and sentiment\n",
    "    encodings = embed_sentences(dummy_input_text)\n",
    "    raw_sentiments = predict_sentiments(\"Model/finbert_best_model_merged\",dummy_input_text)\n",
    "\n",
    "    #Combine them\n",
    "    sentiment = pd.DataFrame(raw_sentiments)\n",
    "    sentiment['final_sentiment'] = sentiment.probabilities.apply(lambda x: float(x['positive']) - float(x['negative'])) * sentiment.confidence.astype(float)\n",
    "    sentiment['encodings'] = list(encodings)\n",
    "    sentiment['final_encodings'] = sentiment.encodings * sentiment.final_sentiment\n",
    "\n",
    "    #Convert embeddings to required dimension.\n",
    "    encodings = np.array(list(sentiment.final_encodings), dtype=np.float32)\n",
    "    encodings = torch.tensor(encodings.reshape(1,*encodings.shape), dtype=torch.float32).to(device)\n",
    "    # encodings = torch.tensor(np.random.rand(1, 10, 512).astype(np.float32), dtype=torch.float32).to(device)\n",
    "    \n",
    "    #Define placeholder mask\n",
    "    mask = torch.tensor(np.ones((1, len(raw_sentiments))).astype(np.float32), dtype=torch.float32).to(device)\n",
    "\n",
    "    return encodings, mask\n",
    "\n",
    "#Sanity check to make sure function works.\n",
    "enc,msk = generate_dummy_news_input(device)\n",
    "print(enc.shape,msk.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0469a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in testing: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './finbert_best_model_merged'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "def test_model(model_path=\"./finbert_best_model_merged\"):\n",
    "    \"\"\"\n",
    "    Test the trained model on sample texts and print sentiment, logits, and probabilities.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model and tokenizer\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "        # Sample texts for testing\n",
    "        test_texts = [\n",
    "            \"Dec. gold climbs $9.40, or 0.7%, to settle at $1,356.90/oz\",\n",
    "            \"gold prices rebound rs 350 on global cues, weak rupee\",\n",
    "            \"Gold futures down at Rs 30,244 \",\n",
    "            \"gold, oil trade lower as jobs data weigh\"\n",
    "        ]\n",
    "\n",
    "        # Make predictions\n",
    "        results = []\n",
    "        for text in test_texts:\n",
    "            prediction = predict_sentiment(text, model, tokenizer, device)\n",
    "            if prediction:\n",
    "                results.append(prediction)\n",
    "                print(\"\\nText:\", text)\n",
    "                print(\"Sentiment:\", prediction[\"sentiment\"])\n",
    "                print(\"Confidence:\", prediction[\"confidence\"])\n",
    "                print(\"Logits:\", prediction[\"logits\"])\n",
    "                print(\"Class Probabilities:\", prediction[\"probabilities\"])\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in testing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb187aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Time Series Models and get predictions\n",
    "# --------------------------------------------------------------------\n",
    "# Load pre-trained models\n",
    "arimax_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/Arimax/arimax_{today}.pkl')\n",
    "random_forest_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/RandomForest/random_forest_{today}.pkl')\n",
    "xgboost_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/XGBoost/xgboost_{today}.pkl')\n",
    "\n",
    "lstw_model = LSTMModel(input_size=11).to(device)\n",
    "lstw_model.load_state_dict(torch.load(f'{WORKAREA}/Tarun/Model/LSTM/lstm_{today}.pt', map_location=device))\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Predict gold price using all four models with gold_price_prediction where possible\n",
    "\n",
    "# ARIMAX\n",
    "predicted_price_arimax = predict_next_day_gold_price_arimax(df, arimax_model)\n",
    "\n",
    "# Random Forest\n",
    "predicted_price_rf = predict_next_day_gold_price_rf(df, random_forest_model)\n",
    "\n",
    "# XGBoost\n",
    "predicted_price_xgb = predict_next_day_gold_price_xgboost(df, xgboost_model)\n",
    "\n",
    "# LSTM\n",
    "predicted_price_lstw = predict_next_day_gold_price_lstm(df, lstw_model)\n",
    "\n",
    "print(f\"ARIMAX: Predicted gold price for {next_day}: {predicted_price_arimax}\")\n",
    "\n",
    "print(f\"Random Forest: Predicted gold price for {next_day}: {predicted_price_rf}\")\n",
    "\n",
    "print(f\"XGBoost: Predicted gold price for {next_day}: {predicted_price_xgb}\")\n",
    "\n",
    "print(f\"LSTM: Predicted gold price for {next_day}: {predicted_price_lstw}\")\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84264fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved to D:/CAREER/IISC_B/Academics/Courses/SEM_3/DA_225o/Project/DL-7-25/Final/Tarun/data/news_data_with_sentiment_2025-06-23.csv\n",
      "date          object\n",
      "text          object\n",
      "sentiment    float64\n",
      "dtype: object\n",
      "date                object\n",
      "text                object\n",
      "sentiment          float64\n",
      "topic_encodings     object\n",
      "dtype: object\n",
      "---------------------------------------------------\n",
      "Current Gold Price: 82.44999694824219\n",
      "---------------------------------------------------\n",
      "Predictions for next day: 2025-06-24\n",
      "---------------------------------------------------\n",
      "News LLM: Predicted gold price: 95.92861764982422\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Prepare input dictionary for the news LLM chain\n",
    "news_llm_inputs = {\n",
    "    \"device\": device,\n",
    "    \"current_price\": current_price,\n",
    "    \"model_path\": news_model_path,\n",
    "    \"finbert_model\": finbert_model,\n",
    "    \"news_data_csv\": news_data_csv,\n",
    "    \"gold_data_plain_csv\": gold_data_plain_csv,\n",
    "    \"news_data_with_sentiment_csv\": news_data_with_sentiment_csv\n",
    "}\n",
    "\n",
    "news_llm_chain = TransformChain(\n",
    "    input_variables=[\"current_price\", \"device\", \"model_path\", \"finbert_model\", \"news_data_csv\", \"gold_data_plain_csv\", \"news_data_with_sentiment_csv\"],\n",
    "    output_variables=[\"predicted_price_news_llm\"],\n",
    "    transform=news_llm_transform\n",
    ")\n",
    "\n",
    "\n",
    "# Compose the full sequence\n",
    "news_llm_seq_chain = SequentialChain(\n",
    "    chains=[news_llm_chain],\n",
    "    input_variables=[\n",
    "        \"current_price\", \"device\", \"model_path\", \"finbert_model\", \"news_data_csv\", \"gold_data_plain_csv\", \"news_data_with_sentiment_csv\"      \n",
    "    ],\n",
    "    output_variables=[\n",
    "        \"predicted_price_news_llm\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run the news LLM chain sequence\n",
    "news_llm_results = news_llm_seq_chain.invoke(news_llm_inputs)\n",
    "predicted_price_news_llm = news_llm_results[\"predicted_price_news_llm\"]\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Current Gold Price: {current_price}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Predictions for next day: {next_day}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"News LLM: Predicted gold price: {predicted_price_news_llm}\")\n",
    "print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd13ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO [Tarun]: Replace the input data with the actual news data for prediction.\n",
    "# Generate random inputs and masks for testing\n",
    "inputs = np.random.rand(1, 10, 512).astype(np.float32)\n",
    "masks = np.ones((1,10)).astype(np.float32)\n",
    "\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32).to(device=device)\n",
    "masks = torch.tensor(masks, dtype=torch.float32).to(device=device)\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "news_llm_change_precentage = news_model(inputs,mask= masks).item() * 100  # Convert to percentage\n",
    "predicted_price_news_llm = current_price*(1 + news_llm_change_precentage / 100)\n",
    "print(f\"News LLM: Predicted gold price for {next_day}: {predicted_price_news_llm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6569cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained News LLM model & get predictions\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "news_model = SetTransformer(\n",
    "    dim_input = 512, \n",
    "    num_outputs = 1, #One final prediction\n",
    "    dim_output = 1, #1D output for price change\n",
    "    num_inds=32, \n",
    "    dim_hidden=128, \n",
    "    num_heads=4, \n",
    "    ln=True #Layer normalization\n",
    "    ).to(device)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Load the pre-trained model weights\n",
    "checkpoint_path = f'{WORKAREA}/Tarun/Model/final_model.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, start_loss = load_checkpoint(checkpoint_path, news_model, device)\n",
    "    print(f\"Model loaded from {checkpoint_path} at epoch {start_epoch} with loss {start_loss:.4f}\")\n",
    "else:\n",
    "    start_epoch, start_loss = 0, float('inf')\n",
    "    print(f\"No checkpoint found at {checkpoint_path}. Starting from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145adac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/Final_Ensemble/ensemble_model_{today}.pkl')\n",
    "results = predict_next_day_gold_price_ensemble(\n",
    "    ensemble_model,\n",
    "    predicted_price_arimax,\n",
    "    predicted_price_xgb,\n",
    "    predicted_price_rf,\n",
    "    predicted_price_lstw,\n",
    "    predicted_price_news_llm,\n",
    ")\n",
    "\n",
    "print(f\"Ensemble Model Results for {next_day}:\")\n",
    "print(f\"Predicted Price: {results['predictions']['meta_ensemble']}\")\n",
    "print(f\"Percentage Change: {results['percentage_changes']['meta_ensemble']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
