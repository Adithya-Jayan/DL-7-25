{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d18d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script installs all required libraries for data analysis, plotting, LLM workflows, and notebook imports.\n",
    "# Note: The installation command is commented out to prevent accidental execution.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Required Libraries:\n",
    "# pandas: Data manipulation and analysis\n",
    "# numpy: Numerical computations\n",
    "# matplotlib: Data visualization\n",
    "# yfinance: Downloading financial data from Yahoo Finance\n",
    "# langchain: Building LLM-powered applications and chains\n",
    "# import_ipynb: Importing Jupyter notebooks as Python modules\n",
    "# scipy: Scientific computing (e.g., signal processing)\n",
    "# statsmodels: Statistical modeling and time series analysis\n",
    "# xgboost: Gradient boosting for machine learning\n",
    "# selenium: Web scraping and browser automation\n",
    "# webdriver_manager: Managing browser drivers for Selenium\n",
    "# transformers: State-of-the-art NLP models\n",
    "# peft: Parameter-efficient fine-tuning for transformers\n",
    "# accelerate: Optimizing training and inference of models\n",
    "# bitsandbytes: Efficient training of large models with 8-bit optimizers\n",
    "# tensorflow: Deep learning framework\n",
    "# torch: PyTorch deep learning framework\n",
    "# tensorboard: Visualization tool for TensorFlow and PyTorch\n",
    "# scikit-learn: Machine learning library for Python (version 1.6.1)\n",
    "\n",
    "# Install all required libraries\n",
    "#%pip install -U tensorflow pandas torch tensorboard numpy matplotlib yfinance langchain import_ipynb scipy statsmodels xgboost selenium webdriver_manager transformers peft accelerate bitsandbytes\n",
    "#%pip install scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb411c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# -------------------------------------------------------------------------\n",
    "#  LangChain Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import datetime\n",
    "#from langchain.chains import SequentialChain, LLMChain\n",
    "#from langchain.prompts import PromptTemplate\n",
    "#from langchain.llms import OpenAI  # Replace with any LLM provider\n",
    "#from langchain.output_parsers import RegexParser\n",
    "# -------------------------------------------------------------------------\n",
    "# Other Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "from torch.utils.data import Dataset\n",
    "import statsmodels.api as sm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "# -------------------------------------------------------------------------\n",
    "#  Custom Imports\n",
    "from modules.modules import SetTransformer, VariableSetDataset\n",
    "from modules.functions import *\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "# Import predict_sentiment from your finbert_finetune_refactored.py\n",
    "#from finbert_finetune_refactored import predict_sentiment\n",
    "# -------------------------------------------------------------------------\n",
    "#  Web Scraping Imports\n",
    "# -------------------------------------------------------------------------\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "# -------------------------------------------------------------------------\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfd0aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Predict sentiment for a given text using the trained model\n",
    "    Returns: Dictionary containing prediction results including logits\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare model\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            predicted_class = torch.argmax(probs, dim=1)[0].item()\n",
    "\n",
    "        # Map prediction to sentiment\n",
    "        sentiment_map = {0: \"positive\", 1: \"neutral\", 2: \"negative\"}\n",
    "        confidence = probs[0][predicted_class].item()\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"sentiment\": sentiment_map[predicted_class],\n",
    "            \"confidence\": f\"{confidence:.4f}\",\n",
    "            \"logits\": logits[0].cpu().numpy().tolist(),\n",
    "            \"probabilities\": {\n",
    "                \"positive\": f\"{probs[0][0].item():.4f}\",\n",
    "                \"neutral\": f\"{probs[0][1].item():.4f}\",\n",
    "                \"negative\": f\"{probs[0][2].item():.4f}\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0469a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in testing: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './finbert_best_model_merged'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "\n",
    "def test_model(model_path=\"./finbert_best_model_merged\"):\n",
    "    \"\"\"\n",
    "    Test the trained model on sample texts and print sentiment, logits, and probabilities.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model and tokenizer\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "        # Sample texts for testing\n",
    "        test_texts = [\n",
    "            \"Dec. gold climbs $9.40, or 0.7%, to settle at $1,356.90/oz\",\n",
    "            \"gold prices rebound rs 350 on global cues, weak rupee\",\n",
    "            \"Gold futures down at Rs 30,244 \",\n",
    "            \"gold, oil trade lower as jobs data weigh\"\n",
    "        ]\n",
    "\n",
    "        # Make predictions\n",
    "        results = []\n",
    "        for text in test_texts:\n",
    "            prediction = predict_sentiment(text, model, tokenizer, device)\n",
    "            if prediction:\n",
    "                results.append(prediction)\n",
    "                print(\"\\nText:\", text)\n",
    "                print(\"Sentiment:\", prediction[\"sentiment\"])\n",
    "                print(\"Confidence:\", prediction[\"confidence\"])\n",
    "                print(\"Logits:\", prediction[\"logits\"])\n",
    "                print(\"Class Probabilities:\", prediction[\"probabilities\"])\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in testing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
