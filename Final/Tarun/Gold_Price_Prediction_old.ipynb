{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d18d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script installs all required libraries for data analysis, plotting, LLM workflows, and notebook imports.\n",
    "# Note: The installation command is commented out to prevent accidental execution.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Required Libraries:\n",
    "# pandas: Data manipulation and analysis\n",
    "# numpy: Numerical computationsb\n",
    "# matplotlib: Data visualization\n",
    "# yfinance: Downloading financial data from Yahoo Finance\n",
    "# langchain: Building LLM-powered applications and chains\n",
    "# import_ipynb: Importing Jupyter notebooks as Python modules\n",
    "# scipy: Scientific computing (e.g., signal processing)\n",
    "# statsmodels: Statistical modeling and time series analysis\n",
    "# xgboost: Gradient boosting for machine learning\n",
    "# selenium: Web scraping and browser automation\n",
    "# webdriver_manager: Managing browser drivers for Selenium\n",
    "# transformers: State-of-the-art NLP models\n",
    "# peft: Parameter-efficient fine-tuning for transformers\n",
    "# accelerate: Optimizing training and inference of models\n",
    "# bitsandbytes: Efficient training of large models with 8-bit optimizers\n",
    "# tensorflow: Deep learning framework\n",
    "# torch: PyTorch deep learning framework\n",
    "# tensorboard: Visualization tool for TensorFlow and PyTorch\n",
    "# scikit-learn: Machine learning library for Python (version 1.6.1)\n",
    "\n",
    "# Install all required libraries\n",
    "#%pip install -U tensorflow pandas torch tensorboard numpy matplotlib yfinance langchain import_ipynb scipy statsmodels xgboost selenium webdriver_manager transformers peft accelerate bitsandbytes\n",
    "#%pip install scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb411c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# -------------------------------------------------------------------------\n",
    "#  LangChain Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import datetime\n",
    "#from langchain.chains import SequentialChain, LLMChain\n",
    "#from langchain.prompts import PromptTemplate\n",
    "#from langchain.llms import OpenAI  # Replace with any LLM provider\n",
    "#from langchain.output_parsers import RegexParser\n",
    "# -------------------------------------------------------------------------\n",
    "# Other Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "# -------------------------------------------------------------------------\n",
    "#  Custom Imports\n",
    "from modules.modules import SetTransformer, LSTMModel, VariableSetDataset\n",
    "from modules.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83329e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_arimax(df: pd.DataFrame, model) -> float:\n",
    "    \"\"\"\n",
    "    Predict next day's gold price using ARIMAX with technical indicators.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (next_day_price)\n",
    "    \"\"\"\n",
    "    exog_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment',\n",
    "        'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'Momentum_10', 'ROC_10'\n",
    "    ]\n",
    "\n",
    "    for col in exog_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    df = df[['Close'] + exog_cols].dropna()\n",
    "    df = df.asfreq('B')\n",
    "    df.ffill(inplace=True)\n",
    "\n",
    "    y = df['Close']\n",
    "    exog = df[exog_cols]\n",
    "\n",
    "    # -------------------------------\n",
    "    # Forecast Next Price\n",
    "    # -------------------------------\n",
    "    next_exog = exog.iloc[[-1]].values\n",
    "    predicted_price = model.forecast(steps=1, exog=next_exog).iloc[0]\n",
    "\n",
    "    return predicted_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_xgboost(gold: pd.DataFrame, model) -> float:\n",
    "    \"\"\"\n",
    "    Predict next day's gold price using XGBoost with technical indicators.\n",
    "    Returns:\n",
    "        tuple: (next_day_price)\n",
    "    \"\"\"\n",
    "\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment',\n",
    "        'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'Momentum_10', 'ROC_10'\n",
    "    ]\n",
    "\n",
    "    gold_clean = gold[['Close'] + feature_cols].copy().dropna()\n",
    "    gold_clean['Close_pct_change_1'] = gold_clean['Close'].pct_change(1)\n",
    "    gold_clean['Close_pct_change_2'] = gold_clean['Close'].pct_change(2)\n",
    "    gold_clean['Close_pct_change_3'] = gold_clean['Close'].pct_change(3)\n",
    "    gold_clean['Close_rolling_std_5'] = gold_clean['Close'].rolling(5).std()\n",
    "    gold_clean['Close_rolling_std_10'] = gold_clean['Close'].rolling(10).std()\n",
    "    gold_clean['Close_vs_MA5'] = (gold_clean['Close'] - gold_clean['MA_5']) / gold_clean['MA_5']\n",
    "    gold_clean['Close_vs_MA20'] = (gold_clean['Close'] - gold_clean['MA_20']) / gold_clean['MA_20']\n",
    "    feature_cols_extended = feature_cols + [\n",
    "        'Close_pct_change_1', 'Close_pct_change_2', 'Close_pct_change_3',\n",
    "        'Close_rolling_std_5', 'Close_rolling_std_10',\n",
    "        'Close_vs_MA5', 'Close_vs_MA20']\n",
    "    gold_clean = gold_clean.dropna()\n",
    "    gold_clean['Target_pct_change'] = gold_clean['Close'].pct_change().shift(-1)\n",
    "    gold_clean['Target_price'] = gold_clean['Close'].shift(-1)\n",
    "    gold_clean = gold_clean.dropna()\n",
    "    gold_clean = gold_clean[\n",
    "        (np.isfinite(gold_clean['Target_pct_change'])) &\n",
    "        (np.abs(gold_clean['Target_pct_change']) < 1.0)\n",
    "    ]\n",
    "\n",
    "    # Predict next day\n",
    "    latest_features = gold_clean[feature_cols_extended].iloc[[-1]]\n",
    "    latest_price = gold_clean['Close'].iloc[-1]\n",
    "    scaler = RobustScaler().fit(gold_clean[feature_cols_extended])\n",
    "    latest_scaled = scaler.transform(latest_features)\n",
    "    next_day_pct_change = model.predict(latest_scaled)[0]\n",
    "    next_day_price = latest_price * (1 + next_day_pct_change)\n",
    "\n",
    "    return next_day_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_rf(gold: pd.DataFrame, model) -> float:\n",
    "    \"\"\"\n",
    "    Predict next day's gold price using Random Forest with enhanced features.\n",
    "    Saves model daily and loads if already exists. Returns price, model, and percentage change.\n",
    "    \"\"\"\n",
    "\n",
    "    # Feature Engineering\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment'\n",
    "    ]\n",
    "\n",
    "    gold_clean = gold[['Close'] + feature_cols].copy()\n",
    "    gold_clean = gold_clean.dropna()\n",
    "    gold_clean['Close_pct_change_1'] = gold_clean['Close'].pct_change(1)\n",
    "    gold_clean['Close_pct_change_2'] = gold_clean['Close'].pct_change(2)\n",
    "    gold_clean['Close_pct_change_3'] = gold_clean['Close'].pct_change(3)\n",
    "    gold_clean['Close_rolling_std_5'] = gold_clean['Close'].rolling(5).std()\n",
    "    gold_clean['Close_rolling_std_10'] = gold_clean['Close'].rolling(10).std()\n",
    "    gold_clean['Close_vs_MA5'] = (gold_clean['Close'] - gold_clean['MA_5']) / gold_clean['MA_5']\n",
    "    gold_clean['Close_vs_MA20'] = (gold_clean['Close'] - gold_clean['MA_20']) / gold_clean['MA_20']\n",
    "    gold_clean['Price_momentum_3'] = gold_clean['Close'] / gold_clean['Close'].shift(3) - 1\n",
    "    gold_clean['Price_momentum_5'] = gold_clean['Close'] / gold_clean['Close'].shift(5) - 1\n",
    "\n",
    "    feature_cols_extended = feature_cols + [\n",
    "        'Close_pct_change_1', 'Close_pct_change_2', 'Close_pct_change_3',\n",
    "        'Close_rolling_std_5', 'Close_rolling_std_10',\n",
    "        'Close_vs_MA5', 'Close_vs_MA20',\n",
    "        'Price_momentum_3', 'Price_momentum_5']\n",
    "\n",
    "    gold_clean.dropna(inplace=True)\n",
    "    gold_clean['Target_pct_change'] = gold_clean['Close'].pct_change().shift(-1)\n",
    "    gold_clean['Target_price'] = gold_clean['Close'].shift(-1)\n",
    "    gold_clean.dropna(inplace=True)\n",
    "    gold_clean = gold_clean[(np.abs(gold_clean['Target_pct_change']) < 1.0)]\n",
    "\n",
    "    # Predict next day\n",
    "    latest_features = gold_clean[feature_cols_extended].iloc[[-1]]\n",
    "    latest_price = gold_clean['Close'].iloc[-1]\n",
    "    scaler = RobustScaler().fit(gold_clean[feature_cols_extended])\n",
    "    latest_scaled = scaler.transform(latest_features)\n",
    "    next_day_pct_change = model.predict(latest_scaled)[0]\n",
    "    next_day_price = latest_price * (1 + next_day_pct_change)\n",
    "\n",
    "    return next_day_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7aafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_lstm(gold: pd.DataFrame, model=None) -> float:\n",
    "    \n",
    "    sequence_length = 10 ## Based on the model's training sequence length\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Feature Setup\n",
    "    # -------------------------------\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment'\n",
    "    ]\n",
    "\n",
    "    gold = gold[['Close'] + feature_cols].dropna()\n",
    "    gold = gold.asfreq('B')\n",
    "    gold.ffill(inplace=True)\n",
    "    gold['Target'] = gold['Close'].shift(-1)\n",
    "    gold.dropna(inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(gold[feature_cols])\n",
    "    y_scaled = scaler.fit_transform(gold[['Target']])\n",
    "\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X_scaled) - sequence_length):\n",
    "        X_seq.append(X_scaled[i:i + sequence_length])\n",
    "        y_seq.append(y_scaled[i + sequence_length])\n",
    "\n",
    "    X_seq = np.array(X_seq)\n",
    "    y_seq = np.array(y_seq)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Forecast\n",
    "    # -------------------------------\n",
    "    model.eval()\n",
    "    last_seq = torch.tensor(X_scaled[-sequence_length:], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        next_pred = model(last_seq).cpu().numpy()\n",
    "\n",
    "    predicted_price = scaler.inverse_transform(\n",
    "        np.concatenate([np.zeros((1, len(feature_cols))), next_pred], axis=1)\n",
    "    )[:, -1][0]\n",
    "\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_ensemble(\n",
    "    ensemble_model: dict,\n",
    "    arimax_pred: float,\n",
    "    xgb_pred: float,\n",
    "    rf_pred: float,\n",
    "    lstm_pred: float,\n",
    "    llm_pred: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Use a pre-trained ensemble model (results hash) and new predictions to create a results hash.\n",
    "    Only updates the 'individual_predictions' and recalculates all ensemble outputs.\n",
    "    \"\"\"\n",
    "    # Extract weights and metadata from the loaded ensemble model\n",
    "    weights_used = ensemble_model.get('weights_used', {})\n",
    "    meta_weights = weights_used.get('meta_weights', {\n",
    "        'simple': 0.1, 'weighted': 0.25, 'sentiment': 0.2, 'volatility': 0.25, 'trend': 0.2\n",
    "    })\n",
    "    norm_weights = weights_used.get('normalized_weights', {\n",
    "        'arimax': 0.15, 'xgboost': 0.25, 'rf': 0.20, 'lstm': 0.20, 'llm': 0.20\n",
    "    })\n",
    "    vol_weights = weights_used.get('volatility_weights', {\n",
    "        'arimax': 0.25, 'xgboost': 0.20, 'rf': 0.20, 'lstm': 0.15, 'llm': 0.20\n",
    "    })\n",
    "    trend_weights = weights_used.get('trend_weights', {\n",
    "        'arimax': 0.15, 'xgboost': 0.25, 'rf': 0.20, 'lstm': 0.20, 'llm': 0.20\n",
    "    })\n",
    "\n",
    "    # Extract metadata for calculation\n",
    "    metadata = ensemble_model.get('metadata', {})\n",
    "    current_price = metadata.get('current_price', 0)\n",
    "    current_sentiment = metadata.get('current_sentiment', 0)\n",
    "\n",
    "    model_names = ['arimax', 'xgboost', 'rf', 'lstm', 'llm']\n",
    "    model_preds = [arimax_pred, xgb_pred, rf_pred, lstm_pred, llm_pred]\n",
    "\n",
    "    # 1. Simple average\n",
    "    simple_avg = np.mean(model_preds)\n",
    "\n",
    "    # 2. Weighted average (sentiment-boosted)\n",
    "    weighted_avg = sum(norm_weights[k] * p for k, p in zip(model_names, model_preds))\n",
    "\n",
    "    # 3. Sentiment-adjusted\n",
    "    sentiment_factor = 1 + 0.02 * current_sentiment if abs(current_sentiment) > 0.1 else 1.0\n",
    "    sentiment_adjusted = weighted_avg * sentiment_factor\n",
    "\n",
    "    # 4. Volatility-weighted\n",
    "    volatility_weighted = sum(vol_weights[k] * p for k, p in zip(model_names, model_preds))\n",
    "\n",
    "    # 5. Trend-following\n",
    "    trend_following = sum(trend_weights[k] * p for k, p in zip(model_names, model_preds))\n",
    "\n",
    "    # 6. Meta-Ensemble\n",
    "    meta_ensemble = (\n",
    "        meta_weights['simple'] * simple_avg +\n",
    "        meta_weights['weighted'] * weighted_avg +\n",
    "        meta_weights['sentiment'] * sentiment_adjusted +\n",
    "        meta_weights['volatility'] * volatility_weighted +\n",
    "        meta_weights['trend'] * trend_following\n",
    "    )\n",
    "\n",
    "    pct_changes = {\n",
    "        'simple_avg': (simple_avg - current_price) / current_price * 100 if current_price else 0,\n",
    "        'weighted_avg': (weighted_avg - current_price) / current_price * 100 if current_price else 0,\n",
    "        'sentiment_adjusted': (sentiment_adjusted - current_price) / current_price * 100 if current_price else 0,\n",
    "        'volatility_weighted': (volatility_weighted - current_price) / current_price * 100 if current_price else 0,\n",
    "        'trend_following': (trend_following - current_price) / current_price * 100 if current_price else 0,\n",
    "        'meta_ensemble': (meta_ensemble - current_price) / current_price * 100 if current_price else 0\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        'predictions': {\n",
    "            'simple_average': simple_avg,\n",
    "            'weighted_average': weighted_avg,\n",
    "            'sentiment_adjusted': sentiment_adjusted,\n",
    "            'volatility_weighted': volatility_weighted,\n",
    "            'trend_following': trend_following,\n",
    "            'meta_ensemble': meta_ensemble\n",
    "        },\n",
    "        'percentage_changes': pct_changes,\n",
    "        'weights_used': weights_used,\n",
    "        'metadata': metadata,\n",
    "        'model_info': {\n",
    "            **ensemble_model.get('model_info', {}),\n",
    "            'created_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'individual_predictions': {\n",
    "                'arimax': arimax_pred,\n",
    "                'xgboost': xgb_pred,\n",
    "                'random_forest': rf_pred,\n",
    "                'lstm': lstm_pred,\n",
    "                'llm': llm_pred\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Yaswanth] : Replace this with today's news articles scraping.\n",
    "\n",
    "def extract_news_data(local_news=False):\n",
    "    bullion_df = get_latest_bullionvault_articles()\n",
    "    yf_df=get_latest_yf_articles()\n",
    "    yf_df['Date']=pd.to_datetime(yf_df['Date'],errors='coerce').dt.date\n",
    "    reuters_df = get_reuters_articles()\n",
    "    df_list_for_concatenation = [bullion_df, yf_df, reuters_df]\n",
    "    if local_news:\n",
    "        telugu_news_df=fetch_bbc_telugu_news()\n",
    "        df_list_for_concatenation.append(telugu_news_df)\n",
    "    \n",
    "    three_days_ago = pd.to_datetime('today').date() - timedelta(days=3)\n",
    "\n",
    "    df_combined = pd.concat(df_list_for_concatenation, ignore_index=True)\n",
    "    df_combined = df_combined.sort_values(by='Date')\n",
    "    df_combined=df_combined[df_combined['Date'] >= three_days_ago]\n",
    "    return df_combined\n",
    "\n",
    "## TODO [Tejashwini] : cleaning script for scraped news data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Adithya] : Insert Topic extraction model here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9553db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKAREA = os.getenv(\"WORKAREA\", \"D:/CAREER/IISC_B/Academics/Courses\\SEM_3\\DA_225o\\Project\\DL-7-25\\Final\")\n",
    "# =========================================================================\n",
    "# Get today's date and the next day in YYYY-MM-DD format\n",
    "# =========================================================================\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "next_day = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "print(f\"Today's date: {today}\")\n",
    "print(f\"Next day's date: {next_day}\")\n",
    "\n",
    "start = datetime(2010, 1, 1)\n",
    "end = datetime(2026, 1, 1)\n",
    "gold = generate_sentiment_from_trend_with_labels(add_technical_indicators(download_gold_prices(start, end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ac798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Load Datasets for Time Series Models\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "input_data = f\"{WORKAREA}/Tarun/data/GOLDBEES_ETF_price_data_technical_indicators_sentiment.csv\"\n",
    "df = pd.read_csv(input_data, index_col=0, parse_dates=True)\n",
    "gold_today = df.iloc[[-1]]\n",
    "print(f\"Data \\n\\n{gold_today.head()}\\n\\n\")\n",
    "current_price = gold_today['Close'].values[0]\n",
    "print(f\"Current Gold Price: {current_price}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Load News Data and Predict Sentiment\n",
    "# ---------------------------------------------------------------------------\n",
    "gold_data_plain = f\"{WORKAREA}/Tarun/data/GOLDBEES_ETF_price_data.csv\"\n",
    "news_data_path = f\"{WORKAREA}/Tarun/data/news_data_{today}.csv\"\n",
    "news_data_with_sentiment_path = f'{WORKAREA}/Tarun/data/news_data_with_sentiment_{today}.csv'\n",
    "finbert_model_path = f'{WORKAREA}/Tarun/Model/finbert_best_model_merged'\n",
    "\n",
    "batch_predict_and_update_csv(news_data_path, finbert_model_path, news_data_with_sentiment_path)\n",
    "\n",
    "df_gold = pd.read_csv(gold_data_plain)\n",
    "df_raw = pd.read_csv(news_data_with_sentiment_path)\n",
    "print(f\"Raw Data \\n\\n{df_raw.head()}\\n\\n\")\n",
    "df_processed = preprocess_dataset(df_raw)\n",
    "print(f\"Raw Data \\n\\n{df_raw.head()}\\n\\n\")\n",
    "df_processed = generate_topic_encodings(df_processed)  ## model_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "print(f\"Processed Data \\n\\n{df_processed.head()}\\n\\n\")\n",
    "#final_df = add_gold_price_change(df_processed,df_gold)  ## final_df = merged_df[['Date','text','sentiment','topic_encodings','sentiment_combined_encodings','price_percentage_change']].copy()\n",
    "final_df = add_gold_price_change_with_weekend_handling(df_processed,df_gold)\n",
    "print(f\"Final Data \\n\\n{final_df.head()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4881c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Mohan]: Integrate sentiment extraction model here\n",
    "# UI Based inputs + \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Tarun] : Replace the file read with values produced by previous members in the chain.\n",
    "\n",
    "#news_llm_model_data = pd.read_pickle('data/combined_dataset_with_price_change.pkl')\n",
    "#print(\"Number of rows in df:\",news_llm_model_data.shape)\n",
    "#news_llm_model_data.head()\n",
    "\n",
    "## Group input data into sets for use in model.\n",
    "#encodings, price_changes, masks = group_into_variable_sets(news_llm_model_data)\n",
    "#print(f\"Encodings shape: {encodings.shape}, Price changes shape: {price_changes.shape}, Masks shape: {masks.shape}\")\n",
    "\n",
    "## Create the dataset\n",
    "#dataset = VariableSetDataset(encodings, price_changes, masks)\n",
    "#print(f\"Dataset {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f47182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3460e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Time Series Models and get predictions\n",
    "# --------------------------------------------------------------------\n",
    "# Load pre-trained models\n",
    "arimax_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/Arimax/arimax_{today}.pkl')\n",
    "random_forest_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/RandomForest/random_forest_{today}.pkl')\n",
    "xgboost_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/XGBoost/xgboost_{today}.pkl')\n",
    "\n",
    "lstw_model = LSTMModel(input_size=11).to(device)\n",
    "lstw_model.load_state_dict(torch.load(f'{WORKAREA}/Tarun/Model/LSTM/lstm_{today}.pt', map_location=device))\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Predict gold price using all four models with gold_price_prediction where possible\n",
    "\n",
    "# ARIMAX\n",
    "predicted_price_arimax = predict_next_day_gold_price_arimax(df, arimax_model)\n",
    "\n",
    "# Random Forest\n",
    "predicted_price_rf = predict_next_day_gold_price_rf(df, random_forest_model)\n",
    "\n",
    "# XGBoost\n",
    "predicted_price_xgb = predict_next_day_gold_price_xgboost(df, xgboost_model)\n",
    "\n",
    "# LSTM\n",
    "predicted_price_lstw = predict_next_day_gold_price_lstm(df, lstw_model)\n",
    "\n",
    "print(f\"ARIMAX: Predicted gold price for {next_day}: {predicted_price_arimax}\")\n",
    "\n",
    "print(f\"Random Forest: Predicted gold price for {next_day}: {predicted_price_rf}\")\n",
    "\n",
    "print(f\"XGBoost: Predicted gold price for {next_day}: {predicted_price_xgb}\")\n",
    "\n",
    "print(f\"LSTM: Predicted gold price for {next_day}: {predicted_price_lstw}\")\n",
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained News LLM model & get predictions\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "news_model = SetTransformer(\n",
    "    dim_input = 512, \n",
    "    num_outputs = 1, #One final prediction\n",
    "    dim_output = 1, #1D output for price change\n",
    "    num_inds=32, \n",
    "    dim_hidden=128, \n",
    "    num_heads=4, \n",
    "    ln=True #Layer normalization\n",
    "    ).to(device)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Load the pre-trained model weights\n",
    "checkpoint_path = f'{WORKAREA}/Tarun/Model/final_model.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, start_loss = load_checkpoint(checkpoint_path, news_model, device)\n",
    "    print(f\"Model loaded from {checkpoint_path} at epoch {start_epoch} with loss {start_loss:.4f}\")\n",
    "else:\n",
    "    start_epoch, start_loss = 0, float('inf')\n",
    "    print(f\"No checkpoint found at {checkpoint_path}. Starting from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2cd95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO [Tarun]: Replace the input data with the actual news data for prediction.\n",
    "# Generate random inputs and masks for testing\n",
    "inputs = np.random.rand(1, 10, 512).astype(np.float32)\n",
    "masks = np.ones((1,10)).astype(np.float32)\n",
    "\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32).to(device=device)\n",
    "masks = torch.tensor(masks, dtype=torch.float32).to(device=device)\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "news_llm_change_precentage = news_model(inputs,mask= masks).item() * 100  # Convert to percentage\n",
    "predicted_price_news_llm = current_price*(1 + news_llm_change_precentage / 100)\n",
    "print(f\"News LLM: Predicted gold price for {next_day}: {predicted_price_news_llm:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005714ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = sm.load_pickle(f'{WORKAREA}/Tarun/Model/Final_Ensemble/ensemble_model_{today}.pkl')\n",
    "results = predict_next_day_gold_price_ensemble(\n",
    "    ensemble_model,\n",
    "    predicted_price_arimax,\n",
    "    predicted_price_xgb,\n",
    "    predicted_price_rf,\n",
    "    predicted_price_lstw,\n",
    "    predicted_price_news_llm,\n",
    ")\n",
    "\n",
    "print(f\"Ensemble Model Results for {next_day}:\")\n",
    "print(f\"Predicted Price: {results['predictions']['meta_ensemble']}\")\n",
    "print(f\"Percentage Change: {results['percentage_changes']['meta_ensemble']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
