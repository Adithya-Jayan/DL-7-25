{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d18d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script installs all required libraries for data analysis, plotting, LLM workflows, and notebook imports.\n",
    "# Note: The installation command is commented out to prevent accidental execution.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Required Libraries:\n",
    "# pandas: Data manipulation and analysis\n",
    "# numpy: Numerical computations\n",
    "# matplotlib: Data visualization\n",
    "# yfinance: Downloading financial data from Yahoo Finance\n",
    "# langchain: Building LLM-powered applications and chains\n",
    "# import_ipynb: Importing Jupyter notebooks as Python modules\n",
    "# scipy: Scientific computing (e.g., signal processing)\n",
    "# statsmodels: Statistical modeling and time series analysis\n",
    "# xgboost: Gradient boosting for machine learning\n",
    "# selenium: Web scraping and browser automation\n",
    "# webdriver_manager: Managing browser drivers for Selenium\n",
    "# transformers: State-of-the-art NLP models\n",
    "# peft: Parameter-efficient fine-tuning for transformers\n",
    "# accelerate: Optimizing training and inference of models\n",
    "# bitsandbytes: Efficient training of large models with 8-bit optimizers\n",
    "# tensorflow: Deep learning framework\n",
    "# torch: PyTorch deep learning framework\n",
    "# tensorboard: Visualization tool for TensorFlow and PyTorch\n",
    "# scikit-learn: Machine learning library for Python (version 1.6.1)\n",
    "\n",
    "# Install all required libraries\n",
    "#%pip install -U tensorflow pandas torch tensorboard numpy matplotlib yfinance langchain import_ipynb scipy statsmodels xgboost selenium webdriver_manager transformers peft accelerate bitsandbytes\n",
    "#%pip install scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb411c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# -------------------------------------------------------------------------\n",
    "#  LangChain Imports\n",
    "# -------------------------------------------------------------------------\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain, TransformChain\n",
    "# -------------------------------------------------------------------------\n",
    "# Other Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "# -------------------------------------------------------------------------\n",
    "#  Custom Imports\n",
    "from modules.modules import SetTransformer, LSTMModel, VariableSetDataset\n",
    "from modules.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef519f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2025-06-23\n",
      "Next day's date: 2025-06-24\n"
     ]
    }
   ],
   "source": [
    "WORKAREA = os.getenv(\"WORKAREA\", \"D:/CAREER/IISC_B/Academics/Courses\\SEM_3\\DA_225o\\Project\\DL-7-25\\Final\")\n",
    "# =========================================================================\n",
    "# Get today's date and the next day in YYYY-MM-DD format\n",
    "# =========================================================================\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "next_day = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "print(f\"Today's date: {today}\")\n",
    "print(f\"Next day's date: {next_day}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83329e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_arimax(df: pd.DataFrame, model) -> float:\n",
    "    \"\"\"\n",
    "    Predict next day's gold price using ARIMAX with technical indicators.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (next_day_price)\n",
    "    \"\"\"\n",
    "    exog_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment',\n",
    "        'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'Momentum_10', 'ROC_10'\n",
    "    ]\n",
    "\n",
    "    for col in exog_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    df = df[['Close'] + exog_cols].dropna()\n",
    "    df = df.asfreq('B')\n",
    "    df.ffill(inplace=True)\n",
    "\n",
    "    y = df['Close']\n",
    "    exog = df[exog_cols]\n",
    "\n",
    "    # -------------------------------\n",
    "    # Forecast Next Price\n",
    "    # -------------------------------\n",
    "    next_exog = exog.iloc[[-1]].values\n",
    "    predicted_price = model.forecast(steps=1, exog=next_exog).iloc[0]\n",
    "\n",
    "    return predicted_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbfe291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_xgboost(gold: pd.DataFrame, model) -> float:\n",
    "    \"\"\"\n",
    "    Predict next day's gold price using XGBoost with technical indicators.\n",
    "    Returns:\n",
    "        tuple: (next_day_price)\n",
    "    \"\"\"\n",
    "\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment',\n",
    "        'MACD', 'MACD_Signal', 'MACD_Hist',\n",
    "        'Momentum_10', 'ROC_10'\n",
    "    ]\n",
    "\n",
    "    gold_clean = gold[['Close'] + feature_cols].copy().dropna()\n",
    "    gold_clean['Close_pct_change_1'] = gold_clean['Close'].pct_change(1)\n",
    "    gold_clean['Close_pct_change_2'] = gold_clean['Close'].pct_change(2)\n",
    "    gold_clean['Close_pct_change_3'] = gold_clean['Close'].pct_change(3)\n",
    "    gold_clean['Close_rolling_std_5'] = gold_clean['Close'].rolling(5).std()\n",
    "    gold_clean['Close_rolling_std_10'] = gold_clean['Close'].rolling(10).std()\n",
    "    gold_clean['Close_vs_MA5'] = (gold_clean['Close'] - gold_clean['MA_5']) / gold_clean['MA_5']\n",
    "    gold_clean['Close_vs_MA20'] = (gold_clean['Close'] - gold_clean['MA_20']) / gold_clean['MA_20']\n",
    "    feature_cols_extended = feature_cols + [\n",
    "        'Close_pct_change_1', 'Close_pct_change_2', 'Close_pct_change_3',\n",
    "        'Close_rolling_std_5', 'Close_rolling_std_10',\n",
    "        'Close_vs_MA5', 'Close_vs_MA20']\n",
    "    gold_clean = gold_clean.dropna()\n",
    "    gold_clean['Target_pct_change'] = gold_clean['Close'].pct_change().shift(-1)\n",
    "    gold_clean['Target_price'] = gold_clean['Close'].shift(-1)\n",
    "    gold_clean = gold_clean.dropna()\n",
    "    gold_clean = gold_clean[\n",
    "        (np.isfinite(gold_clean['Target_pct_change'])) &\n",
    "        (np.abs(gold_clean['Target_pct_change']) < 1.0)\n",
    "    ]\n",
    "\n",
    "    # Predict next day\n",
    "    latest_features = gold_clean[feature_cols_extended].iloc[[-1]]\n",
    "    latest_price = gold_clean['Close'].iloc[-1]\n",
    "    scaler = RobustScaler().fit(gold_clean[feature_cols_extended])\n",
    "    latest_scaled = scaler.transform(latest_features)\n",
    "    next_day_pct_change = model.predict(latest_scaled)[0]\n",
    "    next_day_price = latest_price * (1 + next_day_pct_change)\n",
    "\n",
    "    return next_day_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e40ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_rf(gold: pd.DataFrame, model) -> float:\n",
    "    \"\"\"\n",
    "    Predict next day's gold price using Random Forest with enhanced features.\n",
    "    Saves model daily and loads if already exists. Returns price, model, and percentage change.\n",
    "    \"\"\"\n",
    "\n",
    "    # Feature Engineering\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment'\n",
    "    ]\n",
    "\n",
    "    gold_clean = gold[['Close'] + feature_cols].copy()\n",
    "    gold_clean = gold_clean.dropna()\n",
    "    gold_clean['Close_pct_change_1'] = gold_clean['Close'].pct_change(1)\n",
    "    gold_clean['Close_pct_change_2'] = gold_clean['Close'].pct_change(2)\n",
    "    gold_clean['Close_pct_change_3'] = gold_clean['Close'].pct_change(3)\n",
    "    gold_clean['Close_rolling_std_5'] = gold_clean['Close'].rolling(5).std()\n",
    "    gold_clean['Close_rolling_std_10'] = gold_clean['Close'].rolling(10).std()\n",
    "    gold_clean['Close_vs_MA5'] = (gold_clean['Close'] - gold_clean['MA_5']) / gold_clean['MA_5']\n",
    "    gold_clean['Close_vs_MA20'] = (gold_clean['Close'] - gold_clean['MA_20']) / gold_clean['MA_20']\n",
    "    gold_clean['Price_momentum_3'] = gold_clean['Close'] / gold_clean['Close'].shift(3) - 1\n",
    "    gold_clean['Price_momentum_5'] = gold_clean['Close'] / gold_clean['Close'].shift(5) - 1\n",
    "\n",
    "    feature_cols_extended = feature_cols + [\n",
    "        'Close_pct_change_1', 'Close_pct_change_2', 'Close_pct_change_3',\n",
    "        'Close_rolling_std_5', 'Close_rolling_std_10',\n",
    "        'Close_vs_MA5', 'Close_vs_MA20',\n",
    "        'Price_momentum_3', 'Price_momentum_5']\n",
    "\n",
    "    gold_clean.dropna(inplace=True)\n",
    "    gold_clean['Target_pct_change'] = gold_clean['Close'].pct_change().shift(-1)\n",
    "    gold_clean['Target_price'] = gold_clean['Close'].shift(-1)\n",
    "    gold_clean.dropna(inplace=True)\n",
    "    gold_clean = gold_clean[(np.abs(gold_clean['Target_pct_change']) < 1.0)]\n",
    "\n",
    "    # Predict next day\n",
    "    latest_features = gold_clean[feature_cols_extended].iloc[[-1]]\n",
    "    latest_price = gold_clean['Close'].iloc[-1]\n",
    "    scaler = RobustScaler().fit(gold_clean[feature_cols_extended])\n",
    "    latest_scaled = scaler.transform(latest_features)\n",
    "    next_day_pct_change = model.predict(latest_scaled)[0]\n",
    "    next_day_price = latest_price * (1 + next_day_pct_change)\n",
    "\n",
    "    return next_day_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7aafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_lstm(gold: pd.DataFrame, model=None) -> float:\n",
    "    \n",
    "    sequence_length = 10 ## Based on the model's training sequence length\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Feature Setup\n",
    "    # -------------------------------\n",
    "    feature_cols = [\n",
    "        'Returns', 'MA_5', 'MA_20', 'MA_50', 'Volatility',\n",
    "        'RSI', 'BB_upper', 'BB_lower', 'BB_width',\n",
    "        'BB_position', 'Sentiment'\n",
    "    ]\n",
    "\n",
    "    gold = gold[['Close'] + feature_cols].dropna()\n",
    "    gold = gold.asfreq('B')\n",
    "    gold.ffill(inplace=True)\n",
    "    gold['Target'] = gold['Close'].shift(-1)\n",
    "    gold.dropna(inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(gold[feature_cols])\n",
    "    y_scaled = scaler.fit_transform(gold[['Target']])\n",
    "\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X_scaled) - sequence_length):\n",
    "        X_seq.append(X_scaled[i:i + sequence_length])\n",
    "        y_seq.append(y_scaled[i + sequence_length])\n",
    "\n",
    "    X_seq = np.array(X_seq)\n",
    "    y_seq = np.array(y_seq)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Forecast\n",
    "    # -------------------------------\n",
    "    model.eval()\n",
    "    last_seq = torch.tensor(X_scaled[-sequence_length:], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        next_pred = model(last_seq).cpu().numpy()\n",
    "\n",
    "    predicted_price = scaler.inverse_transform(\n",
    "        np.concatenate([np.zeros((1, len(feature_cols))), next_pred], axis=1)\n",
    "    )[:, -1][0]\n",
    "\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fc48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_gold_price_ensemble(\n",
    "    ensemble_model: dict,\n",
    "    arimax_pred: float,\n",
    "    xgb_pred: float,\n",
    "    rf_pred: float,\n",
    "    lstm_pred: float,\n",
    "    llm_pred: float\n",
    "):\n",
    "    \"\"\"\n",
    "    Use a pre-trained ensemble model (results hash) and new predictions to create a results hash.\n",
    "    Only updates the 'individual_predictions' and recalculates all ensemble outputs.\n",
    "    \"\"\"\n",
    "    # Extract weights and metadata from the loaded ensemble model\n",
    "    weights_used = ensemble_model.get('weights_used', {})\n",
    "    meta_weights = weights_used.get('meta_weights', {\n",
    "        'simple': 0.1, 'weighted': 0.25, 'sentiment': 0.2, 'volatility': 0.25, 'trend': 0.2\n",
    "    })\n",
    "    norm_weights = weights_used.get('normalized_weights', {\n",
    "        'arimax': 0.15, 'xgboost': 0.25, 'rf': 0.20, 'lstm': 0.20, 'llm': 0.20\n",
    "    })\n",
    "    vol_weights = weights_used.get('volatility_weights', {\n",
    "        'arimax': 0.25, 'xgboost': 0.20, 'rf': 0.20, 'lstm': 0.15, 'llm': 0.20\n",
    "    })\n",
    "    trend_weights = weights_used.get('trend_weights', {\n",
    "        'arimax': 0.15, 'xgboost': 0.25, 'rf': 0.20, 'lstm': 0.20, 'llm': 0.20\n",
    "    })\n",
    "\n",
    "    # Extract metadata for calculation\n",
    "    metadata = ensemble_model.get('metadata', {})\n",
    "    current_price = metadata.get('current_price', 0)\n",
    "    current_sentiment = metadata.get('current_sentiment', 0)\n",
    "\n",
    "    model_names = ['arimax', 'xgboost', 'rf', 'lstm', 'llm']\n",
    "    model_preds = [arimax_pred, xgb_pred, rf_pred, lstm_pred, llm_pred]\n",
    "\n",
    "    # 1. Simple average\n",
    "    simple_avg = np.mean(model_preds)\n",
    "\n",
    "    # 2. Weighted average (sentiment-boosted)\n",
    "    weighted_avg = sum(norm_weights[k] * p for k, p in zip(model_names, model_preds))\n",
    "\n",
    "    # 3. Sentiment-adjusted\n",
    "    sentiment_factor = 1 + 0.02 * current_sentiment if abs(current_sentiment) > 0.1 else 1.0\n",
    "    sentiment_adjusted = weighted_avg * sentiment_factor\n",
    "\n",
    "    # 4. Volatility-weighted\n",
    "    volatility_weighted = sum(vol_weights[k] * p for k, p in zip(model_names, model_preds))\n",
    "\n",
    "    # 5. Trend-following\n",
    "    trend_following = sum(trend_weights[k] * p for k, p in zip(model_names, model_preds))\n",
    "\n",
    "    # 6. Meta-Ensemble\n",
    "    meta_ensemble = (\n",
    "        meta_weights['simple'] * simple_avg +\n",
    "        meta_weights['weighted'] * weighted_avg +\n",
    "        meta_weights['sentiment'] * sentiment_adjusted +\n",
    "        meta_weights['volatility'] * volatility_weighted +\n",
    "        meta_weights['trend'] * trend_following\n",
    "    )\n",
    "\n",
    "    pct_changes = {\n",
    "        'simple_avg': (simple_avg - current_price) / current_price * 100 if current_price else 0,\n",
    "        'weighted_avg': (weighted_avg - current_price) / current_price * 100 if current_price else 0,\n",
    "        'sentiment_adjusted': (sentiment_adjusted - current_price) / current_price * 100 if current_price else 0,\n",
    "        'volatility_weighted': (volatility_weighted - current_price) / current_price * 100 if current_price else 0,\n",
    "        'trend_following': (trend_following - current_price) / current_price * 100 if current_price else 0,\n",
    "        'meta_ensemble': (meta_ensemble - current_price) / current_price * 100 if current_price else 0\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        'predictions': {\n",
    "            'simple_average': simple_avg,\n",
    "            'weighted_average': weighted_avg,\n",
    "            'sentiment_adjusted': sentiment_adjusted,\n",
    "            'volatility_weighted': volatility_weighted,\n",
    "            'trend_following': trend_following,\n",
    "            'meta_ensemble': meta_ensemble\n",
    "        },\n",
    "        'percentage_changes': pct_changes,\n",
    "        'weights_used': weights_used,\n",
    "        'metadata': metadata,\n",
    "        'model_info': {\n",
    "            **ensemble_model.get('model_info', {}),\n",
    "            'created_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'individual_predictions': {\n",
    "                'arimax': arimax_pred,\n",
    "                'xgboost': xgb_pred,\n",
    "                'random_forest': rf_pred,\n",
    "                'lstm': lstm_pred,\n",
    "                'llm': llm_pred\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "543b1a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Gold Price: 82.2300033569336\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "start = datetime(2010, 1, 1)\n",
    "end = datetime(2026, 1, 1)\n",
    "\n",
    "# Download gold prices\n",
    "gold_prices_csv = os.path.join(WORKAREA, \"Tarun/data/GOLDBEES_ETF_price_data_technical_indicators_sentiment.csv\")\n",
    "if os.path.exists(gold_prices_csv):\n",
    "    gold = pd.read_csv(gold_prices_csv, parse_dates=['Date'], index_col='Date')\n",
    "else:\n",
    "    gold = generate_sentiment_from_trend_with_labels(add_technical_indicators(download_gold_prices(start, end)))\n",
    "\n",
    "current_price = gold['Close'].iloc[-1]\n",
    "print(f\"Current Gold Price: {current_price}\")\n",
    "\n",
    "# Prepare input dictionary (ensure these variables are defined in your notebook)\n",
    "# --------------------------------------------------------------------\n",
    "# Load pre-trained models\n",
    "# --------------------------------------------------------------------\n",
    "# # Get device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "lstw_model           = LSTMModel(input_size=11).to(device)\n",
    "lstw_model.load_state_dict(torch.load(f'{WORKAREA}/Jaison/Main_Code/Model/LSTM/lstm_{today}.pt', map_location=device))\n",
    "arimax_model         = sm.load_pickle(f'{WORKAREA}/Jaison/Main_Code/Model/Arimax/arimax_{today}.pkl')\n",
    "random_forest_model  = sm.load_pickle(f'{WORKAREA}/Jaison/Main_Code/Model/RandomForest/random_forest_{today}.pkl')\n",
    "xgboost_model        = sm.load_pickle(f'{WORKAREA}/Jaison/Main_Code/Model/XGBoost/xgboost_{today}.pkl')\n",
    "ensemble_model       = sm.load_pickle(f'{WORKAREA}/Tarun/Model/Final_Ensemble/ensemble_model_{today}.pkl')\n",
    "news_model_path           = os.path.join(WORKAREA, \"/Tarun/Model/final_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c01de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Yaswanth] : Replace this with today's news articles scraping.\n",
    "\n",
    "## TODO [Tejashwini] : cleaning script for scraped news data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4881c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Mohan]: Integrate sentiment extraction model here\n",
    "# UI Based inputs + \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Adithya] : Insert Topic extraction model here.\n",
    "\n",
    "\n",
    "# 2. Define a function to generate dummy input (replace with real input later)\n",
    "def generate_dummy_news_input(device):\n",
    "    encodings = torch.tensor(np.random.rand(1, 10, 512).astype(np.float32), dtype=torch.float32).to(device)\n",
    "    mask = torch.tensor(np.ones((1, 10)).astype(np.float32), dtype=torch.float32).to(device)\n",
    "    return encodings, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define a function to load the SetTransformer model and weights\n",
    "def load_news_llm_model( device, model_path):\n",
    "    news_model = SetTransformer(\n",
    "        dim_input=512,\n",
    "        num_outputs=1,\n",
    "        dim_output=1,\n",
    "        num_inds=32,\n",
    "        dim_hidden=128,\n",
    "        num_heads=4,\n",
    "        ln=True\n",
    "    ).to(device)\n",
    "    if os.path.exists(model_path):\n",
    "        news_model, _ = load_checkpoint(model_path, news_model, device)\n",
    "    return news_model\n",
    "\n",
    "# 3. Define the transform function for the TransformChain\n",
    "def news_llm_transform(inputs):\n",
    "    news_model = load_news_llm_model(inputs[\"device\"],inputs[\"model_path\"])\n",
    "    encodings, mask = generate_dummy_news_input(inputs[\"device\"])\n",
    "    with torch.no_grad():\n",
    "        pred = news_model(encodings, mask=mask)\n",
    "        if hasattr(pred, \"item\"):\n",
    "            pred = pred.item()\n",
    "    predicted_price = inputs[\"current_price\"] * (1 + pred)\n",
    "    return {\"predicted_price_news_llm\": predicted_price}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "005714ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Current Gold Price: 82.2300033569336\n",
      "---------------------------------------------------\n",
      "Predictions for next day: 2025-06-24\n",
      "---------------------------------------------------\n",
      "ARIMAX: Predicted gold price: 82.31355078193063\n",
      "Random Forest: Predicted gold price: 82.63219047144733\n",
      "XGBoost: Predicted gold price: 83.17499557521478\n",
      "LSTM: Predicted gold price: 81.82770381879871\n",
      "News LLM: Predicted gold price: 78.56566835144264\n",
      "---------------------------------------------------\n",
      "Ensemble Model Results:\n",
      "---------------------------------------------------\n",
      "Predicted Price: 88.95519132780538\n",
      "Percentage Change: 8.18%\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain, TransformChain\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Define prompt templates for each model prediction step\n",
    "# Define TransformChains for each model prediction step using the existing functions\n",
    "arimax_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"arimax_model\"],\n",
    "    output_variables=[\"predicted_price_arimax\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_arimax\": predict_next_day_gold_price_arimax(inputs[\"df\"], inputs[\"arimax_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "rf_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"random_forest_model\"],\n",
    "    output_variables=[\"predicted_price_rf\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_rf\": predict_next_day_gold_price_rf(inputs[\"df\"], inputs[\"random_forest_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"xgboost_model\"],\n",
    "    output_variables=[\"predicted_price_xgb\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_xgb\": predict_next_day_gold_price_xgboost(inputs[\"df\"], inputs[\"xgboost_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "lstm_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"lstw_model\"],\n",
    "    output_variables=[\"predicted_price_lstw\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_lstw\": predict_next_day_gold_price_lstm(inputs[\"df\"], inputs[\"lstw_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "news_llm_chain = TransformChain(\n",
    "    input_variables=[\"current_price\", \"device\", \"model_path\"],\n",
    "    output_variables=[\"predicted_price_news_llm\"],\n",
    "    transform=news_llm_transform\n",
    ")\n",
    "\n",
    "# Define the ensemble prediction as a TransformChain\n",
    "ensemble_chain = TransformChain(\n",
    "    input_variables=[\n",
    "        \"ensemble_model\",\n",
    "        \"predicted_price_arimax\",\n",
    "        \"predicted_price_xgb\",\n",
    "        \"predicted_price_rf\",\n",
    "        \"predicted_price_lstw\",\n",
    "        \"predicted_price_news_llm\"\n",
    "    ],\n",
    "    output_variables=[\"ensemble_results\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"ensemble_results\": predict_next_day_gold_price_ensemble(\n",
    "            inputs[\"ensemble_model\"],\n",
    "            inputs[\"predicted_price_arimax\"],\n",
    "            inputs[\"predicted_price_xgb\"],\n",
    "            inputs[\"predicted_price_rf\"],\n",
    "            inputs[\"predicted_price_lstw\"],\n",
    "            inputs[\"predicted_price_news_llm\"]\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Orchestrate the workflow with SequentialChain\n",
    "\n",
    "\n",
    "\n",
    "# General inputs for the sequence\n",
    "general_inputs = {\n",
    "    \"df\": gold,\n",
    "    \"current_price\": current_price,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "# Prepare input dictionary for the time series models\n",
    "ts_inputs = {\n",
    "    \"arimax_model\": arimax_model,\n",
    "    \"random_forest_model\": random_forest_model,\n",
    "    \"xgboost_model\": xgboost_model,\n",
    "    \"lstw_model\": lstw_model\n",
    "}\n",
    "\n",
    "# Prepare input dictionary for the news LLM chain\n",
    "news_llm_inputs = {\n",
    "    \"model_path\": news_model_path\n",
    "}\n",
    "\n",
    "# ensemble inputs\n",
    "emsemble_inputs = {\n",
    "    \"ensemble_model\": ensemble_model,\n",
    "}\n",
    "\n",
    "full_inputs = {\n",
    "    **general_inputs,\n",
    "    **ts_inputs,\n",
    "    **news_llm_inputs,\n",
    "    **emsemble_inputs\n",
    "}\n",
    "\n",
    "# Compose the full sequence\n",
    "full_seq_chain = SequentialChain(\n",
    "    chains=[arimax_chain, rf_chain, xgb_chain, lstm_chain, news_llm_chain, ensemble_chain],\n",
    "    input_variables=[\n",
    "        \"current_price\", \"device\", \"df\",\n",
    "        \"model_path\", \"arimax_model\", \"random_forest_model\", \"xgboost_model\", \"lstw_model\",\n",
    "        \"ensemble_model\", \n",
    "    ],\n",
    "    output_variables=[\n",
    "        \"predicted_price_arimax\", \"predicted_price_rf\", \"predicted_price_xgb\", \"predicted_price_lstw\",\n",
    "        \"predicted_price_news_llm\", \n",
    "        \"ensemble_results\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run the orchestrated sequence\n",
    "results = full_seq_chain(full_inputs)\n",
    "ensemble_results = final_results[\"ensemble_results\"]\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Current Gold Price: {current_price}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Predictions for next day: {next_day}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"ARIMAX: Predicted gold price: {results['predicted_price_arimax']}\")\n",
    "print(f\"Random Forest: Predicted gold price: {results['predicted_price_rf']}\")\n",
    "print(f\"XGBoost: Predicted gold price: {results['predicted_price_xgb']}\")\n",
    "print(f\"LSTM: Predicted gold price: {results['predicted_price_lstw']}\")\n",
    "print(f\"News LLM: Predicted gold price: {results['predicted_price_news_llm']}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Ensemble Model Results:\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Predicted Price: {ensemble_results['predictions']['meta_ensemble']}\")\n",
    "print(f\"Percentage Change: {ensemble_results['percentage_changes']['meta_ensemble']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
