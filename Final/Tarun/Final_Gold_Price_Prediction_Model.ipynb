{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d18d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script installs all required libraries for data analysis, plotting, LLM workflows, and notebook imports.\n",
    "# Note: The installation command is commented out to prevent accidental execution.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# Required Libraries:\n",
    "# pandas: Data manipulation and analysis\n",
    "# numpy: Numerical computations\n",
    "# matplotlib: Data visualization\n",
    "# yfinance: Downloading financial data from Yahoo Finance\n",
    "# langchain: Building LLM-powered applications and chains\n",
    "# import_ipynb: Importing Jupyter notebooks as Python modules\n",
    "# scipy: Scientific computing (e.g., signal processing)\n",
    "# statsmodels: Statistical modeling and time series analysis\n",
    "# xgboost: Gradient boosting for machine learning\n",
    "# selenium: Web scraping and browser automation\n",
    "# webdriver_manager: Managing browser drivers for Selenium\n",
    "# transformers: State-of-the-art NLP models\n",
    "# peft: Parameter-efficient fine-tuning for transformers\n",
    "# accelerate: Optimizing training and inference of models\n",
    "# bitsandbytes: Efficient training of large models with 8-bit optimizers\n",
    "# tensorflow: Deep learning framework\n",
    "# torch: PyTorch deep learning framework\n",
    "# tensorboard: Visualization tool for TensorFlow and PyTorch\n",
    "# scikit-learn: Machine learning library for Python (version 1.6.1)\n",
    "\n",
    "# Install all required libraries\n",
    "# %pip install -U tensorflow pandas torch tensorboard numpy matplotlib yfinance langchain import_ipynb scipy statsmodels xgboost selenium webdriver_manager transformers peft accelerate bitsandbytes\n",
    "# %pip install scikit-learn==1.6.1\n",
    "# %pip install tensorflow-hub\n",
    "# %pip install \"numpy<2.0\"\n",
    "# %pip install --upgrade numpy\n",
    "# %pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb411c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# -------------------------------------------------------------------------\n",
    "#  LangChain Imports\n",
    "# -------------------------------------------------------------------------\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain, TransformChain\n",
    "# -------------------------------------------------------------------------\n",
    "# Other Imports\n",
    "# -------------------------------------------------------------------------\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "# -------------------------------------------------------------------------\n",
    "#  Custom Imports ## It internally imports the modules & functions\n",
    "# -------------------------------------------------------------------------\n",
    "from modules.model_run_functions_old import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef519f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2025-06-23\n",
      "Next day's date: 2025-06-24\n"
     ]
    }
   ],
   "source": [
    "WORKAREA = \"D:/CAREER/IISC_B/Academics/Courses/SEM_3/DA_225o/Project/DL-7-25/Final\"\n",
    "# =========================================================================\n",
    "# Get today's date and the next day in YYYY-MM-DD format\n",
    "# =========================================================================\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "next_day = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "print(f\"Today's date: {today}\")\n",
    "print(f\"Next day's date: {next_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "543b1a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Gold Price: 82.44999694824219\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "start = datetime(2010, 1, 1)\n",
    "end = datetime(2026, 1, 1)\n",
    "\n",
    "## TODO: update news_data_raw to correct path\n",
    "news_data_raw       = f\"{WORKAREA}/Tarun/data/bullionvault_articles.csv\"\n",
    "news_data_csv       = f\"{WORKAREA}/Tarun/data/news_data_{today}.csv\"\n",
    "gold_prices_csv     = f\"{WORKAREA}/Tarun/data/GOLDBEES_ETF_price_data_technical_indicators_sentiment.csv\"\n",
    "gold_data_plain_csv = f\"{WORKAREA}/Tarun/data/GOLDBEES_ETF_price_data.csv\"\n",
    "news_data_with_sentiment_csv = f\"{WORKAREA}/Tarun/data/news_data_with_sentiment_{today}.csv\"\n",
    "finbert_model       = f\"{WORKAREA}/Tarun/Model/finbert_best_model_merged\"\n",
    "\n",
    "if os.path.exists(gold_prices_csv):\n",
    "    gold = pd.read_csv(gold_prices_csv, parse_dates=['Date'], index_col='Date')\n",
    "else:\n",
    "    # Download gold prices and save to CSV\n",
    "    gold = generate_sentiment_from_trend_with_labels(add_technical_indicators(download_gold_prices(start, end)))\n",
    "\n",
    "current_price = gold['Close'].iloc[-1]\n",
    "print(f\"Current Gold Price: {current_price}\")\n",
    "\n",
    "\n",
    "\n",
    "# Prepare input dictionary (ensure these variables are defined in your notebook)\n",
    "# --------------------------------------------------------------------\n",
    "# Load pre-trained models\n",
    "# --------------------------------------------------------------------\n",
    "# # Get device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd2424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get models if available, else train them.\n",
    "def get_base_models (path,today,device):\n",
    "\n",
    "    #If today's wights exists, then load them.\n",
    "    if os.path.exists(f'{path}/LSTM/lstm_{today}.pt'):\n",
    "        lstw_model           = LSTMModel(input_size=11).to(device)\n",
    "        lstw_model.load_state_dict(torch.load(f'{path}/LSTM/lstm_{today}.pt', map_location=device))\n",
    "        arimax_model         = sm.load_pickle(f'{path}/Arimax/arimax_{today}.pkl')\n",
    "        random_forest_model  = sm.load_pickle(f'{path}/RandomForest/random_forest_{today}.pkl')\n",
    "        xgboost_model        = sm.load_pickle(f'{path}/XGBoost/xgboost_{today}.pkl')\n",
    "        ensemble_model       = sm.load_pickle(f'{path}/Final_Ensemble/ensemble_model_{today}.pkl')\n",
    "    \n",
    "    #If not then train models.\n",
    "    else:\n",
    "\n",
    "        ## TODO! : Replace with model training script!!!\n",
    "        print(f\"Could not load from {path}\")\n",
    "        \n",
    "        # Loading latest by default until above is done.\n",
    "        path = '../..//Final/Jaison/Main_Code/Model'\n",
    "        today = \"2025-06-20\"\n",
    "        lstw_model           = LSTMModel(input_size=11).to(device)\n",
    "        lstw_model.load_state_dict(torch.load(f'{path}/LSTM/lstm_{today}.pt', map_location=device))\n",
    "        arimax_model         = sm.load_pickle(f'{path}/Arimax/arimax_{today}.pkl')\n",
    "        random_forest_model  = sm.load_pickle(f'{path}/RandomForest/random_forest_{today}.pkl')\n",
    "        xgboost_model        = sm.load_pickle(f'{path}/XGBoost/xgboost_{today}.pkl')\n",
    "        ensemble_model       = sm.load_pickle(f'{path}/Final_Ensemble/ensemble_model_{today}.pkl')    \n",
    "\n",
    "    news_model_path      = os.path.join(path, \"/final_model.pth\")\n",
    "\n",
    "    return lstw_model,arimax_model,random_forest_model,xgboost_model,ensemble_model,news_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84fd373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstw_model,arimax_model,random_forest_model,xgboost_model,ensemble_model,news_model_path = get_base_models(f'{WORKAREA}/Tarun/Model/',today,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c01de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Yaswanth] : Replace this with today's news articles scraping.\n",
    "# Extract news data\n",
    "#news_df = extract_news_data(local_news=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90ba7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO [Deepak, Tejashwini] : cleaning script for scraped news data. Mention expected input and output formats.\n",
    "#clean_and_prepare_articles(news_data_raw,news_data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b581a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the transform function for the TransformChain\n",
    "def news_llm_transform(inputs):\n",
    "    news_model = load_news_llm_model(inputs[\"device\"], inputs[\"model_path\"])\n",
    "    encodings, mask = generate_news_input(\n",
    "        inputs[\"device\"],\n",
    "        inputs[\"news_data_csv\"],\n",
    "        inputs[\"gold_data_plain_csv\"],\n",
    "        inputs[\"finbert_model\"],\n",
    "        inputs[\"news_data_with_sentiment_csv\"]\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        pred = news_model(encodings, mask=mask)\n",
    "        if hasattr(pred, \"item\"):\n",
    "            pred = pred.item()\n",
    "    predicted_price = inputs[\"current_price\"] * (1 + pred)\n",
    "    return {\"predicted_price_news_llm\": predicted_price}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005714ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved to D:/CAREER/IISC_B/Academics/Courses/SEM_3/DA_225o/Project/DL-7-25/Final/Tarun/data/news_data_with_sentiment_2025-06-23.csv\n",
      "WARNING:tensorflow:From c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tarun Vinjamuru\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Current Gold Price: 82.44999694824219\n",
      "---------------------------------------------------\n",
      "Predictions for next day: 2025-06-24\n",
      "---------------------------------------------------\n",
      "ARIMAX: Predicted gold price: 82.86905617926536\n",
      "Random Forest: Predicted gold price: 82.12877083738854\n",
      "XGBoost: Predicted gold price: 82.47662647419656\n",
      "LSTM: Predicted gold price: 81.17937989204205\n",
      "News LLM: Predicted gold price: 85.87733830491788\n",
      "---------------------------------------------------\n",
      "Ensemble Model Results:\n",
      "---------------------------------------------------\n",
      "Predicted Price: 82.7178386187372\n",
      "Percentage Change: 0.59%\n"
     ]
    }
   ],
   "source": [
    "# Orchestrate the workflow with SequentialChain\n",
    "# --------------------------------------------------------------------\n",
    "# Define prompt templates for each model prediction step\n",
    "# Define TransformChains for each model prediction step using the existing functions\n",
    "arimax_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"arimax_model\"],\n",
    "    output_variables=[\"predicted_price_arimax\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_arimax\": predict_next_day_gold_price_arimax(inputs[\"df\"], inputs[\"arimax_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "rf_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"random_forest_model\"],\n",
    "    output_variables=[\"predicted_price_rf\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_rf\": predict_next_day_gold_price_rf(inputs[\"df\"], inputs[\"random_forest_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "xgb_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"xgboost_model\"],\n",
    "    output_variables=[\"predicted_price_xgb\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_xgb\": predict_next_day_gold_price_xgboost(inputs[\"df\"], inputs[\"xgboost_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "lstm_chain = TransformChain(\n",
    "    input_variables=[\"df\", \"device\", \"lstw_model\"],\n",
    "    output_variables=[\"predicted_price_lstw\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"predicted_price_lstw\": predict_next_day_gold_price_lstm(inputs[\"df\"], inputs[\"device\"], inputs[\"lstw_model\"])\n",
    "    }\n",
    ")\n",
    "\n",
    "news_llm_chain = TransformChain(\n",
    "    input_variables=[\"current_price\", \"device\", \"model_path\", \"finbert_model\", \"news_data_csv\", \"gold_data_plain_csv\", \"news_data_with_sentiment_csv\"],\n",
    "    output_variables=[\"predicted_price_news_llm\"],\n",
    "    transform=news_llm_transform\n",
    ")\n",
    "\n",
    "# Define the ensemble prediction as a TransformChain\n",
    "ensemble_chain = TransformChain(\n",
    "    input_variables=[\n",
    "        \"ensemble_model\",\n",
    "        \"predicted_price_arimax\",\n",
    "        \"predicted_price_xgb\",\n",
    "        \"predicted_price_rf\",\n",
    "        \"predicted_price_lstw\",\n",
    "        \"predicted_price_news_llm\"\n",
    "    ],\n",
    "    output_variables=[\"ensemble_results\"],\n",
    "    transform=lambda inputs: {\n",
    "        \"ensemble_results\": predict_next_day_gold_price_ensemble(\n",
    "            inputs[\"ensemble_model\"],\n",
    "            inputs[\"predicted_price_arimax\"],\n",
    "            inputs[\"predicted_price_xgb\"],\n",
    "            inputs[\"predicted_price_rf\"],\n",
    "            inputs[\"predicted_price_lstw\"],\n",
    "            inputs[\"predicted_price_news_llm\"]\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# General inputs for the sequence\n",
    "general_inputs = {\n",
    "    \"df\": gold,\n",
    "    \"current_price\": current_price,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "# Prepare input dictionary for the time series models\n",
    "ts_inputs = {\n",
    "    \"arimax_model\": arimax_model,\n",
    "    \"random_forest_model\": random_forest_model,\n",
    "    \"xgboost_model\": xgboost_model,\n",
    "    \"lstw_model\": lstw_model\n",
    "}\n",
    "\n",
    "# Prepare input dictionary for the news LLM chain\n",
    "news_llm_inputs = {\n",
    "    \"device\": device,\n",
    "    \"current_price\": current_price,\n",
    "    \"model_path\": news_model_path,\n",
    "    \"finbert_model\": finbert_model,\n",
    "    \"news_data_csv\": news_data_csv,\n",
    "    \"gold_data_plain_csv\": gold_data_plain_csv,\n",
    "    \"news_data_with_sentiment_csv\": news_data_with_sentiment_csv\n",
    "}\n",
    "\n",
    "# ensemble inputs\n",
    "emsemble_inputs = {\n",
    "    \"ensemble_model\": ensemble_model,\n",
    "}\n",
    "\n",
    "full_inputs = {\n",
    "    **general_inputs,\n",
    "    **ts_inputs,\n",
    "    **news_llm_inputs,\n",
    "    **emsemble_inputs\n",
    "}\n",
    "\n",
    "# Compose the full sequence\n",
    "full_seq_chain = SequentialChain(\n",
    "    chains=[arimax_chain, rf_chain, xgb_chain, lstm_chain, news_llm_chain, ensemble_chain],\n",
    "    input_variables=[\n",
    "        \"current_price\", \"device\", \"df\",\n",
    "        \"finbert_model\", \n",
    "        \"news_data_csv\", \"gold_data_plain_csv\", \"news_data_with_sentiment_csv\",\n",
    "        \"model_path\", \"arimax_model\", \"random_forest_model\", \"xgboost_model\", \"lstw_model\",\n",
    "        \"ensemble_model\"        \n",
    "    ],\n",
    "    output_variables=[\n",
    "        \"predicted_price_arimax\", \"predicted_price_rf\", \"predicted_price_xgb\", \"predicted_price_lstw\",\n",
    "        \"predicted_price_news_llm\", \n",
    "        \"ensemble_results\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run the orchestrated sequence\n",
    "results = full_seq_chain.invoke(full_inputs)\n",
    "ensemble_results = results[\"ensemble_results\"]\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Current Gold Price: {current_price}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Predictions for next day: {next_day}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"ARIMAX: Predicted gold price: {results['predicted_price_arimax']}\")\n",
    "print(f\"Random Forest: Predicted gold price: {results['predicted_price_rf']}\")\n",
    "print(f\"XGBoost: Predicted gold price: {results['predicted_price_xgb']}\")\n",
    "print(f\"LSTM: Predicted gold price: {results['predicted_price_lstw']}\")\n",
    "print(f\"News LLM: Predicted gold price: {results['predicted_price_news_llm']}\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"Ensemble Model Results:\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Predicted Price: {ensemble_results['predictions']['meta_ensemble']}\")\n",
    "print(f\"Percentage Change: {ensemble_results['percentage_changes']['meta_ensemble']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
