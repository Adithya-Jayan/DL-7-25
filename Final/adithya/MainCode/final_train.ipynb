{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d168dd0f",
   "metadata": {},
   "source": [
    "# Final model training script:\n",
    "Please run Combine_data_with_gold_price.ipynb to get the final processed and annotated data file.\n",
    "'Final\\adithya\\Data\\combined_dataset_with_price_change.csv'\n",
    "before running this script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81441b4b",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54ae064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import notebook as tqdm\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import shutil\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c5822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import our defined classes and functions\n",
    "from modules import NewsDataset, SetTransformer , VariableSetDataset\n",
    "from functions import group_into_variable_sets, load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c1f83",
   "metadata": {},
   "source": [
    "### Read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30b6a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df: (6491, 6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "topic_encodings",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentiment_combined_encodings",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "price_percentage_change",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7bc41a6e-0c1c-487f-8e42-665ad1038694",
       "rows": [
        [
         "0",
         "2016-01-28 00:00:00",
         "april gold down 20 cents to settle at $1,116.10/oz",
         "-0.9990002400000001",
         "[-0.03060799 -0.06112092  0.05298826  0.0025289  -0.03638886 -0.07299493\n  0.02046622  0.01156865  0.01162445 -0.0616043  -0.04030951 -0.05163803\n  0.06358126  0.02262463  0.02527188  0.01009099  0.0218296   0.00401299\n  0.02320212  0.01840406  0.07099302 -0.05999327  0.05512141 -0.00486027\n -0.01445769  0.01327463  0.01412656  0.05520682  0.02154909  0.03877787\n -0.01477625  0.02260535  0.03380904  0.07417348 -0.07842116  0.06172097\n -0.00722861 -0.06963449 -0.02782996 -0.00300515  0.00311992 -0.04044174\n -0.05033601 -0.04302497  0.03521148 -0.00674379 -0.02293996  0.07465921\n -0.03291184 -0.08575693 -0.04050859 -0.07181226  0.0492393  -0.03098445\n -0.0267233  -0.02657945  0.03298942  0.00143339 -0.03874432 -0.00633903\n  0.0072122  -0.07564452 -0.01386265  0.01673867 -0.00010899  0.02253064\n -0.01644825  0.06253189 -0.01174232 -0.05542235  0.01332529 -0.05355043\n -0.05024853 -0.04696002 -0.08363569  0.06868701  0.03286146  0.0072184\n -0.01546243  0.03366553 -0.02013146  0.02619362 -0.00706884 -0.0076259\n -0.04681716  0.03897078 -0.05188498 -0.05431785 -0.05436934 -0.04849016\n -0.00022483  0.04601097  0.02673947  0.01855598 -0.07643524 -0.03416492\n  0.0104013   0.03540764 -0.02783735  0.03650146  0.03681616  0.02023847\n -0.00070697  0.04584326  0.08067842 -0.0422569   0.01907275  0.00530204\n -0.083761   -0.03345601 -0.06878904 -0.04471475 -0.03991587 -0.05958318\n -0.05389266 -0.00761097 -0.00048052 -0.06856151 -0.05415869 -0.02754776\n  0.06522793  0.07326005 -0.0712814  -0.05309229  0.02510547  0.00290017\n  0.00301274  0.06836648  0.07304256 -0.00017639  0.01730784  0.00477659\n -0.01275147  0.02272531 -0.0474665  -0.0395419  -0.06857067  0.0250839\n  0.03575613 -0.03055125 -0.02483121 -0.00795718 -0.0123119  -0.0059608\n -0.00151042 -0.05365949 -0.07321971 -0.02133894 -0.09237103  0.07865131\n  0.03502284  0.04824168  0.04583891  0.0186416  -0.07045352  0.00676598\n  0.00068599 -0.07745604  0.005068   -0.04888221  0.00246496  0.02944654\n -0.02111885 -0.06186155 -0.0287878  -0.06445026 -0.06199     0.07418165\n -0.01565153  0.0009194   0.05025635 -0.02552276 -0.07800826 -0.05734867\n -0.04984413  0.06612686 -0.04458354 -0.06436928 -0.0074135   0.00017087\n -0.02595965  0.01400746 -0.04512938  0.04966498 -0.02387098 -0.01211483\n -0.01479543 -0.05957516 -0.00765668 -0.00200202  0.01559334 -0.08923154\n -0.02549055  0.01026444 -0.03512738 -0.01208751 -0.08127406 -0.03538607\n  0.0238379  -0.03941635 -0.02658368  0.05435999  0.03687765  0.00694837\n -0.00300575 -0.04395045 -0.02152155 -0.01076224 -0.05215716 -0.02392807\n -0.04448511 -0.05046634 -0.02100455 -0.0280573   0.00738292  0.0248356\n  0.06618484  0.05435246  0.04135766  0.00497467 -0.04721113 -0.02120279\n -0.05664758  0.03366268 -0.00362956 -0.02218214  0.00784913  0.03684668\n -0.08589929 -0.05274304  0.08825708 -0.05894476 -0.06876174  0.00479312\n  0.00078308  0.07709686 -0.05150171  0.0657438  -0.07015677  0.02577646\n -0.02715389  0.04575896 -0.07060973 -0.03019159  0.03614494  0.04799487\n  0.00395358 -0.01066946  0.04138668  0.06967817  0.02574099  0.0121533\n -0.02570466 -0.04473447 -0.04481049 -0.00589975  0.01340064 -0.08065244\n  0.02526991  0.01495083 -0.02093755  0.03045776  0.01974575  0.08034623\n  0.02027657  0.03911046  0.03939407  0.03379276 -0.0652896  -0.0291815\n -0.09277252  0.03432918 -0.05156878  0.01961251 -0.02917315 -0.05682648\n -0.082623    0.0362778  -0.02902075  0.03411527  0.06873902 -0.01647531\n -0.0623653  -0.05135417 -0.03112791  0.00248385  0.04727773 -0.04897066\n -0.05405267  0.05391892 -0.0603884  -0.02004526 -0.04501663  0.07969156\n  0.00758657 -0.06932089 -0.00421074  0.00594293  0.01421573 -0.06162978\n -0.01383616 -0.04209746 -0.0284232  -0.03160886 -0.04693345  0.00118234\n -0.03039856 -0.05521169  0.06563931 -0.02077457  0.01949558  0.01558753\n  0.08033288 -0.07800873  0.01318738 -0.01162792 -0.01407327  0.09609251\n -0.05521653 -0.03398157 -0.01730926  0.02687987  0.06745194  0.02697426\n  0.01494284 -0.0623166  -0.07285997 -0.06445263 -0.07432485  0.02099579\n -0.05769779 -0.03979247 -0.04852267  0.04044847 -0.03964155  0.01717729\n  0.08128795  0.05473131 -0.0429499   0.03287106 -0.00350498  0.01039318\n  0.0323399   0.01424567  0.05028107 -0.07106783 -0.02767063  0.00984758\n  0.01066899 -0.0732889  -0.06345612 -0.02617735  0.03722087  0.00858802\n -0.10072696  0.0594535  -0.08790426  0.0025537   0.05049363 -0.02223925\n  0.05152288  0.02361581  0.05303993 -0.01427712  0.01179398  0.00982833\n  0.06959677 -0.06971829  0.03913464 -0.01602991 -0.06673922 -0.0088033\n -0.01555507 -0.02750071  0.03892148 -0.01394932 -0.03737103 -0.02887443\n  0.05481398  0.03068455  0.03924127 -0.01520203 -0.0435516   0.02980434\n -0.07495456  0.03069155  0.01882227 -0.03325604 -0.04280555  0.04689428\n -0.06301485 -0.03782857 -0.04021469  0.0533688   0.03882589 -0.04464123\n -0.00239494 -0.00182198  0.0113339  -0.08667967 -0.04044904  0.0160445\n  0.07454786  0.00204288  0.04594523  0.04270747  0.00456695 -0.04528303\n  0.02383051  0.03081109  0.02051561  0.04121043  0.02459877 -0.0174291\n -0.04870238  0.02604179  0.01972426 -0.00621016  0.02533624  0.00275671\n -0.07724576 -0.02490363 -0.03071677  0.03885673 -0.03797515  0.06160687\n -0.09247442 -0.06432457 -0.04658696  0.00937365  0.05171432 -0.03566235\n -0.00955764  0.09906664 -0.00072665  0.0140413  -0.03059272 -0.0086379\n -0.00996369  0.00429717  0.02194089  0.01646249  0.02078139 -0.01377642\n  0.00413388  0.00105219  0.03322009  0.02348765 -0.03549129 -0.00130468\n  0.03225757  0.06203884  0.00823414 -0.04047196  0.00912542 -0.08954436\n -0.03559636  0.02266426 -0.02124952  0.02625306 -0.03795307 -0.06399749\n  0.03602317  0.0789882  -0.01838737  0.06168995  0.06420645  0.07399425\n -0.02915965  0.02317173 -0.08161085  0.06215012 -0.0160385   0.01129771\n -0.00584187  0.04832446  0.0016165   0.09538612  0.060814    0.00833437\n  0.03412996 -0.03452191  0.07292676  0.02444159  0.02279735  0.02499982\n  0.02528707 -0.00391597 -0.02503288 -0.03050189  0.09123816 -0.00224973\n  0.00800383 -0.06505815 -0.02933516 -0.06626534  0.07939659  0.0449586\n -0.0242429  -0.07387587  0.01370137  0.01510715  0.07266158  0.08370309\n  0.07946902  0.02541378  0.00899594  0.03802771 -0.06516914 -0.02766143\n -0.06662946  0.00577274]",
         "[ 0.03057739  0.06105981 -0.05293529 -0.00252637  0.03635248  0.07292195\n -0.02044576 -0.01155708 -0.01161282  0.06154271  0.04026921  0.05158641\n -0.06351769 -0.02260201 -0.02524662 -0.01008091 -0.02180778 -0.00400898\n -0.02317892 -0.01838566 -0.07092205  0.0599333  -0.0550663   0.00485541\n  0.01444323 -0.01326136 -0.01411244 -0.05515163 -0.02152754 -0.0387391\n  0.01476148 -0.02258275 -0.03377524 -0.07409932  0.07834276 -0.06165926\n  0.00722138  0.06956487  0.02780214  0.00300215 -0.00311681  0.04040131\n  0.05028568  0.04298195 -0.03517627  0.00673705  0.02291703 -0.07458457\n  0.03287894  0.08567119  0.04046809  0.07174046 -0.04919007  0.03095347\n  0.02669659  0.02655287 -0.03295644 -0.00143195  0.03870559  0.0063327\n -0.00720499  0.0755689   0.01384879 -0.01672194  0.00010889 -0.02250812\n  0.0164318  -0.06246937  0.01173058  0.05536694 -0.01331197  0.0534969\n  0.0501983   0.04691307  0.08355207 -0.06861833 -0.03282861 -0.00721118\n  0.01544697 -0.03363187  0.02011133 -0.02616744  0.00706177  0.00761827\n  0.04677035 -0.03893181  0.05183311  0.05426354  0.05431499  0.04844168\n  0.00022461 -0.04596497 -0.02671273 -0.01853743  0.07635882  0.03413076\n -0.0103909  -0.03537225  0.02780952 -0.03646497 -0.03677936 -0.02021823\n  0.00070626 -0.04579743 -0.08059776  0.04221466 -0.01905368 -0.00529674\n  0.08367726  0.03342256  0.06872027  0.04467004  0.03987597  0.05952362\n  0.05383878  0.00760336  0.00048004  0.06849296  0.05410455  0.02752022\n -0.06516271 -0.07318681  0.07121014  0.05303921 -0.02508037 -0.00289727\n -0.00300973 -0.06829813 -0.07296953  0.00017621 -0.01729054 -0.00477182\n  0.01273872 -0.02270259  0.04741905  0.03950237  0.06850211 -0.02505882\n -0.03572038  0.03052071  0.02480638  0.00794923  0.01229959  0.00595484\n  0.00150891  0.05360585  0.07314651  0.0213176   0.09227868 -0.07857268\n -0.03498783 -0.04819345 -0.04579308 -0.01862297  0.07038309 -0.00675921\n -0.0006853   0.07737861 -0.00506293  0.04883334 -0.00246249 -0.0294171\n  0.02109773  0.06179971  0.02875902  0.06438583  0.06192802 -0.07410749\n  0.01563588 -0.00091849 -0.0502061   0.02549724  0.07793027  0.05729134\n  0.0497943  -0.06606075  0.04453897  0.06430493  0.00740609 -0.0001707\n  0.0259337  -0.01399346  0.04508426 -0.04961533  0.02384711  0.01210272\n  0.01478064  0.0595156   0.00764903  0.00200002 -0.01557775  0.08914234\n  0.02546506 -0.01025418  0.03509226  0.01207542  0.08119281  0.0353507\n -0.02381406  0.03937694  0.0265571  -0.05430565 -0.03684078 -0.00694143\n  0.00300274  0.04390651  0.02150004  0.01075148  0.05210502  0.02390415\n  0.04444063  0.05041588  0.02098355  0.02802925 -0.00737554 -0.02481077\n -0.06611867 -0.05429812 -0.04131631 -0.0049697   0.04716393  0.02118159\n  0.05659094 -0.03362903  0.00362593  0.02215997 -0.00784129 -0.03680984\n  0.08581341  0.0526903  -0.08816884  0.05888583  0.068693   -0.00478833\n -0.0007823  -0.07701978  0.05145022 -0.06567807  0.07008663 -0.02575069\n  0.02712674 -0.04571322  0.07053914  0.03016141 -0.03610881 -0.04794689\n -0.00394963  0.01065879 -0.04134531 -0.0696085  -0.02571525 -0.01214115\n  0.02567896  0.04468975  0.04476568  0.00589385 -0.01338724  0.08057181\n -0.02524464 -0.01493589  0.02091662 -0.03042731 -0.01972601 -0.0802659\n -0.0202563  -0.03907136 -0.03935469 -0.03375898  0.06522433  0.02915232\n  0.09267977 -0.03429485  0.05151723 -0.01959291  0.02914399  0.05676967\n  0.0825404  -0.03624153  0.02899173 -0.03408116 -0.0686703   0.01645884\n  0.06230295  0.05130282  0.03109679 -0.00248137 -0.04723046  0.0489217\n  0.05399863 -0.05386501  0.06032803  0.02002522  0.04497163 -0.07961189\n -0.00757898  0.06925158  0.00420653 -0.00593699 -0.01420152  0.06156817\n  0.01382233  0.04205537  0.02839479  0.03157726  0.04688653 -0.00118116\n  0.03036817  0.0551565  -0.06557368  0.0207538  -0.01947609 -0.01557195\n -0.08025257  0.07793073 -0.0131742   0.0116163   0.0140592  -0.09599645\n  0.05516133  0.03394759  0.01729195 -0.026853   -0.0673845  -0.02694729\n -0.0149279   0.06225429  0.07278713  0.06438819  0.07425054 -0.0209748\n  0.05764011  0.03975268  0.04847416 -0.04040803  0.03960191 -0.01716012\n -0.08120668 -0.0546766   0.04290696 -0.03283819  0.00350147 -0.01038279\n -0.03230757 -0.01423143 -0.0502308   0.07099678  0.02764296 -0.00983774\n -0.01065832  0.07321563  0.06339268  0.02615118 -0.03718366 -0.00857943\n  0.10062626 -0.05939407  0.08781638 -0.00255115 -0.05044315  0.02221701\n -0.05147137 -0.0235922  -0.0529869   0.01426284 -0.01178219 -0.0098185\n -0.06952719  0.06964859 -0.03909551  0.01601388  0.0666725   0.00879449\n  0.01553952  0.02747321 -0.03888257  0.01393538  0.03733367  0.02884556\n -0.05475918 -0.03065387 -0.03920204  0.01518683  0.04350806 -0.02977454\n  0.07487962 -0.03066086 -0.01880345  0.03322279  0.04276276 -0.0468474\n  0.06295185  0.03779075  0.04017448 -0.05331544 -0.03878707  0.04459661\n  0.00239255  0.00182016 -0.01132257  0.08659301  0.0404086  -0.01602846\n -0.07447333 -0.00204083 -0.04589929 -0.04266477 -0.00456239  0.04523776\n -0.02380668 -0.03078029 -0.0204951  -0.04116923 -0.02457418  0.01741167\n  0.04865369 -0.02601576 -0.01970454  0.00620395 -0.02531091 -0.00275395\n  0.07716853  0.02487874  0.03068606 -0.03881789  0.03793719 -0.06154528\n  0.09238197  0.06426026  0.04654038 -0.00936428 -0.05166262  0.03562669\n  0.00954809 -0.0989676   0.00072592 -0.01402726  0.03056214  0.00862926\n  0.00995373 -0.00429288 -0.02191896 -0.01644603 -0.02076062  0.01376265\n -0.00412975 -0.00105114 -0.03318688 -0.02346417  0.0354558   0.00130337\n -0.03222532 -0.06197682 -0.00822591  0.0404315  -0.0091163   0.08945484\n  0.03556078 -0.0226416   0.02122827 -0.02622681  0.03791513  0.06393351\n -0.03598716 -0.07890923  0.01836899 -0.06162828 -0.06414226 -0.07392027\n  0.02913049 -0.02314856  0.08152926 -0.06208798  0.01602246 -0.01128642\n  0.00583603 -0.04827615 -0.00161489 -0.09529076 -0.0607532  -0.00832604\n -0.03409584  0.0344874  -0.07285385 -0.02441716 -0.02277456 -0.02497483\n -0.0252618   0.00391205  0.02500785  0.0304714  -0.09114695  0.00224748\n -0.00799583  0.06499311  0.02930583  0.06619909 -0.07931721 -0.04491365\n  0.02421866  0.07380202 -0.01368767 -0.01509205 -0.07258894 -0.0836194\n -0.07938957 -0.02538837 -0.00898694 -0.0379897   0.06510399  0.02763378\n  0.06656285 -0.00576697]",
         "0.19161547035584145"
        ],
        [
         "1",
         "2016-01-28 00:00:00",
         "gold sticks near 12-week high as fed eyes global economy",
         "0.9967026600000002",
         "[ 0.01613437 -0.03043513  0.05567852  0.02714832 -0.03795345 -0.06267978\n -0.04648193 -0.02436773 -0.01390197 -0.01640089  0.00450919  0.08383387\n -0.05940384 -0.03249551 -0.03595341 -0.04989222  0.03329321 -0.00226448\n  0.06935231  0.06047926  0.07008274 -0.08311916  0.05455993  0.01387192\n  0.00449403 -0.01218927 -0.05701718  0.04052735 -0.06500535  0.0736521\n  0.08389591 -0.03344592  0.06834858  0.05958758  0.01580583  0.06364918\n -0.04430149  0.01167582  0.00215282 -0.06174159 -0.00639471  0.02494857\n -0.04601186 -0.02365508 -0.00695173  0.01839833 -0.01985575  0.03653559\n  0.0326491  -0.06430528  0.01134896 -0.07682522  0.02318352 -0.01507657\n -0.03686203 -0.07133066 -0.0273608   0.02128434 -0.06909671  0.01842193\n -0.02386004 -0.02511115  0.06192098 -0.00701246  0.00414002  0.03939115\n  0.0377521   0.06912795  0.02697308 -0.03950191 -0.03908638  0.07400308\n -0.06313079 -0.05754173 -0.07371113  0.05224561 -0.0175585   0.05477194\n -0.01531499  0.00305341 -0.05184471  0.01920138 -0.02451581  0.03226006\n  0.03241505  0.03134511  0.04615248 -0.00499291  0.03128483 -0.03957818\n  0.05866094 -0.01475418  0.04104706  0.06629457  0.07570737 -0.04660314\n -0.00141904  0.02942776  0.01632853  0.07082572  0.09203208 -0.03308158\n  0.00703302 -0.001565    0.02174749 -0.06492911  0.01672558 -0.06521983\n -0.05128285 -0.00275865 -0.07144257  0.03954614 -0.06272338  0.00665659\n  0.03609217  0.00816846 -0.02321696 -0.05503556 -0.08108404 -0.03819043\n -0.06789307  0.04527223 -0.07445437 -0.02196691  0.01035397  0.00088507\n  0.0938362  -0.0281813   0.0201801   0.05613179  0.05276785 -0.01735401\n -0.03321536 -0.04150128 -0.02339556 -0.01533118 -0.02264312  0.04340134\n  0.06073289 -0.08899695  0.0663674  -0.01245199  0.01128349 -0.04925209\n  0.03944334 -0.04549645 -0.01767051  0.01558666 -0.0704275  -0.02265915\n -0.03225949 -0.0125642   0.01339296  0.05890704  0.02185724  0.01851476\n  0.02307088 -0.06865084  0.03690826 -0.02681725  0.01740615  0.02792854\n  0.01442573 -0.06027636 -0.02176956 -0.07379592 -0.02151933  0.08016469\n  0.01305621 -0.00548242  0.01630577  0.02423989 -0.03249202  0.02425091\n  0.02497308  0.07666612 -0.06896635 -0.03053344 -0.05211141 -0.04540278\n  0.07950826  0.0146763  -0.0644344  -0.06207076 -0.00029721 -0.06717299\n  0.06341442 -0.04905012 -0.04258369 -0.04034721  0.03001085 -0.06405362\n -0.03446108  0.03536349  0.02156064 -0.02394086 -0.05646078 -0.01465504\n -0.02167642  0.01216136 -0.04348593  0.04606895  0.07499477  0.03402417\n -0.0171634  -0.00180857  0.00541751 -0.03451759  0.01762639  0.0483114\n  0.04497572  0.01898798  0.00522308 -0.02327984  0.01351835  0.03484965\n  0.01115198  0.03842996 -0.01594514  0.00202153 -0.03143871 -0.03218916\n -0.07506003  0.08454443  0.02814781 -0.00238097  0.01018419 -0.00541474\n -0.06760494 -0.08017388  0.07113348 -0.01857915  0.03948824  0.02967959\n  0.05318376  0.01948672 -0.04877422 -0.0041663   0.05416879  0.00202214\n  0.01274133  0.0120092  -0.01102521 -0.06424237  0.01139313  0.01709805\n  0.0657208  -0.04222821  0.04111831  0.03424554  0.0554408   0.02028163\n -0.00754877  0.01051745 -0.04801999 -0.01682066 -0.03745664 -0.06300978\n  0.08552068 -0.02725893 -0.04131683  0.02197906  0.02517199  0.06077073\n -0.07860968 -0.0099976  -0.02309741 -0.00676405 -0.05415561 -0.05747138\n -0.05383993  0.01779715  0.03673811  0.01626537  0.02503082 -0.07597955\n -0.01068134 -0.07380554 -0.00325179  0.07791103  0.00286775  0.04854636\n  0.00923577 -0.07144694 -0.03837399  0.01443691  0.01124669 -0.04505714\n  0.03820397  0.01506903 -0.02327039 -0.01958033  0.01389476 -0.06106577\n -0.00145112  0.02109732 -0.0316322   0.0364056  -0.05841004  0.01670145\n -0.04721364 -0.04370814 -0.00115931 -0.03088269 -0.03895396  0.01326217\n  0.05307933  0.02695383  0.04950018  0.03126461 -0.0322159   0.03526438\n  0.04379019 -0.06870998 -0.04259576  0.03290065 -0.01162481  0.02546331\n -0.0253845  -0.03919587 -0.01889527  0.04557227  0.05173652  0.08884161\n -0.02548361  0.01252903 -0.0346124  -0.07032814  0.00836502 -0.00427323\n -0.08682095 -0.03835732  0.05967753  0.01983663  0.02938089 -0.01436376\n  0.05060421 -0.04736358 -0.02742003 -0.02751315 -0.06873439 -0.07913296\n  0.00264462 -0.02504151  0.04995278 -0.08323888 -0.00917213 -0.00101442\n -0.00319724 -0.06919003 -0.04919242  0.06027959  0.08098347 -0.0785655\n -0.09512921  0.02736457 -0.08110779 -0.01126065  0.00860152 -0.03328943\n  0.07589207 -0.04359266  0.04697589 -0.01380846  0.00764366  0.06156839\n  0.02051868 -0.0612435  -0.01110901 -0.07032151 -0.01161782 -0.05451307\n  0.06536999 -0.05622555  0.03075536 -0.01276483 -0.0552798  -0.06774168\n  0.05407009 -0.00506394  0.03714655 -0.09152806  0.02272944  0.00473655\n -0.01603965 -0.01211356 -0.06090333  0.03058519 -0.04772475 -0.00636351\n -0.04022205 -0.01095765 -0.08233009 -0.01571041  0.01140027  0.03454696\n -0.02816467  0.03588343 -0.0215813   0.01555893 -0.04503962 -0.01122002\n  0.05840269 -0.07575536  0.00551989 -0.00467643 -0.04404119  0.0340188\n -0.03838391 -0.011244    0.023949    0.0665906   0.02476048  0.03197934\n -0.02707279 -0.01525975  0.05663444 -0.03395951 -0.00161692 -0.02365739\n -0.05099397  0.06782731  0.02042038  0.08356739  0.02271687  0.05342329\n -0.06579615 -0.05365988  0.0542059  -0.02885793 -0.06171209 -0.04360094\n -0.05957997 -0.03579501  0.0609058  -0.01930933  0.01302233  0.00412789\n  0.04050445 -0.01628177 -0.00989137  0.05130409 -0.02777327 -0.05235086\n -0.03255425 -0.00714966  0.02841409 -0.04588113  0.05325899 -0.03503198\n -0.06587071 -0.05541431  0.04989177 -0.03143732  0.06660184  0.00291072\n -0.0136957   0.06400283  0.03267483 -0.00787441  0.07737766 -0.02373461\n  0.04921664  0.05317703 -0.06670363  0.05905972  0.04434827 -0.02854018\n -0.04029432  0.00733254 -0.01402368  0.00264004  0.07253832 -0.02201165\n -0.04588505  0.0372282   0.03429504  0.05202067  0.05058177 -0.06153232\n -0.03078134 -0.01028158  0.00039381  0.01929495  0.04501602  0.07075418\n  0.05846148  0.03320362  0.02385001 -0.04820866 -0.03135673  0.03107817\n  0.02566687  0.04304403 -0.04960399  0.05899875 -0.00047314  0.03967138\n -0.00210542 -0.06813975 -0.07154498  0.02811657  0.03356967  0.07525204\n -0.07469777  0.01442725  0.03634088  0.06108026 -0.07318626 -0.00853033\n -0.07559565 -0.07595006]",
         "[ 0.01608117 -0.03033478  0.05549493  0.0270588  -0.0378283  -0.06247311\n -0.04632866 -0.02428738 -0.01385613 -0.01634681  0.00449432  0.08355744\n -0.05920797 -0.03238836 -0.03583486 -0.0497277   0.03318343 -0.00225702\n  0.06912363  0.06027984  0.06985165 -0.08284509  0.05438003  0.01382618\n  0.00447921 -0.01214908 -0.05682918  0.04039372 -0.064791    0.07340924\n  0.08361928 -0.03333563  0.06812321  0.0593911   0.01575372  0.0634393\n -0.04415541  0.01163732  0.00214572 -0.061538   -0.00637362  0.0248663\n -0.04586014 -0.02357708 -0.00692881  0.01833767 -0.01979028  0.03641512\n  0.03254144 -0.06409324  0.01131154 -0.0765719   0.02310708 -0.01502686\n -0.03674049 -0.07109546 -0.02727058  0.02121416 -0.06886888  0.01836119\n -0.02378137 -0.02502835  0.06171681 -0.00698934  0.00412637  0.03926126\n  0.03762762  0.06890002  0.02688414 -0.03937165 -0.0389575   0.07375906\n -0.06292263 -0.057352   -0.07346807  0.05207333 -0.0175006   0.05459134\n -0.01526449  0.00304334 -0.05167376  0.01913807 -0.02443497  0.03215368\n  0.03230817  0.03124176  0.0460003  -0.00497645  0.03118167 -0.03944768\n  0.05846752 -0.01470553  0.04091171  0.06607597  0.07545774 -0.04644948\n -0.00141436  0.02933073  0.01627469  0.07059218  0.09172862 -0.0329725\n  0.00700983 -0.00155984  0.02167578 -0.06471502  0.01667043 -0.06500477\n -0.05111375 -0.00274955 -0.07120699  0.03941574 -0.06251656  0.00663464\n  0.03597316  0.00814152 -0.02314041 -0.05485409 -0.08081667 -0.03806451\n -0.06766921  0.04512296 -0.07420886 -0.02189448  0.01031983  0.00088215\n  0.09352679 -0.02808838  0.02011356  0.0559467   0.05259386 -0.01729679\n -0.03310584 -0.04136444 -0.02331842 -0.01528063 -0.02256846  0.04325823\n  0.06053263 -0.08870351  0.06614856 -0.01241093  0.01124629 -0.04908969\n  0.03931328 -0.04534643 -0.01761225  0.01553527 -0.07019528 -0.02258444\n -0.03215312 -0.01252277  0.0133488   0.0587128   0.02178517  0.01845371\n  0.02299481 -0.06842448  0.03678656 -0.02672882  0.01734876  0.02783645\n  0.01437816 -0.0600776  -0.02169778 -0.07355259 -0.02144838  0.07990036\n  0.01301316 -0.00546434  0.01625201  0.02415996 -0.03238489  0.02417095\n  0.02489074  0.07641333 -0.06873894 -0.03043276 -0.05193958 -0.04525307\n  0.0792461   0.01462791 -0.06422194 -0.06186609 -0.00029623 -0.0669515\n  0.06320532 -0.04888839 -0.04244328 -0.04021417  0.0299119  -0.06384241\n -0.03434745  0.03524688  0.02148955 -0.02386192 -0.0562746  -0.01460672\n -0.02160495  0.01212126 -0.04334254  0.04591705  0.07474748  0.03391198\n -0.01710681 -0.00180261  0.00539965 -0.03440377  0.01756827  0.0481521\n  0.04482742  0.01892537  0.00520585 -0.02320308  0.01347378  0.03473474\n  0.01111521  0.03830324 -0.01589256  0.00201487 -0.03133505 -0.03208302\n -0.07481253  0.08426566  0.02805499 -0.00237311  0.01015061 -0.00539689\n -0.06738203 -0.07990952  0.07089893 -0.01851789  0.03935803  0.02958172\n  0.0530084   0.01942246 -0.04861339 -0.00415256  0.05399018  0.00201547\n  0.01269932  0.0119696  -0.01098885 -0.06403054  0.01135556  0.01704167\n  0.0655041  -0.04208897  0.04098273  0.03413262  0.05525799  0.02021476\n -0.00752388  0.01048278 -0.04786166 -0.01676519 -0.03733313 -0.06280202\n  0.0852387  -0.02716905 -0.04118059  0.02190659  0.02508899  0.06057035\n -0.07835048 -0.00996463 -0.02302125 -0.00674175 -0.05397704 -0.05728188\n -0.0536624   0.01773847  0.03661697  0.01621174  0.02494828 -0.07572902\n -0.01064612 -0.07356218 -0.00324107  0.07765414  0.0028583   0.04838629\n  0.00920532 -0.07121135 -0.03824746  0.01438931  0.01120961 -0.04490857\n  0.038078    0.01501934 -0.02319366 -0.01951577  0.01384894 -0.06086442\n -0.00144633  0.02102775 -0.0315279   0.03628556 -0.05821744  0.01664638\n -0.04705796 -0.04356402 -0.00115549 -0.03078086 -0.03882552  0.01321844\n  0.05290431  0.02686496  0.04933696  0.03116152 -0.03210968  0.03514811\n  0.0436458  -0.06848342 -0.04245531  0.03279216 -0.01158648  0.02537935\n -0.0253008  -0.03906662 -0.01883297  0.045422    0.05156593  0.08854867\n -0.02539958  0.01248772 -0.03449827 -0.07009625  0.00833744 -0.00425914\n -0.08653468 -0.03823084  0.05948076  0.01977122  0.02928401 -0.0143164\n  0.05043735 -0.0472074  -0.02732961 -0.02742243 -0.06850775 -0.07887203\n  0.0026359  -0.02495894  0.04978807 -0.08296442 -0.00914189 -0.00101107\n -0.0031867  -0.06896188 -0.04903021  0.06008083  0.08071644 -0.07830644\n -0.09481554  0.02727433 -0.08084035 -0.01122352  0.00857316 -0.03317966\n  0.07564183 -0.04344892  0.046821   -0.01376293  0.00761846  0.06136538\n  0.02045102 -0.06104156 -0.01107239 -0.07008964 -0.01157952 -0.05433332\n  0.06515444 -0.05604016  0.03065395 -0.01272274 -0.05509752 -0.06751832\n  0.0538918  -0.00504724  0.03702407 -0.09122626  0.02265449  0.00472093\n -0.01598676 -0.01207362 -0.06070251  0.03048434 -0.04756739 -0.00634253\n -0.04008942 -0.01092152 -0.08205862 -0.01565861  0.01136268  0.03443305\n -0.0280718   0.03576511 -0.02151014  0.01550762 -0.04489112 -0.01118302\n  0.05821012 -0.07550557  0.00550169 -0.00466101 -0.04389597  0.03390662\n -0.03825735 -0.01120692  0.02387004  0.06637103  0.02467884  0.0318739\n -0.02698353 -0.01520944  0.0564477  -0.03384753 -0.00161159 -0.02357939\n -0.05082583  0.06760366  0.02035304  0.08329184  0.02264197  0.05324714\n -0.0655792  -0.05348295  0.05402717 -0.02876278 -0.06150861 -0.04345718\n -0.05938352 -0.03567698  0.06070498 -0.01924567  0.01297939  0.00411428\n  0.04037089 -0.01622808 -0.00985875  0.05113493 -0.02768169 -0.05217825\n -0.03244691 -0.00712609  0.0283204  -0.04572985  0.05308337 -0.03491647\n -0.06565351 -0.05523159  0.04972726 -0.03133366  0.06638224  0.00290112\n -0.01365054  0.0637918   0.03256709 -0.00784845  0.07712252 -0.02365635\n  0.04905435  0.05300168 -0.06648369  0.05886498  0.04420203 -0.02844607\n -0.04016146  0.00730836 -0.01397744  0.00263133  0.07229914 -0.02193907\n -0.04573375  0.03710544  0.03418196  0.05184914  0.05041499 -0.06132943\n -0.03067985 -0.01024768  0.00039251  0.01923133  0.04486759  0.07052088\n  0.05826872  0.03309414  0.02377137 -0.0480497  -0.03125334  0.0309757\n  0.02558224  0.0429021  -0.04944043  0.05880421 -0.00047158  0.03954057\n -0.00209848 -0.06791507 -0.07130907  0.02802386  0.03345898  0.07500391\n -0.07445147  0.01437968  0.03622105  0.06087886 -0.07294495 -0.00850221\n -0.07534639 -0.07569963]",
         "0.19161547035584145"
        ],
        [
         "2",
         "2016-01-28 00:00:00",
         "the biggest potential driver for gold prices is a double-edged sword",
         "0.005662950000000001",
         "[ 5.44093959e-02 -9.33943465e-02 -1.10682822e-03  1.15485359e-02\n -3.68841439e-02 -6.35749251e-02  6.38147965e-02 -3.67092453e-02\n  5.03177941e-02 -8.63511041e-02  7.08500156e-03  6.94468617e-02\n  1.04867117e-02  2.18564197e-02 -3.57893072e-02 -3.54984291e-02\n  2.55172327e-02 -7.49444887e-02  5.24437800e-02 -1.25195999e-02\n -2.11018906e-03 -4.79667783e-02 -5.77792339e-02  3.19416225e-02\n  4.41800803e-03  6.91842809e-02 -1.40691111e-02 -2.33078264e-02\n -3.15137543e-02  1.99852809e-02 -6.35503456e-02 -6.31847531e-02\n -3.16171125e-02  6.90575838e-02 -5.65697923e-02  8.51496533e-02\n -3.48939337e-02 -1.19415941e-02 -1.91256907e-02 -6.61952607e-03\n -7.38731176e-02 -3.37516032e-02  5.97256534e-02  3.95277850e-02\n -2.09599864e-02 -1.89728513e-02  6.43935055e-02  3.88002358e-02\n  2.29368787e-02 -5.99362934e-03  1.46239009e-02 -8.41768757e-02\n  2.59964704e-03 -4.22365554e-02  4.30963188e-02 -6.73652515e-02\n -3.43060773e-03 -3.92941348e-02 -1.22651178e-02  2.69840695e-02\n -1.05548948e-02 -2.61326283e-02 -4.04204475e-03 -6.54124171e-02\n -7.53511861e-02  6.73462730e-03  5.90117089e-02  5.27698062e-02\n -9.47828591e-03  4.72888211e-03 -1.13409823e-02  2.68672705e-02\n  1.40887620e-02  3.05125900e-02 -5.01286723e-02 -1.98874380e-02\n -2.83080842e-02 -4.12114039e-02  3.83597240e-02  5.10906242e-02\n -7.09321201e-02  2.96425764e-02  7.05888122e-02  8.28365516e-03\n  2.90124156e-02 -1.58942193e-02  2.33306400e-02  3.94549854e-02\n -1.23242075e-02 -6.89664409e-02  4.23206650e-02  3.37498486e-02\n -5.09997830e-02  6.79411143e-02 -4.62779924e-02 -1.71990842e-02\n  5.32547422e-02 -6.85872063e-02 -1.58904437e-02 -2.33002175e-02\n  6.09141588e-02  4.20956984e-02  5.97504787e-02 -7.03431591e-02\n -6.16143160e-02  8.66211078e-04 -3.07084005e-02 -5.17443791e-02\n -8.75221118e-02  1.83573943e-02 -3.92077602e-02 -4.69584949e-02\n -5.66431768e-02  2.44663283e-02 -3.91100571e-02 -5.79184555e-02\n  6.60995319e-02 -7.73867033e-03 -4.33499273e-03 -5.95431961e-02\n -6.47455975e-02  6.79594800e-02 -9.21179056e-02  3.34181152e-02\n -2.91228518e-02 -6.55372068e-02 -1.12590911e-02 -1.34731075e-02\n  1.69460960e-02  3.08342241e-02 -4.74756919e-02 -3.13532799e-02\n -4.69410516e-05  1.80636384e-02 -3.15074623e-02  4.46018018e-02\n  9.07850079e-03  2.97999419e-02  1.26483422e-02 -6.07347228e-02\n  7.63446465e-02 -2.19099279e-02  3.68458927e-02 -2.24251039e-02\n -2.21331082e-02  3.73770595e-02 -5.73280826e-03 -3.61548513e-02\n -6.85198978e-02  2.47230437e-02  1.70584805e-02  5.40588461e-02\n  1.12998998e-03 -5.79590872e-02  5.68976142e-02  3.57439853e-02\n  4.65419330e-02 -2.10238863e-02 -4.71636541e-02  7.33934045e-02\n  8.75176117e-03 -4.33137603e-02 -2.25234963e-02 -4.01395857e-02\n  3.72933620e-03  3.59506868e-02 -6.38377736e-04  7.12060854e-02\n -5.05800731e-02  5.90996705e-02  7.80147500e-03 -3.06274183e-03\n  3.70282307e-02 -9.57885478e-03  5.86534962e-02  7.20729232e-02\n -4.87823412e-03  3.12966034e-02  3.41919549e-02  5.31764366e-02\n -4.29471629e-03  6.23134747e-02  7.29509592e-02 -7.65292048e-02\n -2.08829576e-03 -2.67217271e-02  2.93258820e-02 -4.81760316e-02\n  6.90756505e-03 -3.15449871e-02 -2.60880543e-03 -8.89103208e-03\n  7.36890361e-02  5.44178896e-02  7.55234733e-02 -6.83614658e-03\n -4.07281406e-02 -3.97376483e-03 -1.16670989e-02 -2.59690173e-03\n -1.84388105e-02 -2.66182404e-02 -3.50451618e-02 -7.36200362e-02\n  5.20573892e-02  3.21413651e-02 -4.51616244e-03 -3.61003093e-02\n  2.57516038e-02  3.75659056e-02  2.53902301e-02 -3.11671961e-02\n -7.35626370e-03 -5.07232025e-02  1.51398517e-02  4.79871668e-02\n  1.94854848e-02  3.16367894e-02 -4.84465063e-02 -1.46434652e-02\n  5.16402721e-02 -1.71998739e-02 -5.98718636e-02  9.15582851e-02\n -1.20817544e-02 -8.32459852e-02  1.37205552e-02 -2.98794899e-02\n -7.33953193e-02 -4.81728725e-02  3.33374925e-02 -8.27575028e-02\n  4.06691879e-02 -4.74026017e-02 -2.65939850e-02  3.40323076e-02\n -4.42407615e-02  6.02363683e-02  2.50580404e-02  3.80677953e-02\n -2.83037201e-02  3.68043594e-02  2.87661348e-02  4.69733514e-02\n  3.91704328e-02 -1.15501536e-02 -1.87032577e-02 -6.07771538e-02\n  5.80257289e-02  4.26581465e-02 -2.16491017e-02 -3.40965502e-02\n  6.79905489e-02  5.16313612e-02 -6.97432160e-02 -5.00126742e-02\n  2.06847917e-02 -5.78556880e-02  2.96057314e-02 -4.04838137e-02\n  1.11389514e-02 -3.00471205e-03  1.59229692e-02  6.05367199e-02\n -4.96166609e-02  3.88464034e-02 -3.25528719e-02 -2.72769202e-02\n -4.92337756e-02 -7.20716044e-02 -8.96272436e-02 -1.92683097e-02\n -5.95102906e-02 -4.61458303e-02  4.32182439e-02  8.59526396e-02\n  1.62633136e-02  5.25444038e-02 -4.61302288e-02 -4.43220474e-02\n  3.33023928e-02  4.40367386e-02  3.29612792e-02  4.15561460e-02\n  5.17064817e-02 -4.63146865e-02  5.21142520e-02  7.65979737e-02\n  1.30996546e-02  1.69324186e-02 -1.76285896e-02  5.25188521e-02\n  7.77875679e-03  4.86183390e-02  5.90828285e-02  3.39690149e-02\n -3.63956541e-02  1.13870930e-02 -8.37954599e-03 -8.17879513e-02\n  3.01597510e-02  2.51614265e-02 -2.96642305e-03  5.57837449e-02\n  4.76791933e-02 -4.15336229e-02 -6.47010133e-02  7.71070793e-02\n  6.74760342e-02  3.16579044e-02  2.51481757e-02 -1.87554304e-02\n  4.61826995e-02 -7.89351836e-02 -7.37438798e-02  3.24284770e-02\n  5.25388420e-02  5.93477897e-02 -1.43471099e-02 -4.96597849e-02\n -3.42350043e-02  4.79455292e-02 -1.88874360e-02  4.37386036e-02\n  5.75063936e-02  2.48435829e-02  5.37111610e-03  3.78612354e-02\n -8.12623743e-03  3.43267014e-03  5.83488122e-02  8.91579017e-02\n -3.05940360e-02 -3.02914958e-02  2.55418080e-03 -2.59014014e-02\n -7.60811493e-02 -1.19184572e-02  2.66109314e-03  6.94205463e-02\n -2.00895276e-02  3.35070156e-02 -8.14920571e-03 -1.55777810e-02\n -2.88470369e-02 -3.08291037e-02 -7.56162032e-02 -1.45251136e-02\n -1.52598983e-02  4.13510762e-02 -7.81341922e-03  3.33208032e-02\n  4.53620479e-02 -4.22601141e-02 -9.72733945e-02  3.92316990e-02\n -8.41200203e-02  2.15232894e-02  3.37373987e-02  3.54048610e-02\n -2.09196694e-02 -2.18184367e-02  2.64371745e-02 -2.51424573e-02\n -6.54617250e-02 -4.48058359e-02 -2.44422797e-02  4.77779917e-02\n  2.29347143e-02 -4.25504707e-02  1.42804561e-02 -8.69075730e-02\n  3.36230993e-02  2.81271376e-02  3.98098044e-02 -3.92152630e-02\n -2.57493481e-02 -9.02383681e-03  7.07475767e-02  3.59354466e-02\n  9.06053111e-02 -2.33570784e-02  2.64404621e-02  6.29825890e-02\n -4.23960313e-02 -1.25075667e-03 -2.41923165e-02 -6.37383237e-02\n -7.16004744e-02  1.06677068e-02 -4.76748012e-02 -6.70346320e-02\n -3.72113809e-02 -2.82942988e-02  3.15286145e-02  4.01080921e-02\n -5.99180609e-02 -5.26931994e-02  4.52600885e-03  3.92117426e-02\n  2.65088864e-02 -4.15214039e-02 -2.13077699e-04  1.76168978e-02\n  3.49445865e-02  2.02797775e-04 -1.00200567e-02 -5.96273616e-02\n -4.08559144e-02 -4.52587791e-02  1.74456351e-02 -6.34068102e-02\n  4.43927944e-02 -2.74973479e-03 -1.96399018e-02  1.07662436e-02\n -2.37456504e-02  1.48336776e-02  9.39717293e-02 -4.15151715e-02\n  3.91760804e-02 -3.62588582e-03  2.36077979e-02 -3.29076201e-02\n  8.13481063e-02  4.51621339e-02  3.65467705e-02 -2.97762267e-02\n  4.19375002e-02  5.40057123e-02 -2.06794497e-02  6.24355488e-02\n  4.65915054e-02 -2.60198712e-02  6.31593075e-03 -2.94450782e-02\n  5.95090725e-02  3.59834218e-03 -2.07804013e-02 -3.39208469e-02\n  1.90618727e-02 -5.97058721e-02 -3.63500603e-02 -8.44735280e-02\n  1.56555139e-03 -3.47233415e-02  4.23926152e-02 -6.97365105e-02\n  5.69340698e-02  2.93876254e-03  5.39295599e-02  5.24734668e-02\n  1.07653849e-02  5.05300686e-02  1.40108494e-02 -5.18845059e-02\n  5.41204168e-03  4.96590622e-02 -1.49667170e-02  7.68182427e-02\n  2.02312581e-02 -4.00459282e-02  1.61597226e-02  4.28855158e-02\n -2.98380610e-02  4.32815403e-02  4.47352566e-02 -5.89774139e-02\n  5.97664679e-04  8.99986643e-03 -3.47771086e-02  3.61069217e-02\n  2.79790685e-02  1.26778036e-02 -2.27304902e-02 -1.57137085e-02\n -5.24103455e-02  1.90399718e-02  8.98043588e-02 -6.41153306e-02\n -7.56124966e-03  3.73251848e-02  4.47866470e-02 -4.47667055e-02\n -4.65977043e-02 -1.08843707e-02 -4.32783477e-02 -5.36240675e-02\n  6.46589622e-02 -3.45440954e-02  8.32766816e-02 -7.79405003e-03\n -5.63397184e-02 -6.25280738e-02  6.24103844e-02  1.95147973e-02\n -2.23078951e-02  6.00282028e-02  1.11205671e-02 -6.76011201e-03\n -4.93252315e-02  4.18042056e-02 -3.51784453e-02  8.82937312e-02\n -5.29186539e-02 -3.16069797e-02  5.36214821e-02  3.37711275e-02\n -8.18192884e-02 -4.63096537e-02 -4.33977693e-02 -3.55511867e-02]",
         "[ 3.08117713e-04 -5.28887555e-04 -6.26791325e-06  6.53987809e-05\n -2.08873069e-04 -3.60021630e-04  3.61380022e-04 -2.07882622e-04\n  2.84947164e-04 -4.89001977e-04  4.01220095e-05  3.93274124e-04\n  5.93857258e-05  1.23771824e-04 -2.02673065e-04 -2.01025832e-04\n  1.44502817e-04 -4.24406899e-04  2.96986516e-04 -7.08978696e-05\n -1.19498955e-05 -2.71633471e-04 -3.27200920e-04  1.80883813e-04\n  2.50189587e-05  3.91787151e-04 -7.96726745e-05 -1.31991066e-04\n -1.78460818e-04  1.13175651e-04 -3.59882455e-04 -3.57812125e-04\n -1.79046139e-04  3.91069654e-04 -3.20351915e-04  4.82198258e-04\n -1.97602611e-04 -6.76246564e-05 -1.08307831e-04 -3.74860465e-05\n -4.18339798e-04 -1.91133644e-04  3.38223414e-04  2.23843876e-04\n -1.18695360e-04 -1.07442313e-04  3.64657230e-04  2.19723806e-04\n  1.29890395e-04 -3.39416256e-05  8.28144257e-05 -4.76689456e-04\n  1.47216715e-05 -2.39183515e-04  2.44052309e-04 -3.81486054e-04\n -1.94273616e-05 -2.22520728e-04 -6.94567498e-05  1.52809444e-04\n -5.97718426e-05 -1.47987768e-04 -2.28898989e-05 -3.70427268e-04\n -4.26710030e-04  3.81378595e-05  3.34180368e-04  2.98832776e-04\n -5.36750631e-05  2.67794239e-05 -6.42234154e-05  1.52148015e-04\n  7.97839602e-05  1.72791275e-04 -2.83876172e-04 -1.12621572e-04\n -1.60307274e-04 -2.33378130e-04  2.17229201e-04  2.89323652e-04\n -4.01685073e-04  1.67864433e-04  3.99740937e-04  4.69099250e-05\n  1.64295867e-04 -9.00081723e-05  1.32120258e-04  2.23431620e-04\n -6.97913711e-05 -3.90553527e-04  2.39659814e-04  1.91123720e-04\n -2.88809242e-04  3.84747138e-04 -2.62069982e-04 -9.73975548e-05\n  3.01578955e-04 -3.88405926e-04 -8.99867882e-05 -1.31947978e-04\n  3.44953849e-04  2.38385852e-04  3.38363985e-04 -3.98349803e-04\n -3.48918809e-04  4.90531011e-06 -1.73900145e-04 -2.93025834e-04\n -4.95633343e-04  1.03957012e-04 -2.22031595e-04 -2.65923620e-04\n -3.20767489e-04  1.38551593e-04 -2.21478302e-04 -3.27989343e-04\n  3.74318362e-04 -4.38237039e-05 -2.45488482e-05 -3.37190169e-04\n -3.66651104e-04  3.84851155e-04 -5.21659094e-04  1.89245126e-04\n -1.64921265e-04 -3.71133938e-04 -6.37596750e-05 -7.62975396e-05\n  9.59648969e-05  1.74612680e-04 -2.68852484e-04 -1.77552065e-04\n -2.65824838e-07  1.02293488e-04 -1.78425194e-04  2.52577796e-04\n  5.14110980e-05  1.68755592e-04  7.16269351e-05 -3.43937718e-04\n  4.32335946e-04 -1.24074824e-04  2.08656449e-04 -1.26992250e-04\n -1.25338687e-04  2.11664432e-04 -3.24646062e-05 -2.04743119e-04\n -3.88024782e-04  1.40005359e-04  9.66013249e-05  3.06132541e-04\n  6.39907694e-06 -3.28219438e-04  3.22208361e-04  2.02416413e-04\n  2.63564638e-04 -1.19057222e-04 -2.67085416e-04  4.15623188e-04\n  4.95607892e-05 -2.45283678e-04 -1.27549443e-04 -2.27308483e-04\n  2.11190454e-05  2.03586955e-04 -3.61510138e-06  4.03236510e-04\n -2.86432449e-04  3.34678480e-04  4.41793636e-05 -1.73441549e-05\n  2.09689024e-04 -5.42445778e-05  3.32151831e-04  4.08145366e-04\n -2.76251976e-05  1.77231108e-04  1.93627333e-04  3.01135500e-04\n -2.43207651e-05  3.52878094e-04  4.13117639e-04 -4.33381065e-04\n -1.18259150e-05 -1.51323809e-04  1.66071011e-04 -2.72818463e-04\n  3.91171961e-05 -1.78637696e-04 -1.47735354e-05 -5.03494703e-05\n  4.17297357e-04  3.08165792e-04  4.27685678e-04 -3.87127584e-05\n -2.30641439e-04 -2.25032327e-05 -6.60701990e-05 -1.47061255e-05\n -1.04418068e-04 -1.50737775e-04 -1.98459005e-04 -4.16906609e-04\n  2.94798403e-04  1.82014948e-04 -2.55748037e-05 -2.04434255e-04\n  1.45830054e-04  2.12733852e-04  1.43783604e-04 -1.76498274e-04\n -4.16581533e-05 -2.87242961e-04  8.57362247e-05  2.71748926e-04\n  1.10345332e-04  1.79157563e-04 -2.74350139e-04 -8.29252167e-05\n  2.92436278e-04 -9.74020295e-05 -3.39051388e-04  5.18490036e-04\n -6.84183760e-05 -4.71417879e-04  7.76988236e-05 -1.69206061e-04\n -4.15634044e-04 -2.72800593e-04  1.88788559e-04 -4.68651619e-04\n  2.30307589e-04 -2.68438569e-04 -1.50600419e-04  1.92723266e-04\n -2.50533223e-04  3.41115549e-04  1.41902434e-04  2.15576030e-04\n -1.60282550e-04  2.08421261e-04  1.62901182e-04  2.66007759e-04\n  2.21820213e-04 -6.54079413e-05 -1.05915620e-04 -3.44177999e-04\n  3.28596827e-04  2.41570960e-04 -1.22597790e-04 -1.93087064e-04\n  3.85027088e-04  2.92385841e-04 -3.94952367e-04 -2.83219299e-04\n  1.17136944e-04 -3.27633868e-04  1.67655788e-04 -2.29257828e-04\n  6.30793293e-05 -1.70155345e-05  9.01709791e-05  3.42816435e-04\n -2.80976674e-04  2.19985246e-04 -1.84345292e-04 -1.54467838e-04\n -2.78808409e-04 -4.08137916e-04 -5.07554621e-04 -1.09115477e-04\n -3.37003818e-04 -2.61321547e-04  2.44742754e-04  4.86745528e-04\n  9.20983366e-05  2.97556340e-04 -2.61233188e-04 -2.50993558e-04\n  1.88589795e-04  2.49377859e-04  1.86658086e-04  2.35330386e-04\n  2.92811223e-04 -2.62277754e-04  2.95120408e-04  4.33770503e-04\n  7.41826952e-05  9.58874443e-05 -9.98298274e-05  2.97411636e-04\n  4.40507138e-05  2.75323226e-04  3.34583106e-04  1.92364838e-04\n -2.06106779e-04  6.44845422e-05 -4.74529515e-05 -4.63161094e-04\n  1.70793166e-04  1.42487901e-04 -1.67987055e-05  3.15900572e-04\n  2.70004908e-04 -2.35202839e-04 -3.66398628e-04  4.36653558e-04\n  3.82113416e-04  1.79277136e-04  1.42412871e-04 -1.06211068e-04\n  2.61530338e-04 -4.47006023e-04 -4.17607924e-04  1.83640848e-04\n  2.97524850e-04  3.36083584e-04 -8.12469661e-05 -2.81220884e-04\n -1.93871121e-04  2.71513156e-04 -1.06958607e-04  2.47689546e-04\n  3.25655856e-04  1.40687975e-04  3.04163623e-05  2.14406289e-04\n -4.60184783e-05  1.94390395e-05  3.30426410e-04  5.04896743e-04\n -1.73252498e-04 -1.71539228e-04  1.44641990e-05 -1.46678343e-04\n -4.30843764e-04 -6.74936309e-05  1.50696378e-05  3.93125112e-04\n -1.13765993e-04  1.89748564e-04 -4.61485470e-05 -8.82161985e-05\n -1.63359335e-04 -1.74583678e-04 -4.28210798e-04 -8.22549919e-05\n -8.64160465e-05  2.34169085e-04 -4.42470046e-05  1.88694044e-04\n  2.56883010e-04 -2.39316927e-04 -5.50854369e-04  2.22167160e-04\n -4.76367481e-04  1.21885314e-04  1.91053216e-04  2.00495968e-04\n -1.18467047e-04 -1.23556718e-04  1.49712403e-04 -1.42380479e-04\n -3.70706490e-04 -2.53733218e-04 -1.38415417e-04  2.70564400e-04\n  1.29878143e-04 -2.40961192e-04  8.08695113e-05 -4.92153282e-04\n  1.90405932e-04  1.59282587e-04  2.25440934e-04 -2.22074086e-04\n -1.45817277e-04 -5.11015387e-05  4.00640012e-04  2.03500647e-04\n  5.13093371e-04 -1.32269968e-04  1.49731015e-04  3.56667268e-04\n -2.40086621e-04 -7.08297284e-06 -1.36999879e-04 -3.60946957e-04\n -4.05469909e-04  6.04106935e-05 -2.69980024e-04 -3.79613775e-04\n -2.10726197e-04 -1.60229203e-04  1.78544971e-04  2.27130135e-04\n -3.39313003e-04 -2.98398954e-04  2.56305630e-05  2.22054150e-04\n  1.50118503e-04 -2.35133644e-04 -1.20664845e-06  9.97636162e-05\n  1.97889458e-04  1.14843374e-06 -5.67430834e-05 -3.37666774e-04\n -2.31365004e-04 -2.56298226e-04  9.87937601e-05 -3.59069614e-04\n  2.51394173e-04 -1.55716116e-05 -1.11219786e-04  6.09687013e-05\n -1.34470436e-04  8.40023786e-05  5.32157253e-04 -2.35098356e-04\n  2.21852199e-04 -2.05332108e-05  1.33689784e-04 -1.86354213e-04\n  4.60670271e-04  2.55750929e-04  2.06962548e-04 -1.68621293e-04\n  2.37489978e-04  3.05831665e-04 -1.17106691e-04  3.53569398e-04\n  2.63845373e-04 -1.47349230e-04  3.57668032e-05 -1.66746016e-04\n  3.36996920e-04  2.03772324e-05 -1.17678377e-04 -1.92092062e-04\n  1.07946435e-04 -3.38111393e-04 -2.05848584e-04 -4.78369388e-04\n  8.86563976e-06 -1.96636553e-04  2.40067267e-04 -3.94914387e-04\n  3.22414795e-04  1.66420668e-05  3.05400405e-04  2.97154620e-04\n  6.09638373e-05  2.86149269e-04  7.93427462e-05 -2.93819379e-04\n  3.06481234e-05  2.81216810e-04 -8.47557749e-05  4.35017893e-04\n  1.14568611e-04 -2.26778095e-04  9.15117053e-05  2.42858543e-04\n -1.68971455e-04  2.45101197e-04  2.53333536e-04 -3.33986158e-04\n  3.38454538e-06  5.09657948e-05 -1.96941037e-04  2.04471697e-04\n  1.58444076e-04  7.17937728e-05 -1.28721629e-04 -8.89859512e-05\n -2.96797167e-04  1.07822416e-04  5.08557598e-04 -3.63081926e-04\n -4.28189815e-05  2.11370658e-04  2.53624545e-04 -2.53511622e-04\n -2.63880473e-04 -6.16376492e-05 -2.45083123e-04 -3.03670415e-04\n  3.66160471e-04 -1.95621498e-04  4.71591717e-04 -4.41373159e-05\n -3.19049024e-04 -3.54093383e-04  3.53426905e-04  1.10511326e-04\n -1.26328494e-04  3.39936727e-04  6.29752176e-05 -3.82821781e-05\n -2.79326341e-04  2.36735141e-04 -1.99213784e-04  5.00002992e-04\n -2.99675710e-04 -1.78988746e-04  3.03655775e-04  1.91244209e-04\n -4.63338569e-04 -2.62249261e-04 -2.45759409e-04 -2.01324598e-04]",
         "0.19161547035584145"
        ],
        [
         "3",
         "2016-01-28 00:00:00",
         "buy comex gold if it touches $1,107-08/ounce",
         "0.0025896",
         "[-8.77055991e-03 -1.73022766e-02  8.38129371e-02 -3.87716740e-02\n  3.11674252e-02 -6.27548918e-02 -3.01280357e-02 -5.79932891e-02\n  1.34446789e-02 -4.03379686e-02 -1.62136350e-02 -1.82772223e-02\n  2.17753109e-02 -6.95542619e-02 -1.43388119e-02 -1.90883987e-02\n  2.85436679e-02 -6.04143329e-02  5.58955893e-02 -2.03214074e-03\n  8.44140649e-02 -5.57735860e-02  1.98706985e-02 -3.82054523e-02\n  2.38467269e-02 -6.57607149e-03 -7.83756599e-02  2.13554110e-02\n -3.20055932e-02  3.42553332e-02  2.09156293e-02 -4.87830751e-02\n -2.41860654e-02  6.26342893e-02  1.21938027e-02  2.89444588e-02\n -1.31513728e-02  1.19674550e-02  1.69191917e-03 -6.88318908e-02\n  6.41783997e-02 -2.75772363e-02  9.87042207e-03  2.41804379e-03\n  2.96934461e-03  4.66744937e-02  4.31132019e-02 -6.39880747e-02\n -4.76317480e-02 -4.07279916e-02  3.15876789e-02 -1.46175418e-02\n  3.43094766e-02 -2.10928861e-02 -3.67004308e-04 -2.97027901e-02\n  3.03813685e-02 -4.14636947e-04 -7.64227137e-02 -8.45175702e-03\n -3.36156925e-03 -4.88763265e-02 -3.94026889e-03 -8.77061263e-02\n  2.09472906e-02  5.02779186e-02 -4.19548601e-02  2.70712823e-02\n  5.59495017e-02 -1.59159340e-02 -5.87538704e-02 -2.71423329e-02\n -8.47052783e-02 -6.64963126e-02 -7.53315240e-02  5.11191636e-02\n -4.39102650e-02 -2.03223377e-02  1.70899350e-02 -1.00408368e-01\n -5.70007153e-02  2.83675101e-02  2.38621086e-02  4.23037261e-03\n  6.07533567e-03 -3.69612947e-02  5.51168323e-02  6.28959527e-03\n  3.42681562e-03 -3.56654786e-02  1.76891033e-02  6.73248956e-04\n -7.46561959e-02  2.29411498e-02 -1.23982942e-02 -3.30043919e-02\n  1.62094310e-02  3.79538313e-02 -2.77102664e-02  4.41787802e-02\n  7.28209242e-02  1.81334782e-02  7.53847808e-02 -8.09530634e-03\n -2.27209795e-02 -1.50842443e-02  3.03381868e-02 -6.02166615e-02\n -9.23272744e-02  1.09609291e-02 -4.80071418e-02  6.04228079e-02\n -4.08279113e-02 -6.30867258e-02 -4.23334502e-02  6.23222906e-03\n -5.45828119e-02 -1.50133129e-02  9.73558926e-05  3.35964840e-03\n -2.82067545e-02  5.54369278e-02 -4.43360098e-02 -2.32481863e-02\n  1.27486251e-02 -4.86498885e-02  3.40516865e-02 -2.20720610e-03\n  6.65360913e-02  3.14197913e-02  6.36490202e-03 -9.72537207e-04\n  1.18062515e-02 -4.10364568e-02  3.46609354e-02  3.44579667e-02\n -8.35905373e-02  4.63256799e-02 -3.88826542e-02 -2.30981540e-02\n -5.19114882e-02 -3.78287002e-03  3.25273424e-02 -3.51867713e-02\n  3.87099059e-03 -3.62466052e-02  9.41955019e-03 -5.95508236e-03\n -9.03084874e-02 -6.75712712e-03  5.53966202e-02 -3.26973051e-02\n  1.73678212e-02 -4.66930829e-02  5.18373996e-02  1.49653926e-02\n  3.36405784e-02 -6.21169247e-02  9.19420868e-02  4.07599006e-03\n -2.99354382e-02  6.48847595e-02 -4.63982187e-02 -6.39747828e-02\n  2.61455663e-02 -8.48732814e-02 -7.26440698e-02  8.91479626e-02\n -2.55384985e-02  2.23580897e-02  4.36682366e-02  1.08929519e-02\n -7.00765522e-03 -8.37828740e-02 -3.71131301e-02  1.10075008e-02\n -4.15059850e-02  2.03849822e-02 -2.47311890e-02 -3.20474245e-02\n  6.11707419e-02 -1.45087428e-02 -8.79641064e-03 -4.46189083e-02\n  6.96008503e-02  7.61101535e-03 -4.46795337e-02  1.71170552e-06\n  2.94626672e-02  9.11972225e-02  5.87892160e-02 -1.09809889e-02\n  2.39990000e-02 -3.14141827e-04 -1.98101196e-02  7.13707060e-02\n -5.72952554e-02 -1.66910794e-02  2.38520093e-02  1.42982397e-02\n -1.77759677e-02 -1.17952665e-02 -2.82397214e-02 -3.92849557e-02\n  5.78376241e-02 -6.44463748e-02 -4.20186222e-02 -4.96928804e-02\n -2.20337939e-02  3.75882164e-02 -2.87603904e-02 -8.33385717e-03\n  4.98001911e-02  1.01042474e-02  4.10698354e-02 -3.34190694e-03\n -1.59493685e-02  3.42619419e-02 -4.93462421e-02  7.35710412e-02\n -9.01010074e-03 -7.45645687e-02 -2.37898584e-02  6.32275417e-02\n  9.61690443e-04 -8.82469490e-03  5.91933653e-02  2.21412107e-02\n -7.39865378e-02 -1.01670854e-01  7.25613758e-02 -3.75849344e-02\n -3.43179107e-02  8.93406868e-02  3.83597538e-02 -3.21921110e-02\n -1.37979621e-02  1.49012785e-02  2.91381823e-03 -4.65956591e-02\n -5.38759455e-02  2.30648052e-02  1.69423353e-02  1.28808338e-02\n -5.73245343e-03 -1.61664635e-02 -4.24278490e-02 -6.95932209e-02\n -8.12148601e-02  6.06952943e-02 -3.33539993e-02 -2.94925421e-02\n -3.03477012e-02 -4.46593529e-03 -4.80040349e-02  3.70244030e-03\n  7.72447437e-02  3.41759883e-02  3.80983464e-02 -6.15933761e-02\n -2.22795997e-02  1.37561122e-02 -7.06527242e-03  3.03923357e-02\n  2.86080297e-02  1.50889726e-02  2.72075064e-03  7.47000799e-03\n -8.37296131e-04 -5.89777417e-02 -2.84449793e-02 -1.47882728e-02\n -6.47742003e-02 -3.21428701e-02  3.82468589e-02 -5.19605465e-02\n -2.00208686e-02  1.93224242e-03 -8.20921548e-03 -1.47731612e-02\n -6.88801035e-02  5.88416681e-02  1.65771414e-02 -1.73937492e-02\n -4.11066934e-02  4.96516470e-03  5.57688251e-02 -2.83525251e-02\n  8.07835907e-02  6.27754554e-02 -2.48969402e-02  1.11379707e-02\n -3.80958850e-03  5.74877895e-02  1.01796620e-01  4.27345783e-02\n  1.62229706e-02  3.91371623e-02  1.47110038e-02 -5.00024818e-02\n -6.85186461e-02 -4.04564291e-02 -2.46618260e-02  3.69344885e-03\n -3.60680819e-02  6.01081774e-02 -5.84634878e-02  4.34162058e-02\n  3.52308787e-02 -7.42832124e-02  5.99217974e-02  9.99388844e-02\n  5.60757071e-02 -6.01698235e-02 -1.99835561e-02  3.31764892e-02\n  6.61833212e-02  7.59462714e-02 -8.78825709e-02 -4.21686247e-02\n  1.15028825e-02  3.91024426e-02 -1.59756769e-03  3.26762237e-02\n -1.59527687e-03  6.73450297e-03 -4.49397676e-02 -5.88700213e-02\n  3.99359316e-02 -5.39908074e-02 -7.56302476e-02 -1.63955409e-02\n  1.98435895e-02  5.23007810e-02  2.75731292e-02  4.36813533e-02\n  1.24600502e-02  2.44969930e-02  6.87801912e-02  2.10674070e-02\n -7.77091458e-03  8.15689471e-03 -2.24432535e-02  3.56027782e-02\n  4.21219729e-02 -7.51366988e-02 -7.05201551e-02  5.46579342e-03\n  1.98655087e-03 -6.46384433e-02 -2.68200114e-02  5.75791672e-02\n  6.11674003e-02 -9.12565459e-03 -1.02750942e-01  5.84654994e-02\n -8.82159919e-02  4.57735360e-02  7.63198808e-02  1.87193304e-02\n  5.29698748e-03  1.19780153e-02  5.13477474e-02  2.20179167e-02\n -2.49530859e-02 -8.68244618e-02  3.67193893e-02 -6.70237392e-02\n  1.61152761e-02 -6.38573915e-02 -1.42304897e-02  2.46218015e-02\n  2.63311975e-02 -5.46200667e-03  2.18550824e-02  8.07890072e-02\n -6.70139641e-02 -4.48341183e-02  5.80216832e-02  9.06114951e-02\n -2.63484986e-03 -6.97809383e-02 -3.25808637e-02  9.35394841e-04\n -5.94011098e-02 -5.88454008e-02 -7.09366351e-02  2.75948159e-02\n -7.41899088e-02  3.91749144e-02 -9.74548310e-02 -6.66838065e-02\n -7.27668479e-02  3.18529494e-02 -4.28967178e-03 -2.00775024e-02\n -5.09143136e-02  1.18523883e-02  9.50554572e-03  9.44297761e-02\n  2.64134072e-02  7.06429302e-04  2.71447632e-03 -6.03476353e-03\n  5.19003645e-02  3.43058184e-02  1.93695147e-02 -6.11415021e-02\n  2.97263241e-03  3.72468941e-02  5.38527593e-02 -1.19124316e-02\n -2.42310632e-02 -3.63085270e-02 -4.56156246e-02 -2.37574149e-02\n  4.73076291e-02 -5.16842753e-02  5.57080396e-02 -5.01786582e-02\n -1.09195365e-02  5.43127544e-02 -5.39937988e-02  4.42778766e-02\n  4.74760532e-02 -5.68775721e-02 -7.80678317e-02  1.60967968e-02\n -2.74207592e-02 -4.97310013e-02 -1.84811223e-02  6.26926497e-02\n  3.04049402e-02  2.96270172e-03  4.52123694e-02  5.58371888e-03\n -4.86808456e-02 -2.57950611e-02  5.00634573e-02  3.42790373e-02\n  2.08875611e-02 -7.27464557e-02 -7.11994525e-03 -5.03819324e-02\n  3.62848714e-02 -5.07793436e-03  6.74570426e-02  6.34808280e-03\n  3.27090919e-02 -6.88621774e-02 -2.14208681e-02  2.22967472e-02\n -1.28926826e-03 -5.40224761e-02 -7.69890053e-03 -3.02125234e-02\n -5.32888286e-02 -1.25604374e-02  6.76948484e-03  4.57430594e-02\n  2.12850329e-02 -8.64145532e-02 -1.00097805e-02 -5.52727468e-02\n -4.01990898e-02  3.96862812e-03  5.27487956e-02  5.20833656e-02\n -2.41524763e-02  1.34395156e-02 -4.47588116e-02  7.54211396e-02\n  6.16764873e-02 -8.77961796e-03 -1.52564673e-02  8.04415643e-02\n -3.47158266e-03  6.14130683e-02  8.81360564e-03 -2.40995083e-02\n  1.25265634e-02 -2.62110494e-02 -1.15575241e-02  8.84937495e-03\n  4.17907462e-02  2.43299622e-02 -7.77127827e-03 -3.01842671e-02\n  7.42699206e-02 -2.48604547e-02  7.60125965e-02  4.97208647e-02\n  9.75298416e-03  7.60823116e-02  4.73271646e-02  3.67701761e-02\n -7.54890451e-03  2.95497533e-02  2.26873737e-02  5.97444456e-03\n -4.72508417e-03  2.54094210e-02 -2.36740778e-03 -1.56473108e-02\n -6.80327192e-02 -5.07363863e-02  1.22220153e-02  7.31690377e-02\n -1.54905245e-02 -4.31841798e-02 -4.89969440e-02 -5.97113743e-02]",
         "[-2.27122418e-05 -4.48059727e-05  2.17041976e-04 -1.00403122e-04\n  8.07111646e-05 -1.62510070e-04 -7.80195624e-05 -1.50179418e-04\n  3.48163412e-05 -1.04459199e-04 -4.19868265e-05 -4.73306936e-05\n  5.63893445e-05 -1.80117713e-04 -3.71317874e-05 -4.94313172e-05\n  7.39166790e-05 -1.56448950e-04  1.44747217e-04 -5.26243139e-06\n  2.18598652e-04 -1.44431280e-04  5.14571584e-05 -9.89368345e-05\n  6.17534824e-05 -1.70293952e-05 -2.02961601e-04  5.53019709e-05\n -8.28816846e-05  8.87076094e-05  5.41631125e-05 -1.26328654e-04\n -6.26322362e-05  1.62197757e-04  3.15770703e-05  7.49545652e-05\n -3.40567931e-05  3.09909192e-05  4.38139386e-06 -1.78247064e-04\n  1.66196376e-04 -7.14140115e-05  2.55604446e-05  6.26176598e-06\n  7.68941482e-06  1.20868266e-04  1.11645946e-04 -1.65703517e-04\n -1.23347170e-04 -1.05469204e-04  8.17994514e-05 -3.78535842e-05\n  8.88478171e-05 -5.46221381e-05 -9.50394337e-07 -7.69183462e-05\n  7.86755918e-05 -1.07374376e-06 -1.97904257e-04 -2.18866699e-05\n -8.70511940e-06 -1.26570128e-04 -1.02037202e-05 -2.27123775e-04\n  5.42451016e-05  1.30199696e-04 -1.08646302e-04  7.01037934e-05\n  1.44886828e-04 -4.12159025e-05 -1.52149019e-04 -7.02877805e-05\n -2.19352776e-04 -1.72198852e-04 -1.95078508e-04  1.32378176e-04\n -1.13710019e-04 -5.26267249e-05  4.42560959e-05 -2.60017492e-04\n -1.47609055e-04  7.34605055e-05  6.17933183e-05  1.09549728e-05\n  1.57326886e-05 -9.57149678e-05  1.42730540e-04  1.62875349e-05\n  8.87408169e-06 -9.23593179e-05  4.58077011e-05  1.74344541e-06\n -1.93329673e-04  5.94084013e-05 -3.21066218e-05 -8.54681712e-05\n  4.19759417e-05  9.82852362e-05 -7.17585062e-05  1.14405368e-04\n  1.88577062e-04  4.69584556e-05  1.95216417e-04 -2.09636055e-05\n -5.88382463e-05 -3.90621572e-05  7.85637676e-05 -1.55937058e-04\n -2.39090703e-04  2.83844220e-05 -1.24319296e-04  1.56470895e-04\n -1.05727959e-04 -1.63369376e-04 -1.09626701e-04  1.61389798e-05\n -1.41347642e-04 -3.88784756e-05  2.52112812e-07  8.70014537e-06\n -7.30442116e-05  1.43559460e-04 -1.14812530e-04 -6.02035034e-05\n  3.30138391e-05 -1.25983745e-04  8.81802480e-05 -5.71578084e-06\n  1.72301850e-04  8.13646911e-05  1.64825506e-05 -2.51848223e-06\n  3.05734684e-05 -1.06268002e-04  8.97579594e-05  8.92323515e-05\n -2.16466055e-04  1.19964978e-04 -1.00690515e-04 -5.98149782e-05\n -1.34429982e-04 -9.79612014e-06  8.42328009e-05 -9.11196621e-05\n  1.00243169e-05 -9.38642042e-05  2.43928662e-05 -1.54212812e-05\n -2.33862855e-04 -1.74982561e-05  1.43455080e-04 -8.46729381e-05\n  4.49757099e-05 -1.20916404e-04  1.34238129e-04  3.87543805e-05\n  8.71156371e-05 -1.60857977e-04  2.38093227e-04  1.05551835e-05\n -7.75208100e-05  1.68025566e-04 -1.20152821e-04 -1.65669087e-04\n  6.77065545e-05 -2.19787849e-04 -1.88119084e-04  2.30857564e-04\n -6.61344966e-05  5.78985091e-05  1.13083261e-04  2.82083874e-05\n -1.81470241e-05 -2.16964123e-04 -9.61081605e-05  2.85050228e-05\n -1.07483895e-04  5.27889497e-05 -6.40438884e-05 -8.29900091e-05\n  1.58407754e-04 -3.75718409e-05 -2.27791843e-05 -1.15545125e-04\n  1.80238363e-04  1.97094851e-05 -1.15702118e-04  4.43263248e-09\n  7.62965210e-05  2.36164327e-04  1.52240551e-04 -2.84363687e-05\n  6.21478102e-05 -8.13501629e-07 -5.13002851e-05  1.84821576e-04\n -1.48371793e-04 -4.32232191e-05  6.17671612e-05  3.70267189e-05\n -4.60326446e-05 -3.05450230e-05 -7.31295804e-05 -1.01732316e-04\n  1.49776301e-04 -1.66890328e-04 -1.08811422e-04 -1.28684682e-04\n -5.70587108e-05  9.73384449e-05 -7.44779027e-05 -2.15813561e-05\n  1.28962565e-04  2.61659588e-05  1.06354441e-04 -8.65420225e-06\n -4.13024827e-05  8.87247224e-05 -1.27787018e-04  1.90519568e-04\n -2.33325554e-05 -1.93092405e-04 -6.16062171e-05  1.63734032e-04\n  2.49039340e-06 -2.28524295e-05  1.53287139e-04  5.73368779e-05\n -1.91595536e-04 -2.63286842e-04  1.87904938e-04 -9.73299466e-05\n -8.88696595e-05  2.31356637e-04  9.93364156e-05 -8.33646918e-05\n -3.57312019e-05  3.85883504e-05  7.54562370e-06 -1.20664117e-04\n -1.39517142e-04  5.97286162e-05  4.38738716e-05  3.33562057e-05\n -1.48447607e-05 -4.18646741e-05 -1.09871158e-04 -1.80218602e-04\n -2.10314000e-04  1.57176532e-04 -8.63735113e-05 -7.63738863e-05\n -7.85884040e-05 -1.15649855e-05 -1.24311249e-04  9.58783949e-06\n  2.00032984e-04  8.85021364e-05  9.86594750e-05 -1.59502204e-04\n -5.76952480e-05  3.56228265e-05 -1.82962285e-05  7.87039899e-05\n  7.40833493e-05  3.90744026e-05  7.04565582e-06  1.93443320e-05\n -2.16826197e-06 -1.52728753e-04 -7.36611182e-05 -3.82957114e-05\n -1.67739257e-04 -8.32371734e-05  9.90440603e-05 -1.34557034e-04\n -5.18460402e-05  5.00373471e-06 -2.12585837e-05 -3.82565777e-05\n -1.78371905e-04  1.52376379e-04  4.29281645e-05 -4.50428524e-05\n -1.06449894e-04  1.28577904e-05  1.44418940e-04 -7.34216956e-05\n  2.09197184e-04  1.62563316e-04 -6.44731117e-05  2.88428873e-05\n -9.86530995e-06  1.48870371e-04  2.63612514e-04  1.10665460e-04\n  4.20110046e-05  1.01349593e-04  3.80956153e-05 -1.29486420e-04\n -1.77435883e-04 -1.04765968e-04 -6.38642596e-05  9.56455460e-06\n -9.34019045e-05  1.55656133e-04 -1.51397049e-04  1.12430600e-04\n  9.12338801e-05 -1.92363805e-04  1.55173475e-04  2.58801738e-04\n  1.45213649e-04 -1.55815767e-04 -5.17494154e-05  8.59138308e-05\n  1.71388325e-04  1.96670459e-04 -2.27580706e-04 -1.09199871e-04\n  2.97878632e-05  1.01259684e-04 -4.13706130e-06  8.46183466e-05\n -4.13112866e-06  1.74396682e-05 -1.16376017e-04 -1.52449808e-04\n  1.03418082e-04 -1.39814598e-04 -1.95852088e-04 -4.24578902e-05\n  5.13869563e-05  1.35438095e-04  7.14033740e-05  1.13117232e-04\n  3.22665437e-05  6.34374082e-05  1.78113172e-04  5.45561561e-05\n -2.01235598e-05  2.11230945e-05 -5.81190470e-05  9.21969549e-05\n  1.09079061e-04 -1.94573993e-04 -1.82618984e-04  1.41542187e-05\n  5.14437215e-06 -1.67387712e-04 -6.94530972e-05  1.49107014e-04\n  1.58399096e-04 -2.36317937e-05 -2.66083836e-04  1.51402259e-04\n -2.28444129e-04  1.18535143e-04  1.97637957e-04  4.84755765e-05\n  1.37170782e-05  3.10182659e-05  1.32970119e-04  5.70175944e-05\n -6.46185072e-05 -2.24840624e-04  9.50885296e-05 -1.73564666e-04\n  4.17321171e-05 -1.65365098e-04 -3.68512738e-05  6.37606136e-05\n  6.81872698e-05 -1.41444125e-05  5.65959199e-05  2.09211212e-04\n -1.73539360e-04 -1.16102427e-04  1.50252949e-04  2.34647523e-04\n -6.82320706e-06 -1.80704708e-04 -8.43714006e-05  2.42229839e-06\n -1.53825109e-04 -1.52386041e-04 -1.83697499e-04  7.14595299e-05\n -1.92122185e-04  1.01447353e-04 -2.52369035e-04 -1.72684377e-04\n -1.88437029e-04  8.24863964e-05 -1.11085337e-05 -5.19926980e-05\n -1.31847701e-04  3.06929433e-05  2.46155614e-05  2.44535331e-04\n  6.84001570e-05  1.82936924e-06  7.02940770e-06 -1.56276237e-05\n  1.34401183e-04  8.88383438e-05  5.01592949e-05 -1.58332026e-04\n  7.69792860e-06  9.64545543e-05  1.39457101e-04 -3.08484305e-05\n -6.27487607e-05 -9.40245591e-05 -1.18126220e-04 -6.15222016e-05\n  1.22507830e-04 -1.33841590e-04  1.44261532e-04 -1.29942651e-04\n -2.82772307e-05  1.40648306e-04 -1.39822339e-04  1.14661983e-04\n  1.22943980e-04 -1.47290149e-04 -2.02164447e-04  4.16842631e-05\n -7.10087988e-05 -1.28783402e-04 -4.78587135e-05  1.62348879e-04\n  7.87366298e-05  7.67221172e-06  1.17081945e-04  1.44595979e-05\n -1.26063911e-04 -6.67988861e-05  1.29644322e-04  8.87689894e-05\n  5.40904257e-05 -1.88384220e-04 -1.84378096e-05 -1.30469052e-04\n  9.39633028e-05 -1.31498182e-05  1.74686749e-04  1.64389949e-05\n  8.47034607e-05 -1.78325485e-04 -5.54714788e-05  5.77396531e-05\n -3.33868888e-06 -1.39896598e-04 -1.99370716e-05 -7.82383504e-05\n -1.37996743e-04 -3.25265064e-05  1.75302575e-05  1.18456221e-04\n  5.51197190e-05 -2.23779120e-04 -2.59213266e-05 -1.43134297e-04\n -1.04099563e-04  1.02771592e-05  1.36598275e-04  1.34875081e-04\n -6.25452521e-05  3.48029680e-05 -1.15907416e-04  1.95310582e-04\n  1.59717427e-04 -2.27356977e-05 -3.95081479e-05  2.08311467e-04\n -8.99001043e-06  1.59035277e-04  2.28237132e-05 -6.24080858e-05\n  3.24387875e-05 -6.78761353e-05 -2.99293642e-05  2.29163415e-05\n  1.08221313e-04  6.30048671e-05 -2.01245020e-05 -7.81651761e-05\n  1.92329375e-04 -6.43786334e-05  1.96842215e-04  1.28757150e-04\n  2.52563277e-05  1.97022746e-04  1.22558427e-04  9.52200426e-05\n -1.95486427e-05  7.65220393e-05  5.87512222e-05  1.54714216e-05\n -1.22360780e-05  6.58002318e-05 -6.13063912e-06 -4.05202736e-05\n -1.76177520e-04 -1.31386943e-04  3.16501282e-05  1.89478538e-04\n -4.01142606e-05 -1.11829751e-04 -1.26882485e-04 -1.54628564e-04]",
         "0.19161547035584145"
        ],
        [
         "4",
         "2016-01-28 00:00:00",
         "gold prices down slightly in asia with fed rate path the focus",
         "-0.9990002400000001",
         "[ 7.71082519e-03 -4.92208973e-02  5.63184991e-02  6.29901886e-03\n -7.68191218e-02  1.22028880e-03  3.05333920e-02  1.53181907e-02\n  5.72408661e-02 -3.40469666e-02 -5.80551708e-03  6.77950159e-02\n -6.68275058e-02 -5.93805462e-02  3.29370573e-02 -1.71605255e-02\n -5.35985874e-03 -4.18626852e-02  1.28389476e-02  1.02424426e-02\n  1.35146007e-02 -6.89076558e-02  1.63229033e-02 -1.17345676e-02\n  5.82754500e-02 -1.73421483e-02 -4.34890464e-02  1.68041140e-02\n -3.53028774e-02 -1.92594267e-02 -5.06620035e-02 -9.18575283e-03\n  1.41205862e-02  4.86218929e-02 -1.72456875e-02  6.25276193e-02\n -6.76765442e-02 -1.88867878e-02  5.73823899e-02 -4.32518534e-02\n  4.13257554e-02  6.72431886e-02  5.21899248e-03 -3.90843712e-02\n -2.83135083e-02  4.11391035e-02  5.40503971e-02  6.51723519e-02\n  4.72775602e-04 -3.52670290e-02 -4.99211103e-02 -7.35298544e-02\n  2.37714183e-02  6.49297936e-03  3.00196316e-02 -1.08887348e-02\n -2.26783450e-03  7.27744922e-02  9.85335838e-03 -7.89154880e-03\n -5.31421090e-03 -4.70765531e-02  1.78729333e-02  3.62030715e-02\n  2.77170688e-02  5.91108836e-02  3.81698124e-02 -3.60341892e-02\n -3.45334336e-02 -2.37325337e-02  1.72973108e-02  3.59365530e-02\n -6.55949786e-02 -3.71554233e-02 -2.65855826e-02  7.07030073e-02\n -5.57383597e-02  8.44486654e-02 -5.00371233e-02 -3.87077779e-02\n -5.34496680e-02  7.67006725e-02  2.62232646e-02  6.58380240e-02\n  4.55773212e-02 -4.75031361e-02  7.25394934e-02  5.33137843e-02\n -2.31062341e-02  1.61454286e-02  1.45038553e-02  6.93559051e-02\n -1.43128624e-02  5.54354601e-02  6.02070577e-02 -2.34126672e-02\n  2.69590896e-02  1.23387678e-02 -1.29102059e-02  5.12069762e-02\n  8.68427232e-02 -1.34316587e-03  5.01807109e-02  8.18777978e-02\n -3.50610763e-02 -2.16843225e-02 -4.60129827e-02 -6.06103428e-02\n -6.49214536e-02 -2.94223391e-02 -4.27706949e-02 -4.22505364e-02\n -3.08112577e-02  7.49242380e-02 -1.76846199e-02 -4.47275303e-02\n  1.49377119e-02 -6.37141094e-02 -6.90200925e-03 -8.48489925e-02\n -5.76650240e-02  2.36447286e-02 -8.20426047e-02 -4.32635508e-02\n  2.75858231e-02 -9.98146925e-03  9.29806232e-02  8.70111305e-03\n  4.22614180e-02  8.12070295e-02  3.92900966e-02 -5.21725044e-02\n  1.14262686e-03 -4.93416563e-02  4.36620824e-02  1.27776377e-02\n -2.64540538e-02  4.57991287e-02  2.14095339e-02 -8.53801444e-02\n  6.38631582e-02  1.31195839e-02 -8.09556097e-02  2.56043356e-02\n -1.80652160e-02 -7.05181658e-02 -3.91336083e-02  2.32750960e-02\n -4.54745963e-02 -2.53709834e-02  3.91681539e-03  4.95891571e-02\n  3.46511528e-02  4.32791635e-02 -3.39657404e-02 -3.00956517e-03\n  4.20332439e-02 -1.69245265e-02 -1.24988668e-02 -3.21960822e-02\n  3.71393822e-02  2.05715373e-02 -5.28377742e-02 -6.72956482e-02\n  4.70045954e-02 -6.65110350e-02 -2.33145747e-02  6.65851235e-02\n  1.89520381e-02  2.12186966e-02 -2.60787942e-06 -6.62230626e-02\n  4.05122060e-04 -6.71228692e-02 -2.97469459e-02  8.91639814e-02\n -8.00291263e-03 -4.57600206e-02  1.69502832e-02  3.72321196e-02\n  1.07243136e-02  2.61452533e-02 -4.94746938e-02 -2.55343486e-02\n -2.67743021e-02 -3.00712846e-02  2.01446712e-02 -4.54196185e-02\n  4.94008837e-03 -8.20048712e-03  2.08326727e-02 -8.40087458e-02\n -2.03824346e-03  5.70295937e-02  7.87097514e-02  3.88944298e-02\n -2.48927642e-02 -4.85951081e-02 -3.34546827e-02 -5.00208177e-02\n -7.92332143e-02  6.32058457e-02  5.11793494e-02 -2.56306678e-02\n -6.79943860e-02 -1.55372852e-02 -7.00017139e-02 -3.51879336e-02\n -1.51900398e-02  5.02874218e-02  1.70430099e-03 -5.45292757e-02\n -1.39180254e-02 -5.04485564e-03 -5.12990728e-02  7.79855922e-02\n  1.32488646e-02  3.19258235e-02  6.94546476e-02 -6.77095205e-02\n  1.66221745e-02  5.37473820e-02 -7.16205165e-02  8.25649872e-02\n  5.02198376e-02  2.67148875e-02  7.04531372e-02  1.64275225e-02\n -6.64875209e-02 -4.70332382e-03  5.65461330e-02 -6.93285018e-02\n  6.91511333e-02 -4.90304008e-02  6.68145940e-02 -6.16159569e-03\n -9.27815866e-03 -3.42277475e-02  2.54506757e-03  7.70580992e-02\n -2.73557957e-02  7.06188455e-02 -6.81764930e-02  1.71120744e-02\n  4.50344160e-02  4.28848900e-02 -2.58536488e-02 -3.65015678e-02\n  1.04221627e-02  1.79929845e-02  3.91908251e-02  4.66262698e-02\n  2.82648951e-02  1.40414685e-02 -2.32645664e-02 -1.19537925e-02\n -2.00987328e-02 -3.13442685e-02  7.21422955e-02 -5.33217192e-02\n -4.59321961e-03 -4.15815152e-02  2.30213199e-02  3.47833112e-02\n -1.87627450e-02  2.42314935e-02  3.17599364e-02 -6.27929298e-03\n -9.04543400e-02 -4.91984524e-02 -6.57801479e-02 -2.29757801e-02\n  3.61595955e-03 -2.59861373e-03  5.81027158e-02 -4.48775440e-02\n -7.87641406e-02  3.02735926e-03 -3.05077396e-02 -1.68424770e-02\n  1.98687296e-02  1.64007414e-02  1.06587764e-02  5.94316870e-02\n -3.88058033e-05 -1.67277697e-02  4.08162326e-02 -1.33789908e-02\n -4.08407487e-03  2.36325059e-03 -5.78572862e-02  4.97664399e-02\n -3.52223217e-02 -1.46190799e-03  2.58350633e-02  4.34337463e-03\n -5.31945154e-02 -7.39888335e-03 -7.83928037e-02 -1.06929503e-02\n  1.26907416e-02  4.95159365e-02 -5.47787137e-02  2.59087775e-02\n -5.41751385e-02  2.52653118e-02  1.88718792e-02  1.41631998e-02\n -5.50695835e-03 -1.21834939e-02  9.44656972e-03 -3.91600095e-03\n  1.50585296e-02 -6.42489046e-02 -4.69928458e-02  9.13176313e-03\n -2.37169601e-02  7.14712366e-02 -5.93338162e-02 -2.25331634e-02\n -1.21600358e-02  7.14094415e-02  2.46945005e-02  5.99972485e-03\n -5.47590293e-02 -8.39345530e-02  1.67921954e-03 -8.12378302e-02\n -6.32923245e-02  2.33424362e-02 -5.92919663e-02  3.61757055e-02\n  4.62948680e-02 -1.17320651e-02  9.84706450e-03 -4.25359979e-03\n -1.41979726e-02  2.98777688e-02 -2.83341389e-02 -1.23180933e-02\n -2.60313656e-02 -7.86551461e-02 -5.36603213e-04 -6.84668422e-02\n  2.19888277e-02 -5.95172830e-02 -4.84482851e-03 -8.66874866e-03\n  4.41442803e-02  2.29323041e-02 -6.12036362e-02  6.96187615e-02\n -1.59496572e-02  4.39112186e-02 -9.43500772e-02  6.77625611e-02\n -6.87478706e-02  3.56014841e-03  4.79127988e-02 -3.64438444e-02\n  7.36779347e-02  2.18038633e-02 -1.14960596e-02 -5.18385880e-02\n  1.83832124e-02 -2.40104720e-02 -2.46767560e-03 -4.39175026e-04\n  2.28323285e-02 -6.53718337e-02  3.98751311e-02 -8.37160274e-02\n -3.04827411e-02 -7.49452156e-04 -1.00534863e-03 -3.02643832e-02\n -3.78752835e-02 -5.21286242e-02 -6.59296848e-03  3.95780765e-02\n  3.80511694e-02 -7.63654038e-02  2.65063103e-02 -5.35714906e-04\n  6.30990043e-02  1.17188469e-02  7.13120326e-02  1.75997615e-02\n -3.78430914e-03  2.19461974e-02  8.14685412e-03 -1.93895232e-02\n -6.77402020e-02 -3.88788953e-02  2.44890004e-02  4.58068810e-02\n -3.26316357e-02 -2.47278977e-02  3.87985855e-02  1.07470965e-02\n  5.32605278e-04  2.02575345e-02 -3.51851396e-02 -8.72861687e-03\n  2.92732706e-03 -6.88175038e-02 -5.85528836e-02 -5.67126274e-02\n  3.52213681e-02  2.64305118e-02  2.65276823e-02 -1.37642687e-02\n  2.98466906e-02 -2.53491476e-02 -1.24733038e-02  1.39088174e-02\n  6.58181831e-02  3.41244712e-02  7.76764229e-02  5.78072891e-02\n -3.25775705e-02 -5.15252277e-02  7.71969929e-02  8.06550756e-02\n  6.71392493e-03  4.59357575e-02 -6.13336377e-02 -4.18713130e-02\n -1.86589938e-02  1.98619766e-03 -8.48815665e-02  5.96104525e-02\n -4.18427289e-02  6.50492543e-03 -1.60745364e-02 -3.02194003e-02\n -3.89214270e-02 -3.52676399e-02  8.25236738e-02 -2.72632577e-02\n  5.23176864e-02  9.30589531e-03 -4.94525395e-02 -7.60323927e-02\n -1.50616467e-03 -6.39985874e-02  1.22018892e-03 -7.34827146e-02\n  8.48225504e-02 -1.64510999e-02  5.67684174e-02 -2.62384135e-02\n  1.78414956e-02  4.80340347e-02 -2.62089763e-02 -3.93999033e-02\n -1.16047519e-03  5.10014482e-02 -3.96583490e-02  6.70285821e-02\n  9.49654914e-03 -5.49911000e-02  3.99140082e-02  3.08925621e-02\n -8.41180980e-02  8.71491618e-03  5.16338125e-02 -6.30841358e-03\n -2.95767058e-02 -7.45747983e-03  6.32221699e-02  6.95208460e-02\n  7.30456188e-02  1.27096949e-02 -6.45870492e-02 -1.65160298e-02\n  1.89194512e-02  7.05372542e-02  8.44994858e-02 -3.32650915e-02\n  1.55207086e-02 -3.01620015e-03  2.70599108e-02 -3.17848213e-02\n  5.94769306e-02  7.93082814e-04  3.30996662e-02 -4.73268516e-02\n  4.01903642e-04 -4.23712805e-02  5.82511909e-02  2.63950843e-02\n  1.21243708e-02 -6.74266294e-02  9.28563066e-03  4.06636810e-03\n  5.30251972e-02  4.79258187e-02  3.86802969e-03 -7.18027800e-02\n -7.00107813e-02  5.96852265e-02  6.04007319e-02  4.65171374e-02\n  1.91690512e-02  2.19768342e-02 -1.32595294e-03  5.96295111e-02\n -4.93613370e-02 -8.56046006e-03 -7.29371831e-02 -7.93282539e-02]",
         "[-7.70311616e-03  4.91716899e-02 -5.62621951e-02 -6.29272126e-03\n  7.67423213e-02 -1.21906877e-03 -3.05028670e-02 -1.53028760e-02\n -5.71836382e-02  3.40129286e-02  5.79971308e-03 -6.77272379e-02\n  6.67606965e-02  5.93211800e-02 -3.29041295e-02  1.71433687e-02\n  5.35450038e-03  4.18208316e-02 -1.28261121e-02 -1.02322027e-02\n -1.35010891e-02  6.88387677e-02 -1.63065847e-02  1.17228357e-02\n -5.82171902e-02  1.73248108e-02  4.34455685e-02 -1.67873148e-02\n  3.52675840e-02  1.92401726e-02  5.06113544e-02  9.17656906e-03\n -1.41064692e-02 -4.85732816e-02  1.72284469e-02 -6.24651089e-02\n  6.76088855e-02  1.88679062e-02 -5.73250204e-02  4.32086140e-02\n -4.12844382e-02 -6.71759620e-02 -5.21377474e-03  3.90452966e-02\n  2.82852016e-02 -4.10979763e-02 -5.39963618e-02 -6.51071966e-02\n -4.72302956e-04  3.52317691e-02  4.98712026e-02  7.34563395e-02\n -2.37476528e-02 -6.48648804e-03 -2.99896188e-02  1.08778486e-02\n  2.26556719e-03 -7.27017373e-02 -9.84350778e-03  7.88365956e-03\n  5.30889817e-03  4.70294878e-02 -1.78550649e-02 -3.61668766e-02\n -2.76893582e-02 -5.90517893e-02 -3.81316505e-02  3.59981656e-02\n  3.44989076e-02  2.37088073e-02 -1.72800180e-02 -3.59006263e-02\n  6.55293986e-02  3.71182784e-02  2.65590046e-02 -7.06323236e-02\n  5.56826368e-02 -8.43642354e-02  4.99871001e-02  3.86690795e-02\n  5.33962324e-02 -7.66239911e-02 -2.61970479e-02 -6.57722056e-02\n -4.55317572e-02  4.74556461e-02 -7.24669695e-02 -5.32604828e-02\n  2.30831336e-02 -1.61292870e-02 -1.44893555e-02 -6.92865700e-02\n  1.42985536e-02 -5.53800389e-02 -6.01468645e-02  2.33892612e-02\n -2.69321371e-02 -1.23264324e-02  1.28972987e-02 -5.11557832e-02\n -8.67559016e-02  1.34182302e-03 -5.01305424e-02 -8.17959383e-02\n  3.50260250e-02  2.16626432e-02  4.59669828e-02  6.05497472e-02\n  6.48565516e-02  2.93929242e-02  4.27279361e-02  4.22082953e-02\n  3.07804532e-02 -7.48493299e-02  1.76669396e-02  4.46828157e-02\n -1.49227781e-02  6.36504143e-02  6.89510908e-03  8.47641677e-02\n  5.76073751e-02 -2.36210898e-02  8.19605812e-02  4.32202965e-02\n -2.75582448e-02  9.97149013e-03 -9.28876624e-02 -8.69241450e-03\n -4.22191657e-02 -8.11258405e-02 -3.92508171e-02  5.21203466e-02\n -1.14148448e-03  4.92923260e-02 -4.36184295e-02 -1.27648637e-02\n  2.64276061e-02 -4.57533412e-02 -2.13881303e-02  8.52947831e-02\n -6.37993142e-02 -1.31064672e-02  8.08746740e-02 -2.55787373e-02\n  1.80471558e-02  7.04476684e-02  3.90944853e-02 -2.32518259e-02\n  4.54291329e-02  2.53456179e-02 -3.91289964e-03 -4.95395809e-02\n -3.46165113e-02 -4.32358943e-02  3.39317843e-02  3.00655630e-03\n -4.19912226e-02  1.69076063e-02  1.24863712e-02  3.21638957e-02\n -3.71022522e-02 -2.05509719e-02  5.27849495e-02  6.72283694e-02\n -4.69576009e-02  6.64445385e-02  2.32912656e-02 -6.65185526e-02\n -1.89330913e-02 -2.11974829e-02  2.60527213e-06  6.61568567e-02\n -4.04717051e-04  6.70557618e-02  2.97172070e-02 -8.90748426e-02\n  7.99491163e-03  4.57142703e-02 -1.69333369e-02 -3.71948965e-02\n -1.07135922e-02 -2.61191148e-02  4.94252332e-02  2.55088210e-02\n  2.67475341e-02  3.00412215e-02 -2.01245323e-02  4.53742109e-02\n -4.93514957e-03  8.19228869e-03 -2.08118446e-02  8.39247555e-02\n  2.03620573e-03 -5.69725782e-02 -7.86310583e-02 -3.88555452e-02\n  2.48678774e-02  4.85465266e-02  3.34212370e-02  4.99708094e-02\n  7.91539997e-02 -6.31426573e-02 -5.11281826e-02  2.56050434e-02\n  6.79264069e-02  1.55217517e-02  6.99317306e-02  3.51527557e-02\n  1.51748536e-02 -5.02371453e-02 -1.70259713e-03  5.44747598e-02\n  1.39041105e-02  5.03981207e-03  5.12477867e-02 -7.79076293e-02\n -1.32356193e-02 -3.18939053e-02 -6.93852082e-02  6.76418245e-02\n -1.66055560e-02 -5.36936484e-02  7.15489164e-02 -8.24824423e-02\n -5.01696318e-02 -2.66881790e-02 -7.03826994e-02 -1.64110996e-02\n  6.64210469e-02  4.69862157e-03 -5.64896017e-02  6.92591891e-02\n -6.90819994e-02  4.89813834e-02 -6.67477995e-02  6.15543546e-03\n  9.26888268e-03  3.41935270e-02 -2.54252320e-03 -7.69810602e-02\n  2.73284465e-02 -7.05482438e-02  6.81083351e-02 -1.70949660e-02\n -4.49893922e-02 -4.28420156e-02  2.58278009e-02  3.64650749e-02\n -1.04117431e-02 -1.79749969e-02 -3.91516425e-02 -4.65796553e-02\n -2.82366369e-02 -1.40274307e-02  2.32413076e-02  1.19418418e-02\n  2.00786386e-02  3.13129313e-02 -7.20701739e-02  5.32684103e-02\n  4.58862772e-03  4.15399447e-02 -2.29983050e-02 -3.47485356e-02\n  1.87439863e-02 -2.42072679e-02 -3.17281857e-02  6.27301540e-03\n  9.03639048e-02  4.91492674e-02  6.57143816e-02  2.29528099e-02\n -3.61234439e-03  2.59601581e-03 -5.80446273e-02  4.48326766e-02\n  7.86853954e-02 -3.02433269e-03  3.04772388e-02  1.68256387e-02\n -1.98488664e-02 -1.63843445e-02 -1.06481202e-02 -5.93722686e-02\n  3.87670079e-05  1.67110469e-02 -4.07754257e-02  1.33656152e-02\n  4.07999195e-03 -2.36088783e-03  5.77994436e-02 -4.97166850e-02\n  3.51871066e-02  1.46044639e-03 -2.58092340e-02 -4.33903234e-03\n  5.31413332e-02  7.39148632e-03  7.83144310e-02  1.06822597e-02\n -1.26780542e-02 -4.94664349e-02  5.47239482e-02 -2.58828755e-02\n  5.41209765e-02 -2.52400525e-02 -1.88530125e-02 -1.41490400e-02\n  5.50145283e-03  1.21713132e-02 -9.43712518e-03  3.91208613e-03\n -1.50434747e-02  6.41846731e-02  4.69458662e-02 -9.12263338e-03\n  2.36932486e-02 -7.13997856e-02  5.92744984e-02  2.25106366e-02\n  1.21478792e-02 -7.13380501e-02 -2.46698130e-02 -5.99372666e-03\n  5.47042824e-02  8.38506371e-02 -1.67754071e-03  8.11566114e-02\n  6.32290468e-02 -2.33190991e-02  5.92326894e-02 -3.61395404e-02\n -4.62485850e-02  1.17203360e-02 -9.83721949e-03  4.24934737e-03\n  1.41837783e-02 -2.98478995e-02  2.83058118e-02  1.23057785e-02\n  2.60053407e-02  7.85765126e-02  5.36066771e-04  6.83983937e-02\n -2.19668448e-02  5.94577789e-02  4.83998470e-03  8.66008177e-03\n -4.41001467e-02 -2.29093768e-02  6.11424483e-02 -6.95491582e-02\n  1.59337111e-02 -4.38673198e-02  9.42557529e-02 -6.76948130e-02\n  6.86791390e-02 -3.55658913e-03 -4.78648990e-02  3.64074111e-02\n -7.36042783e-02 -2.17820648e-02  1.14845661e-02  5.17867617e-02\n -1.83648337e-02  2.39864681e-02  2.46520853e-03  4.38735966e-04\n -2.28095017e-02  6.53064772e-02 -3.98352668e-02  8.36323351e-02\n  3.04522663e-02  7.48702907e-04  1.00434350e-03  3.02341264e-02\n  3.78374159e-02  5.20765074e-02  6.58637704e-03 -3.95385101e-02\n -3.80131267e-02  7.62890577e-02 -2.64798105e-02  5.35179337e-04\n -6.30359203e-02 -1.17071308e-02 -7.12407380e-02 -1.75821669e-02\n  3.78052588e-03 -2.19242573e-02 -8.13870970e-03  1.93701386e-02\n  6.76724762e-02  3.88400257e-02 -2.44645178e-02 -4.57610860e-02\n  3.25990133e-02  2.47031767e-02 -3.87597978e-02 -1.07363518e-02\n -5.32072794e-04 -2.02372819e-02  3.51499617e-02  8.71989038e-03\n -2.92440038e-03  6.87487051e-02  5.84943444e-02  5.66559285e-02\n -3.51861566e-02 -2.64040884e-02 -2.65011620e-02  1.37505075e-02\n -2.98168510e-02  2.53238045e-02  1.24608334e-02 -1.38949119e-02\n -6.57523796e-02 -3.40903550e-02 -7.75987655e-02 -5.77494949e-02\n  3.25450003e-02  5.14737144e-02 -7.71198124e-02 -8.05744380e-02\n -6.70721289e-03 -4.58898321e-02  6.12723194e-02  4.18294519e-02\n  1.86403394e-02 -1.98421185e-03  8.47967044e-02 -5.95508553e-02\n  4.18008976e-02 -6.49842201e-03  1.60584655e-02  3.01891882e-02\n  3.88825163e-02  3.52323800e-02 -8.24411735e-02  2.72360016e-02\n -5.22653833e-02 -9.29659139e-03  4.94031012e-02  7.59563819e-02\n  1.50465884e-03  6.39346018e-02 -1.21896900e-03  7.34092519e-02\n -8.47377479e-02  1.64346527e-02 -5.67116626e-02  2.62121819e-02\n -1.78236589e-02 -4.79860120e-02  2.61827745e-02  3.93605120e-02\n  1.15931500e-03 -5.09504601e-02  3.96187007e-02 -6.69615716e-02\n -9.48705524e-03  5.49361221e-02 -3.98741029e-02 -3.08616776e-02\n  8.40340033e-02 -8.70620366e-03 -5.15821911e-02  6.30210666e-03\n  2.95471363e-02  7.45002413e-03 -6.31589666e-02 -6.94513395e-02\n -7.29725882e-02 -1.26969879e-02  6.45224750e-02  1.64995175e-02\n -1.89005360e-02 -7.04667345e-02 -8.44150111e-02  3.32318358e-02\n -1.55051919e-02  3.01318476e-03 -2.70328578e-02  3.17530446e-02\n -5.94174676e-02 -7.92289909e-04 -3.30665745e-02  4.72795367e-02\n -4.01501835e-04  4.23289202e-02 -5.81929535e-02 -2.63686962e-02\n -1.21122496e-02  6.73592165e-02 -9.27634723e-03 -4.06230288e-03\n -5.29721864e-02 -4.78779040e-02 -3.86416260e-03  7.17309937e-02\n  6.99407905e-02 -5.96255548e-02 -6.03403449e-02 -4.64706309e-02\n -1.91498864e-02 -2.19548624e-02  1.32462732e-03 -5.95698953e-02\n  4.93119881e-02  8.55190214e-03  7.28642642e-02  7.92489424e-02]",
         "0.19161547035584145"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topic_encodings</th>\n",
       "      <th>sentiment_combined_encodings</th>\n",
       "      <th>price_percentage_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>april gold down 20 cents to settle at $1,116.1...</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>[-0.030607987, -0.06112092, 0.05298826, 0.0025...</td>\n",
       "      <td>[0.030577388, 0.061059814, -0.052935287, -0.00...</td>\n",
       "      <td>0.191615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>gold sticks near 12-week high as fed eyes glob...</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>[0.016134372, -0.030435134, 0.05567852, 0.0271...</td>\n",
       "      <td>[0.016081171, -0.03033478, 0.05549493, 0.02705...</td>\n",
       "      <td>0.191615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>the biggest potential driver for gold prices i...</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>[0.054409396, -0.09339435, -0.0011068282, 0.01...</td>\n",
       "      <td>[0.0003081177, -0.00052888755, -6.2679132e-06,...</td>\n",
       "      <td>0.191615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>buy comex gold if it touches $1,107-08/ounce</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>[-0.00877056, -0.017302277, 0.08381294, -0.038...</td>\n",
       "      <td>[-2.2712242e-05, -4.4805973e-05, 0.00021704198...</td>\n",
       "      <td>0.191615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>gold prices down slightly in asia with fed rat...</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>[0.007710825, -0.049220897, 0.0563185, 0.00629...</td>\n",
       "      <td>[-0.007703116, 0.04917169, -0.056262195, -0.00...</td>\n",
       "      <td>0.191615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                               text  sentiment  \\\n",
       "0 2016-01-28  april gold down 20 cents to settle at $1,116.1...  -0.999000   \n",
       "1 2016-01-28  gold sticks near 12-week high as fed eyes glob...   0.996703   \n",
       "2 2016-01-28  the biggest potential driver for gold prices i...   0.005663   \n",
       "3 2016-01-28       buy comex gold if it touches $1,107-08/ounce   0.002590   \n",
       "4 2016-01-28  gold prices down slightly in asia with fed rat...  -0.999000   \n",
       "\n",
       "                                     topic_encodings  \\\n",
       "0  [-0.030607987, -0.06112092, 0.05298826, 0.0025...   \n",
       "1  [0.016134372, -0.030435134, 0.05567852, 0.0271...   \n",
       "2  [0.054409396, -0.09339435, -0.0011068282, 0.01...   \n",
       "3  [-0.00877056, -0.017302277, 0.08381294, -0.038...   \n",
       "4  [0.007710825, -0.049220897, 0.0563185, 0.00629...   \n",
       "\n",
       "                        sentiment_combined_encodings  price_percentage_change  \n",
       "0  [0.030577388, 0.061059814, -0.052935287, -0.00...                 0.191615  \n",
       "1  [0.016081171, -0.03033478, 0.05549493, 0.02705...                 0.191615  \n",
       "2  [0.0003081177, -0.00052888755, -6.2679132e-06,...                 0.191615  \n",
       "3  [-2.2712242e-05, -4.4805973e-05, 0.00021704198...                 0.191615  \n",
       "4  [-0.007703116, 0.04917169, -0.056262195, -0.00...                 0.191615  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../Data/combined_dataset_with_price_change.csv\",index_col=0)\n",
    "\n",
    "# Load\n",
    "df = pd.read_pickle('../Data/combined_dataset_with_price_change.pkl')\n",
    "print(\"Number of rows in df:\",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7ccb5",
   "metadata": {},
   "source": [
    "### Initialize the dataloader and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ace979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some settings\n",
    "batch_size = 50\n",
    "articles_per_day = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74530117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max articles per day: 22\n"
     ]
    }
   ],
   "source": [
    "#Group input data into sets for use in model.\n",
    "encodings, price_changes, masks = group_into_variable_sets(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a66799e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1648, 22, 512) (1648, 1) (1648, 22)\n"
     ]
    }
   ],
   "source": [
    "print(encodings.shape,price_changes.shape,masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51912f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VariableSetDataset(encodings, price_changes, masks)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f03443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SetTransformer(\n",
    "    dim_input = 512, \n",
    "    num_outputs = 1, #One final prediction\n",
    "    dim_output = 1, #1D output for price change\n",
    "    num_inds=32, \n",
    "    dim_hidden=128, \n",
    "    num_heads=4, \n",
    "    ln=True #Layer normalization\n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d189a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 32, 128]          16,512\n",
      "            Linear-2              [-1, 10, 128]          65,664\n",
      "            Linear-3              [-1, 10, 128]          65,664\n",
      "         LayerNorm-4              [-1, 32, 128]             256\n",
      "            Linear-5              [-1, 32, 128]          16,512\n",
      "         LayerNorm-6              [-1, 32, 128]             256\n",
      "               MAB-7              [-1, 32, 128]               0\n",
      "            Linear-8              [-1, 10, 128]          65,664\n",
      "            Linear-9              [-1, 32, 128]          16,512\n",
      "           Linear-10              [-1, 32, 128]          16,512\n",
      "        LayerNorm-11              [-1, 10, 128]             256\n",
      "           Linear-12              [-1, 10, 128]          16,512\n",
      "        LayerNorm-13              [-1, 10, 128]             256\n",
      "              MAB-14              [-1, 10, 128]               0\n",
      "             ISAB-15              [-1, 10, 128]               0\n",
      "           Linear-16              [-1, 32, 128]          16,512\n",
      "           Linear-17              [-1, 10, 128]          16,512\n",
      "           Linear-18              [-1, 10, 128]          16,512\n",
      "        LayerNorm-19              [-1, 32, 128]             256\n",
      "           Linear-20              [-1, 32, 128]          16,512\n",
      "        LayerNorm-21              [-1, 32, 128]             256\n",
      "              MAB-22              [-1, 32, 128]               0\n",
      "           Linear-23              [-1, 10, 128]          16,512\n",
      "           Linear-24              [-1, 32, 128]          16,512\n",
      "           Linear-25              [-1, 32, 128]          16,512\n",
      "        LayerNorm-26              [-1, 10, 128]             256\n",
      "           Linear-27              [-1, 10, 128]          16,512\n",
      "        LayerNorm-28              [-1, 10, 128]             256\n",
      "              MAB-29              [-1, 10, 128]               0\n",
      "             ISAB-30              [-1, 10, 128]               0\n",
      "           Linear-31               [-1, 1, 128]          16,512\n",
      "           Linear-32              [-1, 10, 128]          16,512\n",
      "           Linear-33              [-1, 10, 128]          16,512\n",
      "        LayerNorm-34               [-1, 1, 128]             256\n",
      "           Linear-35               [-1, 1, 128]          16,512\n",
      "        LayerNorm-36               [-1, 1, 128]             256\n",
      "              MAB-37               [-1, 1, 128]               0\n",
      "              PMA-38               [-1, 1, 128]               0\n",
      "           Linear-39               [-1, 1, 128]          16,512\n",
      "           Linear-40               [-1, 1, 128]          16,512\n",
      "           Linear-41               [-1, 1, 128]          16,512\n",
      "        LayerNorm-42               [-1, 1, 128]             256\n",
      "           Linear-43               [-1, 1, 128]          16,512\n",
      "        LayerNorm-44               [-1, 1, 128]             256\n",
      "              MAB-45               [-1, 1, 128]               0\n",
      "              SAB-46               [-1, 1, 128]               0\n",
      "           Linear-47               [-1, 1, 128]          16,512\n",
      "           Linear-48               [-1, 1, 128]          16,512\n",
      "           Linear-49               [-1, 1, 128]          16,512\n",
      "        LayerNorm-50               [-1, 1, 128]             256\n",
      "           Linear-51               [-1, 1, 128]          16,512\n",
      "        LayerNorm-52               [-1, 1, 128]             256\n",
      "              MAB-53               [-1, 1, 128]               0\n",
      "              SAB-54               [-1, 1, 128]               0\n",
      "           Linear-55                 [-1, 1, 1]             129\n",
      "================================================================\n",
      "Total params: 613,505\n",
      "Trainable params: 613,505\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.63\n",
      "Params size (MB): 2.34\n",
      "Estimated Total Size (MB): 2.99\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Comment this cell if you don't have the package installed\n",
    "from torchsummary import summary\n",
    "print(summary(model,(1, 10, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32bfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove old runs data.\n",
    "if os.path.exists('runs') and os.path.isdir('runs'):\n",
    "    for item in os.listdir('runs'):\n",
    "        item_path = os.path.join('runs', item)\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)  # Remove file\n",
    "        else:\n",
    "            shutil.rmtree(item_path)  # Remove subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59156b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21d96a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running this cell, visit http://localhost:6006 on your browser to visualize the training process.\n",
    "%load_ext tensorboard \n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "626b0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23352), started 0:47:56 ago. (Use '!kill 23352' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-106a8498e5449f90\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-106a8498e5449f90\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run this in your terminal separately to visualize the training process live\n",
    "%tensorboard --logdir=runs --reload_interval=30 --host=127.0.0.1 #Autoreload every 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dcfb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0637fe8228ea4bd3bcdfddf66d352c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m val_losses_temp \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inps, outs \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     50\u001b[0m         inps \u001b[38;5;241m=\u001b[39m inps\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     51\u001b[0m         outs \u001b[38;5;241m=\u001b[39m outs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "plt.ioff()  # Turn off interactive mode initially\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epochs_list = []\n",
    "val_epochs_list = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "pbar = tqdm.tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\")\n",
    "\n",
    "avg_loss = 0.0\n",
    "avg_val_loss = 0.0\n",
    "\n",
    "for epoch in pbar:\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (inps, outs, masks) in enumerate(train_loader):\n",
    "        inps = inps.to(device)\n",
    "        outs = outs.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        preds = model(inps,mask= masks)\n",
    "        if preds.dim() > 1:\n",
    "            preds = preds.squeeze()\n",
    "        if outs.dim() > 1:\n",
    "            outs = outs.squeeze()\n",
    "        \n",
    "        loss = criterion(preds, outs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    train_losses.append(avg_loss)\n",
    "    epochs_list.append(epoch)\n",
    "    \n",
    "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "    \n",
    "    # Validation every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        val_losses_temp = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inps, outs, masks in test_loader:\n",
    "                inps = inps.to(device)\n",
    "                outs = outs.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                \n",
    "                preds = model(inps,mask = masks)\n",
    "                if preds.dim() > 1:\n",
    "                    preds = preds.squeeze()\n",
    "                if outs.dim() > 1:\n",
    "                    outs = outs.squeeze()\n",
    "                \n",
    "                loss = criterion(preds, outs)\n",
    "                val_losses_temp.append(loss.item())\n",
    "        \n",
    "        avg_val_loss = np.mean(val_losses_temp)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_epochs_list.append(epoch)\n",
    "        \n",
    "        writer.add_scalar('Loss/validation', avg_val_loss, epoch)\n",
    "    \n",
    "    # Update plot every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(epochs_list, train_losses, 'b-', label='Training Loss', alpha=0.8, linewidth=2)\n",
    "        if val_losses:\n",
    "            plt.plot(val_epochs_list, val_losses, 'r-', label='Validation Loss', \n",
    "                    alpha=0.8, marker='o', linewidth=2, markersize=6)\n",
    "        \n",
    "        plt.xlabel('Epoch', fontsize=12)\n",
    "        plt.ylabel('Loss', fontsize=12)\n",
    "        plt.title('Training and Validation Loss (Live Update)', fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    pbar.set_postfix({'loss': f'{avg_loss:.4f}', 'val_loss': f'{avg_val_loss:.4f}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaec0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "final_checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': num_epochs,\n",
    "    'loss': avg_loss,\n",
    "    'val_loss': avg_val_loss\n",
    "}\n",
    "torch.save(final_checkpoint, 'FinalModel/final_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff452a4a",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47d30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SetTransformer(\n",
    "    dim_input = 512, \n",
    "    num_outputs = 1, #One final prediction\n",
    "    dim_output = 1, #1D output for price change\n",
    "    num_inds=32, \n",
    "    dim_hidden=128, \n",
    "    num_heads=4, \n",
    "    ln=True #Layer normalization\n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cc2ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from FinalModel/final_model.pth at epoch 100 with loss 0.4647\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the checkpoint\n",
    "checkpoint_path = 'FinalModel/final_model.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    start_epoch, start_loss ,model, optimizer = load_checkpoint(checkpoint_path, model, optimizer,device)\n",
    "    print(f\"Model loaded from {checkpoint_path} at epoch {start_epoch} with loss {start_loss:.4f}\")\n",
    "else:\n",
    "    start_epoch, start_loss = 0, float('inf')\n",
    "    print(f\"No checkpoint found at {checkpoint_path}. Starting from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d3fdb",
   "metadata": {},
   "source": [
    "#### Test call example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78457ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetTransformer(\n",
       "  (enc1): ISAB(\n",
       "    (mab0): MAB(\n",
       "      (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_k): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (fc_v): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (ln0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (mab1): MAB(\n",
       "      (fc_q): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (ln0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (enc2): ISAB(\n",
       "    (mab0): MAB(\n",
       "      (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (ln0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (mab1): MAB(\n",
       "      (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (ln0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dec1): PMA(\n",
       "    (mab): MAB(\n",
       "      (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (ln0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dec2): SAB(\n",
       "    (mab): MAB(\n",
       "      (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (ln0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dec3): SAB(\n",
       "    (mab): MAB(\n",
       "      (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (ln0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9dc28f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 512]) torch.Size([1, 10])\n",
      "The predicted price is:  tensor([[[-0.0335]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Say 10 articles were present for today\n",
    "inputs = np.random.rand(1, 10, 512).astype(np.float32)\n",
    "masks = np.ones((1,10)).astype(np.float32)\n",
    "\n",
    "\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32).to(device=device)\n",
    "masks = torch.tensor(masks, dtype=torch.float32).to(device=device)\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "preds = model(inputs,mask= masks)\n",
    "\n",
    "print(\"The predicted price is: \",preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d273597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLEnvt_Python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
