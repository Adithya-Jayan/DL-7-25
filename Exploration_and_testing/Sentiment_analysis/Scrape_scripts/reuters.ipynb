{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40474d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "def get_reuters_articles(URL):\n",
    "\n",
    "    chrome_options = Options()\n",
    "    #driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(URL)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "    articles=soup.find_all(\"div\", class_=lambda c: c and c.startswith(\"story-card__area-headline\"))\n",
    "    news_data = []\n",
    "    for article in articles:\n",
    "        title = article.get_text(strip=True)\n",
    "        link = article.find('a', href=True)['href']\n",
    "        if not link.startswith('http'):\n",
    "            link = base_URL + link\n",
    "        data_point = {'offset': offset_nb,'section':section_val,'Date': title, 'link': link}\n",
    "        news_data.append(data_point)\n",
    "    return pd.DataFrame(news_data)\n",
    "\n",
    "get_article_sets =set()\n",
    "for section_val in ['markets']:\n",
    "    offset_nb = 0\n",
    "    base_URL=\"https://www.reuters.com\"\n",
    "    search_query=\"/site-search/?query=gold\"\n",
    "    offset =f\"&offset={offset_nb}\"\n",
    "    section=f\"&section={section_val}\"\n",
    "    URL = base_URL + search_query + offset + section\n",
    "    try:\n",
    "        df = get_reuters_articles(URL)\n",
    "        get_article_sets.add((section_val ,offset_nb))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching articles from {URL}: {e}\")\n",
    "    for offset_nb in range(20, 1000, 20):\n",
    "        base_URL=\"https://www.reuters.com\"\n",
    "        search_query=\"/site-search/?query=gold\"\n",
    "        offset =f\"&offset={offset_nb}\"\n",
    "        section=f\"&section={section_val}\"\n",
    "        URL = base_URL + search_query + offset + section\n",
    "        try:\n",
    "            df_latest=get_reuters_articles(URL)\n",
    "            df = pd.concat([df, df_latest], ignore_index=True)\n",
    "            get_article_sets.add((section_val ,offset_nb))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching articles from {URL}: {e}\")\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
