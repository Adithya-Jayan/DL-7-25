{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149c7389",
   "metadata": {},
   "source": [
    "## Model for price prediction from sentiment data.\n",
    "> We need it to take a dictionary of sentence : sentiment pairs.\n",
    "> This size of the dictionary is variable/flexible.\n",
    "\n",
    "We could potentially design this module as an Transformer encoder model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137062f",
   "metadata": {},
   "source": [
    "References:\n",
    "> https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1/\n",
    "\n",
    "> [Set Transformer: A Framework for Attention-based\n",
    " Permutation-Invariant Neural Networks](https://arxiv.org/pdf/1810.00825)\n",
    "\n",
    " > https://github.com/juho-lee/set_transformer\n",
    "\n",
    " > [Deep sets](https://papers.nips.cc/paper_files/paper/2017/hash/f22e4747da1aa27e363d86d40ff442fe-Abstract.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4beec",
   "metadata": {},
   "source": [
    "Since we want our model to be invarient to permutations in the order in which we feed the news articles and associated sentiments, we can proceed using a set-transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ead1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class MAB(nn.Module):\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
    "        super(MAB, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
    "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
    "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(dim_V)\n",
    "            self.ln1 = nn.LayerNorm(dim_V)\n",
    "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.fc_q(Q)\n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.dim_V // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "\n",
    "        A = torch.softmax(Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V), 2)\n",
    "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "        O = O + F.relu(self.fc_o(O))\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        return O\n",
    "\n",
    "class SAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, ln=False):\n",
    "        super(SAB, self).__init__()\n",
    "        self.mab = MAB(dim_in, dim_in, dim_out, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mab(X, X)\n",
    "\n",
    "class ISAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, num_inds, ln=False):\n",
    "        super(ISAB, self).__init__()\n",
    "        self.I = nn.Parameter(torch.Tensor(1, num_inds, dim_out))\n",
    "        nn.init.xavier_uniform_(self.I)\n",
    "        self.mab0 = MAB(dim_out, dim_in, dim_out, num_heads, ln=ln)\n",
    "        self.mab1 = MAB(dim_in, dim_out, dim_out, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        H = self.mab0(self.I.repeat(X.size(0), 1, 1), X)\n",
    "        return self.mab1(X, H)\n",
    "\n",
    "class PMA(nn.Module):\n",
    "    def __init__(self, dim, num_heads, num_seeds, ln=False):\n",
    "        super(PMA, self).__init__()\n",
    "        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))\n",
    "        nn.init.xavier_uniform_(self.S)\n",
    "        self.mab = MAB(dim, dim, dim, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mab(self.S.repeat(X.size(0), 1, 1), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bde620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSet(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output, dim_hidden=128):\n",
    "        super(DeepSet, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.dim_output = dim_output\n",
    "        self.enc = nn.Sequential(\n",
    "                nn.Linear(dim_input, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden))\n",
    "        self.dec = nn.Sequential(\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, num_outputs*dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.enc(X).mean(-2)\n",
    "        X = self.dec(X).reshape(-1, self.num_outputs, self.dim_output)\n",
    "        return X\n",
    "\n",
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=4, ln=False):\n",
    "        super(SetTransformer, self).__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dec(self.enc(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98ee56b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10, 256) [[[0.49391288 0.5181262  0.3267757  ... 0.43159577 0.607781   0.19591542]\n",
      "  [0.14672875 0.32331625 0.8917091  ... 0.36367247 0.86712664 0.3618663 ]\n",
      "  [0.95741004 0.60514283 0.24322791 ... 0.35557702 0.00403093 0.21990432]\n",
      "  ...\n",
      "  [0.8560478  0.99948746 0.27371994 ... 0.01117089 0.10729098 0.38278502]\n",
      "  [0.5368003  0.08103587 0.01180919 ... 0.32980546 0.6937125  0.58217657]\n",
      "  [0.636435   0.8439539  0.39706945 ... 0.21897729 0.7338553  0.9068168 ]]\n",
      "\n",
      " [[0.63911015 0.15714303 0.8798483  ... 0.8810984  0.64553446 0.18334495]\n",
      "  [0.294584   0.02615817 0.95609117 ... 0.10610003 0.2852764  0.38951737]\n",
      "  [0.32694098 0.22553347 0.68783647 ... 0.9789811  0.22953351 0.7581387 ]\n",
      "  ...\n",
      "  [0.6629332  0.17697397 0.8830423  ... 0.21080467 0.9974504  0.18054199]\n",
      "  [0.35023713 0.31883088 0.6572026  ... 0.57077485 0.32763436 0.9826105 ]\n",
      "  [0.23525004 0.9426987  0.64778847 ... 0.917448   0.802853   0.6638273 ]]\n",
      "\n",
      " [[0.16090491 0.3736248  0.36928993 ... 0.402598   0.7880287  0.12224684]\n",
      "  [0.22361216 0.5667805  0.16961206 ... 0.19450384 0.04531623 0.8493725 ]\n",
      "  [0.7663767  0.9152238  0.08583533 ... 0.16858685 0.21406722 0.24301626]\n",
      "  ...\n",
      "  [0.6136765  0.7332255  0.737045   ... 0.8710632  0.03429994 0.26037633]\n",
      "  [0.839753   0.5844663  0.15878598 ... 0.9073193  0.6974434  0.26182345]\n",
      "  [0.40342182 0.7913633  0.3928995  ... 0.07133419 0.9427638  0.76152813]]\n",
      "\n",
      " [[0.69185007 0.744658   0.2523723  ... 0.77275866 0.08323713 0.8424525 ]\n",
      "  [0.85678065 0.08567908 0.5499475  ... 0.87676054 0.95249534 0.10607754]\n",
      "  [0.03978455 0.5672046  0.71381944 ... 0.97819626 0.6162459  0.33138797]\n",
      "  ...\n",
      "  [0.21720064 0.2952779  0.21354522 ... 0.08534037 0.29172534 0.20402586]\n",
      "  [0.37857735 0.38012773 0.15967189 ... 0.7040857  0.7128233  0.2640355 ]\n",
      "  [0.57120687 0.70353925 0.02016287 ... 0.32363027 0.60257983 0.98594266]]\n",
      "\n",
      " [[0.34584802 0.12259918 0.7084872  ... 0.00906017 0.59572756 0.9416152 ]\n",
      "  [0.32438424 0.0510662  0.74954367 ... 0.93678975 0.07496489 0.1511467 ]\n",
      "  [0.8264362  0.7177162  0.8278163  ... 0.30349633 0.4629162  0.8927606 ]\n",
      "  ...\n",
      "  [0.825243   0.61905485 0.79443645 ... 0.48284155 0.6968084  0.747704  ]\n",
      "  [0.01850846 0.01497785 0.76932454 ... 0.94888866 0.9504248  0.33825687]\n",
      "  [0.94781893 0.11317358 0.76935285 ... 0.30469665 0.8249826  0.39329684]]]\n",
      "(100, 1) [[0.4470893 ]\n",
      " [0.24631687]\n",
      " [0.7953618 ]\n",
      " [0.68668514]\n",
      " [0.9208119 ]]\n",
      "(100, 1) [[0.08461728]\n",
      " [0.1471193 ]\n",
      " [0.15261748]\n",
      " [0.01849156]\n",
      " [0.03774938]]\n"
     ]
    }
   ],
   "source": [
    "#Generate some Dummy data to test out the model using\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_size = 100\n",
    "embedding_dim = 256\n",
    "encodings = np.random.rand(dataset_size, 10, embedding_dim).astype(np.float32)\n",
    "print(encodings.shape,encodings[:5])\n",
    "\n",
    "sentiments = np.random.rand(dataset_size, 1).astype(np.float32)\n",
    "print(sentiments.shape, sentiments[:5])\n",
    "\n",
    "price_percentage_changes = np.random.rand(dataset_size, 1).astype(np.float32)* 0.2;\n",
    "print(price_percentage_changes.shape, price_percentage_changes[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2fe291d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "encodings",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentiments",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "price_percentage_changes",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "3800393d-6c74-440c-ae8e-3a013ee4f640",
       "rows": [
        [
         "0",
         "[[0.49391288 0.5181262  0.3267757  ... 0.43159577 0.607781   0.19591542]\n [0.14672875 0.32331625 0.8917091  ... 0.36367247 0.86712664 0.3618663 ]\n [0.95741004 0.60514283 0.24322791 ... 0.35557702 0.00403093 0.21990432]\n ...\n [0.8560478  0.99948746 0.27371994 ... 0.01117089 0.10729098 0.38278502]\n [0.5368003  0.08103587 0.01180919 ... 0.32980546 0.6937125  0.58217657]\n [0.636435   0.8439539  0.39706945 ... 0.21897729 0.7338553  0.9068168 ]]",
         "[0.4470893]",
         "[0.08461728]"
        ],
        [
         "1",
         "[[0.63911015 0.15714303 0.8798483  ... 0.8810984  0.64553446 0.18334495]\n [0.294584   0.02615817 0.95609117 ... 0.10610003 0.2852764  0.38951737]\n [0.32694098 0.22553347 0.68783647 ... 0.9789811  0.22953351 0.7581387 ]\n ...\n [0.6629332  0.17697397 0.8830423  ... 0.21080467 0.9974504  0.18054199]\n [0.35023713 0.31883088 0.6572026  ... 0.57077485 0.32763436 0.9826105 ]\n [0.23525004 0.9426987  0.64778847 ... 0.917448   0.802853   0.6638273 ]]",
         "[0.24631687]",
         "[0.1471193]"
        ],
        [
         "2",
         "[[0.16090491 0.3736248  0.36928993 ... 0.402598   0.7880287  0.12224684]\n [0.22361216 0.5667805  0.16961206 ... 0.19450384 0.04531623 0.8493725 ]\n [0.7663767  0.9152238  0.08583533 ... 0.16858685 0.21406722 0.24301626]\n ...\n [0.6136765  0.7332255  0.737045   ... 0.8710632  0.03429994 0.26037633]\n [0.839753   0.5844663  0.15878598 ... 0.9073193  0.6974434  0.26182345]\n [0.40342182 0.7913633  0.3928995  ... 0.07133419 0.9427638  0.76152813]]",
         "[0.7953618]",
         "[0.15261748]"
        ],
        [
         "3",
         "[[0.69185007 0.744658   0.2523723  ... 0.77275866 0.08323713 0.8424525 ]\n [0.85678065 0.08567908 0.5499475  ... 0.87676054 0.95249534 0.10607754]\n [0.03978455 0.5672046  0.71381944 ... 0.97819626 0.6162459  0.33138797]\n ...\n [0.21720064 0.2952779  0.21354522 ... 0.08534037 0.29172534 0.20402586]\n [0.37857735 0.38012773 0.15967189 ... 0.7040857  0.7128233  0.2640355 ]\n [0.57120687 0.70353925 0.02016287 ... 0.32363027 0.60257983 0.98594266]]",
         "[0.68668514]",
         "[0.01849156]"
        ],
        [
         "4",
         "[[0.34584802 0.12259918 0.7084872  ... 0.00906017 0.59572756 0.9416152 ]\n [0.32438424 0.0510662  0.74954367 ... 0.93678975 0.07496489 0.1511467 ]\n [0.8264362  0.7177162  0.8278163  ... 0.30349633 0.4629162  0.8927606 ]\n ...\n [0.825243   0.61905485 0.79443645 ... 0.48284155 0.6968084  0.747704  ]\n [0.01850846 0.01497785 0.76932454 ... 0.94888866 0.9504248  0.33825687]\n [0.94781893 0.11317358 0.76935285 ... 0.30469665 0.8249826  0.39329684]]",
         "[0.9208119]",
         "[0.03774938]"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encodings</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>price_percentage_changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.49391288, 0.5181262, 0.3267757, 0.419439, ...</td>\n",
       "      <td>[0.4470893]</td>\n",
       "      <td>[0.08461728]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.63911015, 0.15714303, 0.8798483, 0.5889911...</td>\n",
       "      <td>[0.24631687]</td>\n",
       "      <td>[0.1471193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.16090491, 0.3736248, 0.36928993, 0.0652277...</td>\n",
       "      <td>[0.7953618]</td>\n",
       "      <td>[0.15261748]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.69185007, 0.744658, 0.2523723, 0.9564506, ...</td>\n",
       "      <td>[0.68668514]</td>\n",
       "      <td>[0.018491564]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.34584802, 0.12259918, 0.7084872, 0.6204603...</td>\n",
       "      <td>[0.9208119]</td>\n",
       "      <td>[0.037749376]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           encodings    sentiments  \\\n",
       "0  [[0.49391288, 0.5181262, 0.3267757, 0.419439, ...   [0.4470893]   \n",
       "1  [[0.63911015, 0.15714303, 0.8798483, 0.5889911...  [0.24631687]   \n",
       "2  [[0.16090491, 0.3736248, 0.36928993, 0.0652277...   [0.7953618]   \n",
       "3  [[0.69185007, 0.744658, 0.2523723, 0.9564506, ...  [0.68668514]   \n",
       "4  [[0.34584802, 0.12259918, 0.7084872, 0.6204603...   [0.9208119]   \n",
       "\n",
       "  price_percentage_changes  \n",
       "0             [0.08461728]  \n",
       "1              [0.1471193]  \n",
       "2             [0.15261748]  \n",
       "3            [0.018491564]  \n",
       "4            [0.037749376]  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = pd.DataFrame({\n",
    "    'encodings': list(encodings),\n",
    "    'sentiments': list(sentiments),\n",
    "    'price_percentage_changes': list(price_percentage_changes)\n",
    "})    \n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5007142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Create proper dataset class instead of generator\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, encodings, sentiments, price_changes):\n",
    "        self.encodings = encodings\n",
    "        self.sentiments = sentiments\n",
    "        self.price_changes = price_changes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Multiply encodings by sentiment (broadcasting)\n",
    "        input_data = self.encodings[idx] * self.sentiments[idx][0]\n",
    "        target = self.price_changes[idx][0]  # Single value, not array\n",
    "        \n",
    "        return torch.tensor(input_data, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = NewsDataset(encodings, sentiments, price_percentage_changes)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a25bb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SetTransformer(\n",
    "    dim_input = embedding_dim, \n",
    "    num_outputs = 1, #One final prediction\n",
    "    dim_output = 1, #1D output for price change\n",
    "    num_inds=32, \n",
    "    dim_hidden=128, \n",
    "    num_heads=4, \n",
    "    ln=True #Layer normalization\n",
    "    )\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a68c5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adith\\anaconda3\\envs\\MLEnvt_Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\adith\\anaconda3\\envs\\MLEnvt_Python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 2.9138\n",
      "Epoch 0: val loss 0.7320\n",
      "Epoch 1: train loss 0.2499\n",
      "Epoch 2: train loss 0.0873\n",
      "Epoch 3: train loss 0.0527\n",
      "Epoch 4: train loss 0.0180\n",
      "Epoch 5: train loss 0.0343\n",
      "Epoch 5: val loss 0.0213\n",
      "Epoch 6: train loss 0.0092\n",
      "Epoch 7: train loss 0.0159\n",
      "Epoch 8: train loss 0.0052\n",
      "Epoch 9: train loss 0.0099\n",
      "Epoch 10: train loss 0.0040\n",
      "Epoch 10: val loss 0.0066\n",
      "Epoch 11: train loss 0.0076\n",
      "Epoch 12: train loss 0.0036\n",
      "Epoch 13: train loss 0.0066\n",
      "Epoch 14: train loss 0.0041\n",
      "Epoch 15: train loss 0.0043\n",
      "Epoch 15: val loss 0.0029\n",
      "Epoch 16: train loss 0.0027\n",
      "Epoch 17: train loss 0.0031\n",
      "Epoch 18: train loss 0.0027\n",
      "Epoch 19: train loss 0.0030\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (inps, outs) in enumerate(train_loader):\n",
    "        # Move to device\n",
    "        inps = inps.to(device)\n",
    "        outs = outs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        preds = model(inps)\n",
    "        \n",
    "        # Ensure output shapes match\n",
    "        if preds.dim() > 1: #Output will be 32*1*1 if batch size is 32\n",
    "            preds = preds.squeeze(-1)  # Remove last dimension if it's 1\n",
    "        \n",
    "        loss = criterion(preds, outs)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Epoch {epoch}: train loss {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inps, outs in train_loader:  # Using same data for demo\n",
    "                inps = inps.to(device)\n",
    "                outs = outs.to(device)\n",
    "                \n",
    "                preds = model(inps)\n",
    "                if preds.dim() > 1:\n",
    "                    preds = preds.squeeze(-1)\n",
    "                \n",
    "                loss = criterion(preds, outs)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        print(f\"Epoch {epoch}: val loss {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Print sample predictions\n",
    "        # print(f\"Sample predictions: {preds[:5].cpu().numpy()}\")\n",
    "        # print(f\"Sample targets: {outs[:5].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b54a436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 256]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print (inps.shape,outs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f6dae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLEnvt_Python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
