{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149c7389",
   "metadata": {},
   "source": [
    "## Model for price prediction from sentiment data.\n",
    "> We need it to take a dictionary of sentence : sentiment pairs.\n",
    "> This size of the dictionary is variable/flexible.\n",
    "\n",
    "We could potentially design this module as an Transformer encoder model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137062f",
   "metadata": {},
   "source": [
    "References:\n",
    "> https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1/\n",
    "\n",
    "> [Set Transformer: A Framework for Attention-based\n",
    " Permutation-Invariant Neural Networks](https://arxiv.org/pdf/1810.00825)\n",
    "\n",
    " > https://github.com/juho-lee/set_transformer\n",
    "\n",
    " > [Deep sets](https://papers.nips.cc/paper_files/paper/2017/hash/f22e4747da1aa27e363d86d40ff442fe-Abstract.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4beec",
   "metadata": {},
   "source": [
    "Since we want our model to be invarient to permutations in the order in which we feed the news articles and associated sentiments, we can proceed using a set-transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ead1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class MAB(nn.Module):\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):\n",
    "        super(MAB, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.fc_q = nn.Linear(dim_Q, dim_V)\n",
    "        self.fc_k = nn.Linear(dim_K, dim_V)\n",
    "        self.fc_v = nn.Linear(dim_K, dim_V)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(dim_V)\n",
    "            self.ln1 = nn.LayerNorm(dim_V)\n",
    "        self.fc_o = nn.Linear(dim_V, dim_V)\n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.fc_q(Q)\n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.dim_V // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "\n",
    "        A = torch.softmax(Q_.bmm(K_.transpose(1,2))/math.sqrt(self.dim_V), 2)\n",
    "        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "        O = O + F.relu(self.fc_o(O))\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        return O\n",
    "\n",
    "class SAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, ln=False):\n",
    "        super(SAB, self).__init__()\n",
    "        self.mab = MAB(dim_in, dim_in, dim_out, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mab(X, X)\n",
    "\n",
    "class ISAB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, num_heads, num_inds, ln=False):\n",
    "        super(ISAB, self).__init__()\n",
    "        self.I = nn.Parameter(torch.Tensor(1, num_inds, dim_out))\n",
    "        nn.init.xavier_uniform_(self.I)\n",
    "        self.mab0 = MAB(dim_out, dim_in, dim_out, num_heads, ln=ln)\n",
    "        self.mab1 = MAB(dim_in, dim_out, dim_out, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        H = self.mab0(self.I.repeat(X.size(0), 1, 1), X)\n",
    "        return self.mab1(X, H)\n",
    "\n",
    "class PMA(nn.Module):\n",
    "    def __init__(self, dim, num_heads, num_seeds, ln=False):\n",
    "        super(PMA, self).__init__()\n",
    "        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))\n",
    "        nn.init.xavier_uniform_(self.S)\n",
    "        self.mab = MAB(dim, dim, dim, num_heads, ln=ln)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.mab(self.S.repeat(X.size(0), 1, 1), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bde620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSet(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output, dim_hidden=128):\n",
    "        super(DeepSet, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.dim_output = dim_output\n",
    "        self.enc = nn.Sequential(\n",
    "                nn.Linear(dim_input, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden))\n",
    "        self.dec = nn.Sequential(\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, dim_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(dim_hidden, num_outputs*dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.enc(X).mean(-2)\n",
    "        X = self.dec(X).reshape(-1, self.num_outputs, self.dim_output)\n",
    "        return X\n",
    "\n",
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=4, ln=False):\n",
    "        super(SetTransformer, self).__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dec(self.enc(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "98ee56b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10, 256) [[[0.91048276 0.19734186 0.22486499 ... 0.40618408 0.92178136 0.5661647 ]\n",
      "  [0.7591644  0.87074685 0.31699267 ... 0.32964826 0.36503044 0.40797657]\n",
      "  [0.5969745  0.05806377 0.7231523  ... 0.7675753  0.12269455 0.40065286]\n",
      "  ...\n",
      "  [0.0321703  0.8939506  0.953571   ... 0.79273903 0.53147393 0.7241469 ]\n",
      "  [0.10080913 0.83438474 0.98348325 ... 0.69011456 0.98091567 0.83473915]\n",
      "  [0.9856216  0.13100976 0.36658415 ... 0.5846759  0.01886287 0.14966795]]\n",
      "\n",
      " [[0.27407527 0.2191102  0.3515185  ... 0.893201   0.3406108  0.10998099]\n",
      "  [0.8265604  0.9763401  0.8191433  ... 0.40011767 0.87134945 0.43417493]\n",
      "  [0.66520786 0.48240307 0.95109856 ... 0.4819437  0.4842333  0.4407385 ]\n",
      "  ...\n",
      "  [0.22965983 0.6492614  0.03905968 ... 0.94743043 0.17267446 0.05969359]\n",
      "  [0.07663344 0.3735552  0.45401952 ... 0.4988756  0.4566521  0.3246412 ]\n",
      "  [0.73924375 0.20909086 0.49296996 ... 0.80788386 0.7847491  0.3605323 ]]\n",
      "\n",
      " [[0.29940197 0.1599657  0.227631   ... 0.31971666 0.05820284 0.7321239 ]\n",
      "  [0.71637034 0.47612172 0.4493333  ... 0.9113623  0.11407439 0.2784691 ]\n",
      "  [0.5800217  0.64125407 0.1769409  ... 0.1042303  0.38995138 0.1829181 ]\n",
      "  ...\n",
      "  [0.97658795 0.30565405 0.3477436  ... 0.8410179  0.55034405 0.802657  ]\n",
      "  [0.5195393  0.09134583 0.8005428  ... 0.5912523  0.29109326 0.09718584]\n",
      "  [0.8302952  0.5790814  0.12466484 ... 0.7083223  0.41252223 0.03797921]]\n",
      "\n",
      " [[0.7902688  0.76318496 0.9087278  ... 0.2913219  0.7382703  0.76754314]\n",
      "  [0.4017738  0.33258423 0.7257901  ... 0.36393857 0.7821694  0.02950783]\n",
      "  [0.06137364 0.64183366 0.97989035 ... 0.14192577 0.4948401  0.5416751 ]\n",
      "  ...\n",
      "  [0.4398272  0.21884209 0.49029586 ... 0.46825224 0.95936984 0.00217734]\n",
      "  [0.7851749  0.68646044 0.25044736 ... 0.6126976  0.46648237 0.7239252 ]\n",
      "  [0.5796791  0.70165116 0.44943476 ... 0.38622174 0.6832412  0.44920895]]\n",
      "\n",
      " [[0.4374825  0.13676775 0.9476627  ... 0.03782678 0.50790244 0.4780443 ]\n",
      "  [0.55899215 0.98395514 0.00155657 ... 0.5505114  0.76023746 0.8229168 ]\n",
      "  [0.84618753 0.1553497  0.04042401 ... 0.5141664  0.5985079  0.03668739]\n",
      "  ...\n",
      "  [0.44814432 0.8573265  0.71060294 ... 0.9375259  0.1674063  0.23922083]\n",
      "  [0.6821327  0.6019645  0.5566485  ... 0.5849506  0.7143744  0.87780297]\n",
      "  [0.2195071  0.93952733 0.32875288 ... 0.80358785 0.45129868 0.19887207]]]\n",
      "(100, 1) [[0.73971826]\n",
      " [0.24886653]\n",
      " [0.6676872 ]\n",
      " [0.10046396]\n",
      " [0.3344104 ]]\n",
      "(100, 1) [[0.08840006]\n",
      " [0.08190577]\n",
      " [0.12570345]\n",
      " [0.14250155]\n",
      " [0.1833147 ]]\n"
     ]
    }
   ],
   "source": [
    "#Generate some Dummy data to test out the model using\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset_size = 100\n",
    "embedding_dim = 256\n",
    "encodings = np.random.rand(dataset_size, 10, embedding_dim).astype(np.float32)\n",
    "print(encodings.shape,encodings[:5])\n",
    "\n",
    "sentiments = np.random.rand(dataset_size, 1).astype(np.float32)\n",
    "print(sentiments.shape, sentiments[:5])\n",
    "\n",
    "price_percentage_changes = np.random.rand(dataset_size, 1).astype(np.float32)* 0.2;\n",
    "print(price_percentage_changes.shape, price_percentage_changes[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2fe291d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "encodings",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sentiments",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "price_percentage_changes",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "95d42778-3b0a-410c-ab02-995f8cc65013",
       "rows": [
        [
         "0",
         "[[0.91048276 0.19734186 0.22486499 ... 0.40618408 0.92178136 0.5661647 ]\n [0.7591644  0.87074685 0.31699267 ... 0.32964826 0.36503044 0.40797657]\n [0.5969745  0.05806377 0.7231523  ... 0.7675753  0.12269455 0.40065286]\n ...\n [0.0321703  0.8939506  0.953571   ... 0.79273903 0.53147393 0.7241469 ]\n [0.10080913 0.83438474 0.98348325 ... 0.69011456 0.98091567 0.83473915]\n [0.9856216  0.13100976 0.36658415 ... 0.5846759  0.01886287 0.14966795]]",
         "[0.73971826]",
         "[0.08840006]"
        ],
        [
         "1",
         "[[0.27407527 0.2191102  0.3515185  ... 0.893201   0.3406108  0.10998099]\n [0.8265604  0.9763401  0.8191433  ... 0.40011767 0.87134945 0.43417493]\n [0.66520786 0.48240307 0.95109856 ... 0.4819437  0.4842333  0.4407385 ]\n ...\n [0.22965983 0.6492614  0.03905968 ... 0.94743043 0.17267446 0.05969359]\n [0.07663344 0.3735552  0.45401952 ... 0.4988756  0.4566521  0.3246412 ]\n [0.73924375 0.20909086 0.49296996 ... 0.80788386 0.7847491  0.3605323 ]]",
         "[0.24886653]",
         "[0.08190577]"
        ],
        [
         "2",
         "[[0.29940197 0.1599657  0.227631   ... 0.31971666 0.05820284 0.7321239 ]\n [0.71637034 0.47612172 0.4493333  ... 0.9113623  0.11407439 0.2784691 ]\n [0.5800217  0.64125407 0.1769409  ... 0.1042303  0.38995138 0.1829181 ]\n ...\n [0.97658795 0.30565405 0.3477436  ... 0.8410179  0.55034405 0.802657  ]\n [0.5195393  0.09134583 0.8005428  ... 0.5912523  0.29109326 0.09718584]\n [0.8302952  0.5790814  0.12466484 ... 0.7083223  0.41252223 0.03797921]]",
         "[0.6676872]",
         "[0.12570345]"
        ],
        [
         "3",
         "[[0.7902688  0.76318496 0.9087278  ... 0.2913219  0.7382703  0.76754314]\n [0.4017738  0.33258423 0.7257901  ... 0.36393857 0.7821694  0.02950783]\n [0.06137364 0.64183366 0.97989035 ... 0.14192577 0.4948401  0.5416751 ]\n ...\n [0.4398272  0.21884209 0.49029586 ... 0.46825224 0.95936984 0.00217734]\n [0.7851749  0.68646044 0.25044736 ... 0.6126976  0.46648237 0.7239252 ]\n [0.5796791  0.70165116 0.44943476 ... 0.38622174 0.6832412  0.44920895]]",
         "[0.10046396]",
         "[0.14250155]"
        ],
        [
         "4",
         "[[0.4374825  0.13676775 0.9476627  ... 0.03782678 0.50790244 0.4780443 ]\n [0.55899215 0.98395514 0.00155657 ... 0.5505114  0.76023746 0.8229168 ]\n [0.84618753 0.1553497  0.04042401 ... 0.5141664  0.5985079  0.03668739]\n ...\n [0.44814432 0.8573265  0.71060294 ... 0.9375259  0.1674063  0.23922083]\n [0.6821327  0.6019645  0.5566485  ... 0.5849506  0.7143744  0.87780297]\n [0.2195071  0.93952733 0.32875288 ... 0.80358785 0.45129868 0.19887207]]",
         "[0.3344104]",
         "[0.1833147]"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encodings</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>price_percentage_changes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.91048276, 0.19734186, 0.22486499, 0.018048...</td>\n",
       "      <td>[0.73971826]</td>\n",
       "      <td>[0.08840006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.27407527, 0.2191102, 0.3515185, 0.3321529,...</td>\n",
       "      <td>[0.24886653]</td>\n",
       "      <td>[0.081905775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.29940197, 0.1599657, 0.227631, 0.8078488, ...</td>\n",
       "      <td>[0.6676872]</td>\n",
       "      <td>[0.12570345]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.7902688, 0.76318496, 0.9087278, 0.6236607,...</td>\n",
       "      <td>[0.10046396]</td>\n",
       "      <td>[0.14250155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.4374825, 0.13676775, 0.9476627, 0.6723774,...</td>\n",
       "      <td>[0.3344104]</td>\n",
       "      <td>[0.1833147]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           encodings    sentiments  \\\n",
       "0  [[0.91048276, 0.19734186, 0.22486499, 0.018048...  [0.73971826]   \n",
       "1  [[0.27407527, 0.2191102, 0.3515185, 0.3321529,...  [0.24886653]   \n",
       "2  [[0.29940197, 0.1599657, 0.227631, 0.8078488, ...   [0.6676872]   \n",
       "3  [[0.7902688, 0.76318496, 0.9087278, 0.6236607,...  [0.10046396]   \n",
       "4  [[0.4374825, 0.13676775, 0.9476627, 0.6723774,...   [0.3344104]   \n",
       "\n",
       "  price_percentage_changes  \n",
       "0             [0.08840006]  \n",
       "1            [0.081905775]  \n",
       "2             [0.12570345]  \n",
       "3             [0.14250155]  \n",
       "4              [0.1833147]  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = pd.DataFrame({\n",
    "    'encodings': list(encodings),\n",
    "    'sentiments': list(sentiments),\n",
    "    'price_percentage_changes': list(price_percentage_changes)\n",
    "})    \n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5007142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Create proper dataset class instead of generator\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, encodings, sentiments, price_changes):\n",
    "        self.encodings = encodings\n",
    "        self.sentiments = sentiments\n",
    "        self.price_changes = price_changes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Multiply encodings by sentiment (broadcasting)\n",
    "        input_data = self.encodings[idx] * self.sentiments[idx][0]\n",
    "        target = self.price_changes[idx][0]  # Single value, not array\n",
    "        \n",
    "        return torch.tensor(input_data, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = NewsDataset(encodings, sentiments, price_percentage_changes)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a25bb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SetTransformer(\n",
    "    dim_input = embedding_dim, \n",
    "    num_outputs = 1, #One final prediction\n",
    "    dim_output = 1, #1D output for price change\n",
    "    num_inds=32, \n",
    "    dim_hidden=128, \n",
    "    num_heads=4, \n",
    "    ln=True #Layer normalization\n",
    "    )\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a68c5b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 0.0034\n",
      "Epoch 0: val loss 0.0032\n",
      "Epoch 1: train loss 0.0040\n",
      "Epoch 2: train loss 0.0040\n",
      "Epoch 3: train loss 0.0035\n",
      "Epoch 4: train loss 0.0036\n",
      "Epoch 5: train loss 0.0052\n",
      "Epoch 5: val loss 0.0058\n",
      "Epoch 6: train loss 0.0073\n",
      "Epoch 7: train loss 0.0063\n",
      "Epoch 8: train loss 0.0049\n",
      "Epoch 9: train loss 0.0051\n",
      "Epoch 10: train loss 0.0060\n",
      "Epoch 10: val loss 0.0035\n",
      "Epoch 11: train loss 0.0058\n",
      "Epoch 12: train loss 0.0056\n",
      "Epoch 13: train loss 0.0038\n",
      "Epoch 14: train loss 0.0054\n",
      "Epoch 15: train loss 0.0044\n",
      "Epoch 15: val loss 0.0044\n",
      "Epoch 16: train loss 0.0041\n",
      "Epoch 17: train loss 0.0039\n",
      "Epoch 18: train loss 0.0042\n",
      "Epoch 19: train loss 0.0038\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (inps, outs) in enumerate(train_loader):\n",
    "        # Move to device\n",
    "        inps = inps.to(device)\n",
    "        outs = outs.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        preds = model(inps)\n",
    "        \n",
    "        # Ensure output shapes match\n",
    "        if preds.dim() > 1: #Output will be 32*1*1 if batch size is 32\n",
    "            preds = preds.squeeze(-1)  # Remove last dimension if it's 1\n",
    "        \n",
    "        loss = criterion(preds, outs)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Epoch {epoch}: train loss {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inps, outs in train_loader:  # Using same data for demo\n",
    "                inps = inps.to(device)\n",
    "                outs = outs.to(device)\n",
    "                \n",
    "                preds = model(inps)\n",
    "                if preds.dim() > 1:\n",
    "                    preds = preds.squeeze(-1)\n",
    "                \n",
    "                loss = criterion(preds, outs)\n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        print(f\"Epoch {epoch}: val loss {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Print sample predictions\n",
    "        # print(f\"Sample predictions: {preds[:5].cpu().numpy()}\")\n",
    "        # print(f\"Sample targets: {outs[:5].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8f6dae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLEnvt_Python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
